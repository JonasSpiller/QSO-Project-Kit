{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544a1e96-521c-4bd0-b109-e0edbcb7ae1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fitsio\n",
      "  Using cached fitsio-1.2.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy in /global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages (from fitsio) (1.26.3)\n",
      "Using cached fitsio-1.2.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (825 kB)\n",
      "Installing collected packages: fitsio\n",
      "Successfully installed fitsio-1.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d4c4e9-3db6-4b9a-8d86-5fb249727bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 07:33:23.940197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-10 07:33:23.940228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-10 07:33:23.987235: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-10 07:33:28.609350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from utility_functions import extract_data_from_fits\n",
    "from utility_functions import train_CNN_js\n",
    "from MLmodels import CNN_model1\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pytz\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#print(\"GPU Devices: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# For saving the progress to txt file\n",
    "zurich_timezone = pytz.timezone('Europe/Zurich')\n",
    "\n",
    "start_global = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f4272e-ee07-4049-896c-16a5b44e5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal1_amplified100/A/modified_minsignal1_desi_bright_qso_batch3.fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.expandvars('$SCRATCH/DATA/modifiedMainQSO/modifiedMainQSO_minsignal1_amplified100/A/')\n",
    "results_path = os.path.expandvars('$SCRATCH/RESULTS/modifiedMainQSO_minsignal1_amplified100/A/')\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "flux_list = []\n",
    "labels_list = []\n",
    "\n",
    "fits_files = [os.path.join(data_path, file) for file in os.listdir(data_path)[:1] if file.endswith('.fits')]\n",
    "\n",
    "for fits_file in fits_files:\n",
    "    flux, labels, _ = extract_data_from_fits(fits_file)\n",
    "    flux_list.append(flux)\n",
    "    labels_list.append(labels)\n",
    "\n",
    "# Concatenate all flux and labels arrays\n",
    "all_flux = np.concatenate(flux_list, axis=0)\n",
    "all_labels = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "x_train, x_testvalid, y_train, y_testvalid = train_test_split(all_flux, all_labels, train_size=0.7, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_testvalid, y_testvalid, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize and then normalize each spectrum individually\n",
    "x_train = np.array([(x - np.mean(x)) / np.std(x) for x in x_train])\n",
    "x_valid = np.array([(x - np.mean(x)) / np.std(x) for x in x_valid])\n",
    "x_test = np.array([(x - np.mean(x)) / np.std(x) for x in x_test])\n",
    "\n",
    "# Normalize each standardized spectrum (min-max normalization to [-1, 1])\n",
    "x_train = np.array([x / np.max(np.abs(x)) for x in x_train])\n",
    "x_valid = np.array([x / np.max(np.abs(x)) for x in x_valid])\n",
    "x_test = np.array([x / np.max(np.abs(x)) for x in x_test])\n",
    "\n",
    "# Expand Dimensions to Channels\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_valid = np.expand_dims(x_valid, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "del all_flux, all_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059d7c64-3fd7-44c8-97bd-d2095204b24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 2591, 64)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 165824)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "nid001157:2216333:2217692 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn\n",
      "nid001157:2216333:2217692 [0] NCCL INFO Bootstrap : Using hsn0:10.249.4.218<0>\n",
      "nid001157:2216333:2217692 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "nid001157:2216333:2217692 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "nid001157:2216333:2217702 [0] NCCL INFO cudaDriverVersion 12040\n",
      "NCCL version 2.16.5+cudaCUDA_MAJOR.CUDA_MINOR\n",
      "nid001157:2216333:2217708 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.6.0-hcopy\n",
      "nid001157:2216333:2217708 [0] NCCL INFO NET/OFI Selected Provider is cxi (found 8 nics)\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Using network AWS Libfabric\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Using network AWS Libfabric\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Using network AWS Libfabric\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Using network AWS Libfabric\n",
      "nid001157:2216333:2217709 [1] NCCL INFO DMA-BUF is available on GPU device 1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO DMA-BUF is available on GPU device 0\n",
      "nid001157:2216333:2217710 [2] NCCL INFO DMA-BUF is available on GPU device 2\n",
      "nid001157:2216333:2217711 [3] NCCL INFO DMA-BUF is available on GPU device 3\n",
      "nid001157:2216333:2217709 [1] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to PHB\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Setting affinity for GPU 1 to ffff,00000000,0000ffff,00000000\n",
      "nid001157:2216333:2217709 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,ffff0000\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Setting affinity for GPU 3 to ffff,00000000,0000ffff\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,ffff0000,00000000\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 00/24 :    0   1   2   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 01/24 :    0   1   3   2\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 02/24 :    0   2   3   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 03/24 :    0   2   1   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 04/24 :    0   3   1   2\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 05/24 :    0   3   2   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 06/24 :    0   1   2   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 07/24 :    0   1   3   2\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 08/24 :    0   2   3   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 09/24 :    0   2   1   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 10/24 :    0   3   1   2\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 11/24 :    0   3   2   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 12/24 :    0   1   2   3\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->1 [3] 0/-1/-1->3->1 [4] 1/-1/-1->3->0 [5] 1/-1/-1->3->0 [6] 2/-1/-1->3->-1 [7] 2/-1/-1->3->-1 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 0/-1/-1->3->1 [11] 0/-1/-1->3->1 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] 0/-1/-1->3->1 [15] 0/-1/-1->3->1 [16] 1/-1/-1->3->0 [17] 1/-1/-1->3->0 [18] 2/-1/-1->3->-1 [19] 2/-1/-1->3->-1 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] 0/-1/-1->3->1 [23] 0/-1/-1->3->1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 13/24 :    0   1   3   2\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 14/24 :    0   2   3   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 15/24 :    0   2   1   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 16/24 :    0   3   1   2\n",
      "nid001157:2216333:2217711 [3] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 17/24 :    0   3   2   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 18/24 :    0   1   2   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 19/24 :    0   1   3   2\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] -1/-1/-1->2->0 [3] -1/-1/-1->2->0 [4] 0/-1/-1->2->-1 [5] 0/-1/-1->2->-1 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->0 [11] -1/-1/-1->2->0 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] -1/-1/-1->2->0 [15] -1/-1/-1->2->0 [16] 0/-1/-1->2->-1 [17] 0/-1/-1->2->-1 [18] 1/-1/-1->2->3 [19] 1/-1/-1->2->3 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] -1/-1/-1->2->0 [23] -1/-1/-1->2->0\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 3/-1/-1->1->-1 [3] 3/-1/-1->1->-1 [4] -1/-1/-1->1->3 [5] -1/-1/-1->1->3 [6] 0/-1/-1->1->2 [7] 0/-1/-1->1->2 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 3/-1/-1->1->-1 [11] 3/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 3/-1/-1->1->-1 [15] 3/-1/-1->1->-1 [16] -1/-1/-1->1->3 [17] -1/-1/-1->1->3 [18] 0/-1/-1->1->2 [19] 0/-1/-1->1->2 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 3/-1/-1->1->-1 [23] 3/-1/-1->1->-1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 20/24 :    0   2   3   1\n",
      "nid001157:2216333:2217709 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 21/24 :    0   2   1   3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 22/24 :    0   3   1   2\n",
      "nid001157:2216333:2217710 [2] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 23/24 :    0   3   2   1\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 2/-1/-1->0->3 [3] 2/-1/-1->0->3 [4] 3/-1/-1->0->2 [5] 3/-1/-1->0->2 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 2/-1/-1->0->3 [11] 2/-1/-1->0->3 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 2/-1/-1->0->3 [15] 2/-1/-1->0->3 [16] 3/-1/-1->0->2 [17] 3/-1/-1->0->2 [18] -1/-1/-1->0->1 [19] -1/-1/-1->0->1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 2/-1/-1->0->3 [23] 2/-1/-1->0->3\n",
      "nid001157:2216333:2217708 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 00/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 00/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 00/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 04/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 02/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 03/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 06/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 06/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 06/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 06/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 10/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 08/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 09/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 07/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 12/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 12/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 12/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 12/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 16/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 14/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 15/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 13/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 18/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 18/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 18/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 18/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 22/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 20/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 21/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 19/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 01/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 01/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 02/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 04/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 03/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 04/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 07/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 02/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 07/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 08/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 10/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 03/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 09/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 10/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 13/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 08/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 13/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 14/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 16/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 09/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 15/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 16/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 19/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 14/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 19/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 20/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 22/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 15/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 21/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 22/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 20/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 21/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 02/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 01/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 05/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 05/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 03/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 08/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 04/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 07/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 05/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 11/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 05/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 11/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 09/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 14/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 10/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 13/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 11/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 17/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 11/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 17/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 15/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 20/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 16/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 19/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 17/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 23/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 17/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 23/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 21/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 22/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 23/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 23/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Connected all rings\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Connected all rings\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Connected all rings\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Connected all rings\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 01/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 07/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 08/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 02/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 09/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 04/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 01/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 13/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 05/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 07/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 19/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 10/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 09/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 20/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 11/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 08/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 13/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 21/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 14/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 09/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 19/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 16/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 20/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 21/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 17/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 21/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 22/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 23/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 02/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 04/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 05/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 10/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 02/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 04/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 11/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 03/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 05/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 14/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 05/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 10/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 03/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 16/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 11/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 11/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 05/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 17/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 14/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 16/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 11/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 22/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 15/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 17/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 15/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 23/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 17/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 22/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 17/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 23/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 23/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 23/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 00/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 06/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 08/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 09/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 00/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 12/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 01/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 18/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 06/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 02/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 20/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 00/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 07/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 03/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217711 [3] NCCL INFO Channel 21/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 01/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 08/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 14/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 06/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 12/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217708 [0] NCCL INFO Channel 15/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 07/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 13/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 09/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 18/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Channel 12/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217710 [2] NCCL INFO Channel 19/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001157:2216333:2217709 [1] NCCL INFO Ch"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745860975.237242 2216792 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 10s 23ms/step - loss: 0.4142 - precision: 0.6988 - recall: 0.7050 - pr_auc: 0.6742 - val_loss: 0.1254 - val_precision: 0.7322 - val_recall: 0.9371 - val_pr_auc: 0.9098\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0979 - precision: 0.8300 - recall: 0.8068 - pr_auc: 0.8834 - val_loss: 0.0636 - val_precision: 0.8421 - val_recall: 0.8951 - val_pr_auc: 0.9487\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0635 - precision: 0.8820 - recall: 0.8599 - pr_auc: 0.9291 - val_loss: 0.0912 - val_precision: 0.7326 - val_recall: 0.9580 - val_pr_auc: 0.9502\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0435 - precision: 0.9227 - recall: 0.9159 - pr_auc: 0.9688 - val_loss: 0.0650 - val_precision: 0.8291 - val_recall: 0.9161 - val_pr_auc: 0.9474\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 12ms/step - loss: 0.0287 - precision: 0.9459 - recall: 0.9543 - pr_auc: 0.9865 - val_loss: 0.0725 - val_precision: 0.9084 - val_recall: 0.8322 - val_pr_auc: 0.9458\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0150 - precision: 0.9738 - recall: 0.9867 - pr_auc: 0.9978 - val_loss: 0.0792 - val_precision: 0.8072 - val_recall: 0.9371 - val_pr_auc: 0.9460\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0107 - precision: 0.9810 - recall: 0.9926 - pr_auc: 0.9991 - val_loss: 0.0813 - val_precision: 0.8182 - val_recall: 0.8811 - val_pr_auc: 0.9425\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0109 - precision: 0.9839 - recall: 0.9897 - pr_auc: 0.9979 - val_loss: 0.0874 - val_precision: 0.8759 - val_recall: 0.8392 - val_pr_auc: 0.9337\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0037 - precision: 0.9956 - recall: 1.0000 - pr_auc: 0.9999 - val_loss: 0.0984 - val_precision: 0.8800 - val_recall: 0.7692 - val_pr_auc: 0.9292\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0021 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1009 - val_precision: 0.8647 - val_recall: 0.8042 - val_pr_auc: 0.9126\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0993 - val_precision: 0.8531 - val_recall: 0.8531 - val_pr_auc: 0.9185\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.4871e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1120 - val_precision: 0.8731 - val_recall: 0.8182 - val_pr_auc: 0.9153\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.6337e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1171 - val_precision: 0.8667 - val_recall: 0.8182 - val_pr_auc: 0.9089\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.5428e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1194 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9157\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.5230e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1183 - val_precision: 0.8686 - val_recall: 0.8322 - val_pr_auc: 0.8982\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.9971e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1305 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9085\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.2692e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1252 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9032\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.8658e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1264 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9099\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.4764e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1375 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8889\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.2344e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1340 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.8920\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9583e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1384 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8932\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7423e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1397 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.8885\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.5652e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1364 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8948\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.4264e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1420 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.8892\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2596e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1452 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8895\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.1920e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1491 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.8837\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0631e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1510 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.8846\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 9.7181e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1509 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8859\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 8.6217e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1534 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8858\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.8940e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1543 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8855\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.2700e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1572 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8856\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.6825e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1555 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8796\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.1769e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1556 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8817\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 2591, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3087 - precision: 0.7121 - recall: 0.6858 - pr_auc: 0.7115 - val_loss: 0.0902 - val_precision: 0.8440 - val_recall: 0.8322 - val_pr_auc: 0.8983\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0961 - precision: 0.8501 - recall: 0.8451 - pr_auc: 0.8855 - val_loss: 0.0647 - val_precision: 0.8652 - val_recall: 0.8531 - val_pr_auc: 0.9404\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0513 - precision: 0.9108 - recall: 0.9041 - pr_auc: 0.9514 - val_loss: 0.0780 - val_precision: 0.9310 - val_recall: 0.7552 - val_pr_auc: 0.9438\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0284 - precision: 0.9546 - recall: 0.9617 - pr_auc: 0.9835 - val_loss: 0.0755 - val_precision: 0.9194 - val_recall: 0.7972 - val_pr_auc: 0.9426\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0141 - precision: 0.9795 - recall: 0.9853 - pr_auc: 0.9975 - val_loss: 0.0825 - val_precision: 0.8496 - val_recall: 0.7902 - val_pr_auc: 0.9253\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0100 - precision: 0.9810 - recall: 0.9926 - pr_auc: 0.9993 - val_loss: 0.1048 - val_precision: 0.9160 - val_recall: 0.8392 - val_pr_auc: 0.9254\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0051 - precision: 0.9912 - recall: 0.9956 - pr_auc: 0.9998 - val_loss: 0.1219 - val_precision: 0.8917 - val_recall: 0.7483 - val_pr_auc: 0.9124\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0023 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1092 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.9301\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1031 - val_precision: 0.8582 - val_recall: 0.8462 - val_pr_auc: 0.9179\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.1251e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1224 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9057\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.0136e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1223 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9057\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.6945e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1207 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9092\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.1533e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1226 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9088\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.1780e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1319 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9048\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7106e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1277 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9070\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.3696e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1325 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9060\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.0234e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1332 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.9020\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7325e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1363 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.9030\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.5136e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1447 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9032\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3708e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1432 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9034\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2343e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1369 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.9031\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0670e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1462 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8996\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 9.6603e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1459 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.8965\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.5384e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1441 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.8941\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 8.0060e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1521 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8962\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.0514e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1532 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8960\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.5222e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1549 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8840\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 5.9620e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1605 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8902\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.4768e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1566 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8844\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.9917e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1604 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8897\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.6248e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1623 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8846\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.2038e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1631 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8843\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.9844e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1643 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8846\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 2591, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 28 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/28\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 5s 36ms/step - loss: 0.9950 - precision: 0.6158 - recall: 0.6667 - pr_auc: 0.5355 - val_loss: 0.1785 - val_precision: 0.9077 - val_recall: 0.8252 - val_pr_auc: 0.8701\n",
      "Epoch 2/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2198 - precision: 0.8245 - recall: 0.8245 - pr_auc: 0.8438 - val_loss: 0.1584 - val_precision: 0.8301 - val_recall: 0.8881 - val_pr_auc: 0.8803\n",
      "Epoch 3/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1370 - precision: 0.8368 - recall: 0.8319 - pr_auc: 0.8745 - val_loss: 0.2884 - val_precision: 0.5451 - val_recall: 0.9720 - val_pr_auc: 0.8330\n",
      "Epoch 4/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0851 - precision: 0.8514 - recall: 0.8702 - pr_auc: 0.9008 - val_loss: 0.0649 - val_precision: 0.8971 - val_recall: 0.8531 - val_pr_auc: 0.9511\n",
      "Epoch 5/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0431 - precision: 0.9130 - recall: 0.9292 - pr_auc: 0.9701 - val_loss: 0.0659 - val_precision: 0.8971 - val_recall: 0.8531 - val_pr_auc: 0.9507\n",
      "Epoch 6/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0345 - precision: 0.9387 - recall: 0.9484 - pr_auc: 0.9806 - val_loss: 0.0624 - val_precision: 0.8639 - val_recall: 0.8881 - val_pr_auc: 0.9540\n",
      "Epoch 7/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0249 - precision: 0.9496 - recall: 0.9720 - pr_auc: 0.9917 - val_loss: 0.1124 - val_precision: 0.9714 - val_recall: 0.7133 - val_pr_auc: 0.9334\n",
      "Epoch 8/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0238 - precision: 0.9645 - recall: 0.9631 - pr_auc: 0.9914 - val_loss: 0.0846 - val_precision: 0.8723 - val_recall: 0.8601 - val_pr_auc: 0.9324\n",
      "Epoch 9/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0155 - precision: 0.9824 - recall: 0.9882 - pr_auc: 0.9971 - val_loss: 0.1281 - val_precision: 0.7128 - val_recall: 0.9720 - val_pr_auc: 0.9006\n",
      "Epoch 10/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0165 - precision: 0.9753 - recall: 0.9882 - pr_auc: 0.9958 - val_loss: 0.0846 - val_precision: 0.9194 - val_recall: 0.7972 - val_pr_auc: 0.9435\n",
      "Epoch 11/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0077 - precision: 0.9927 - recall: 1.0000 - pr_auc: 0.9996 - val_loss: 0.0861 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9327\n",
      "Epoch 12/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0047 - precision: 0.9971 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0867 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9400\n",
      "Epoch 13/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0033 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1073 - val_precision: 0.8740 - val_recall: 0.7762 - val_pr_auc: 0.9110\n",
      "Epoch 14/28\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0030 - precision: 0.9985 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1052 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9145\n",
      "Epoch 15/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1068 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9130\n",
      "Epoch 16/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1042 - val_precision: 0.8750 - val_recall: 0.8322 - val_pr_auc: 0.9175\n",
      "Epoch 17/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0015 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1088 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.9148\n",
      "Epoch 18/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1124 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9157\n",
      "Epoch 19/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 9.3022e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1204 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9152\n",
      "Epoch 20/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.9937e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1175 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.9084\n",
      "Epoch 21/28\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.1117e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1178 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9153\n",
      "Epoch 22/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3914e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1210 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9141\n",
      "Epoch 23/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.6496e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1268 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9087\n",
      "Epoch 24/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2977e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1312 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9101\n",
      "Epoch 25/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.6015e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1325 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9010\n",
      "Epoch 26/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2431e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1329 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9141\n",
      "Epoch 27/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.0281e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1278 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9095\n",
      "Epoch 28/28\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.4177e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1395 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9113\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 7775, 256)         2048      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 2591, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 663296)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 663297    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665345 (2.54 MB)\n",
      "Trainable params: 665345 (2.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 256 epochs: 34 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/34\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "27/27 [==============================] - 5s 79ms/step - loss: 6.2056 - precision: 0.2483 - recall: 0.3732 - pr_auc: 0.1966 - val_loss: 1.6164 - val_precision: 1.0000 - val_recall: 0.0559 - val_pr_auc: 0.3593\n",
      "Epoch 2/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.8762 - precision: 0.7695 - recall: 0.7876 - pr_auc: 0.7182 - val_loss: 0.3059 - val_precision: 0.8750 - val_recall: 0.8322 - val_pr_auc: 0.8198\n",
      "Epoch 3/34\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.3501 - precision: 0.8449 - recall: 0.8274 - pr_auc: 0.8068 - val_loss: 0.2110 - val_precision: 0.8611 - val_recall: 0.8671 - val_pr_auc: 0.8635\n",
      "Epoch 4/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.2217 - precision: 0.8557 - recall: 0.8481 - pr_auc: 0.8494 - val_loss: 0.1531 - val_precision: 0.9206 - val_recall: 0.8112 - val_pr_auc: 0.8764\n",
      "Epoch 5/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1354 - precision: 0.8588 - recall: 0.8525 - pr_auc: 0.8796 - val_loss: 0.0984 - val_precision: 0.8768 - val_recall: 0.8462 - val_pr_auc: 0.9184\n",
      "Epoch 6/34\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0894 - precision: 0.8607 - recall: 0.8569 - pr_auc: 0.9100 - val_loss: 0.0914 - val_precision: 0.8025 - val_recall: 0.9091 - val_pr_auc: 0.9190\n",
      "Epoch 7/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0743 - precision: 0.8633 - recall: 0.8850 - pr_auc: 0.9286 - val_loss: 0.0997 - val_precision: 0.9244 - val_recall: 0.7692 - val_pr_auc: 0.9256\n",
      "Epoch 8/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0591 - precision: 0.8951 - recall: 0.8938 - pr_auc: 0.9428 - val_loss: 0.0801 - val_precision: 0.8299 - val_recall: 0.8531 - val_pr_auc: 0.9248\n",
      "Epoch 9/34\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0453 - precision: 0.9055 - recall: 0.9189 - pr_auc: 0.9654 - val_loss: 0.0843 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9230\n",
      "Epoch 10/34\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0466 - precision: 0.9099 - recall: 0.9086 - pr_auc: 0.9659 - val_loss: 0.0851 - val_precision: 0.8089 - val_recall: 0.8881 - val_pr_auc: 0.9232\n",
      "Epoch 11/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0498 - precision: 0.8997 - recall: 0.9130 - pr_auc: 0.9639 - val_loss: 0.1652 - val_precision: 0.8880 - val_recall: 0.7762 - val_pr_auc: 0.8724\n",
      "Epoch 12/34\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0385 - precision: 0.9260 - recall: 0.9233 - pr_auc: 0.9777 - val_loss: 0.1024 - val_precision: 0.7572 - val_recall: 0.9161 - val_pr_auc: 0.9156\n",
      "Epoch 13/34\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 0.0406 - precision: 0.9260 - recall: 0.9410 - pr_auc: 0.9733 - val_loss: 0.1036 - val_precision: 0.9397 - val_recall: 0.7622 - val_pr_auc: 0.9311\n",
      "Epoch 14/34\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0217 - precision: 0.9733 - recall: 0.9676 - pr_auc: 0.9923 - val_loss: 0.0960 - val_precision: 0.9016 - val_recall: 0.7692 - val_pr_auc: 0.9324\n",
      "Epoch 15/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0174 - precision: 0.9695 - recall: 0.9838 - pr_auc: 0.9955 - val_loss: 0.0958 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9192\n",
      "Epoch 16/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0179 - precision: 0.9736 - recall: 0.9808 - pr_auc: 0.9953 - val_loss: 0.1022 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9239\n",
      "Epoch 17/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0118 - precision: 0.9869 - recall: 0.9971 - pr_auc: 0.9987 - val_loss: 0.0983 - val_precision: 0.9016 - val_recall: 0.7692 - val_pr_auc: 0.9204\n",
      "Epoch 18/34\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0100 - precision: 0.9898 - recall: 0.9971 - pr_auc: 0.9995 - val_loss: 0.0972 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9110\n",
      "Epoch 19/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0087 - precision: 0.9898 - recall: 1.0000 - pr_auc: 0.9997 - val_loss: 0.0928 - val_precision: 0.8667 - val_recall: 0.8182 - val_pr_auc: 0.9154\n",
      "Epoch 20/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0080 - precision: 0.9927 - recall: 0.9971 - pr_auc: 0.9998 - val_loss: 0.1004 - val_precision: 0.8667 - val_recall: 0.8182 - val_pr_auc: 0.9147\n",
      "Epoch 21/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0069 - precision: 0.9927 - recall: 1.0000 - pr_auc: 0.9998 - val_loss: 0.1018 - val_precision: 0.8657 - val_recall: 0.8112 - val_pr_auc: 0.9119\n",
      "Epoch 22/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0060 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1012 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9161\n",
      "Epoch 23/34\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0053 - precision: 0.9956 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0965 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9145\n",
      "Epoch 24/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0046 - precision: 0.9956 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1063 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9144\n",
      "Epoch 25/34\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0124 - precision: 0.9896 - recall: 0.9853 - pr_auc: 0.9938 - val_loss: 0.1698 - val_precision: 0.9000 - val_recall: 0.7552 - val_pr_auc: 0.8768\n",
      "Epoch 26/34\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0187 - precision: 0.9662 - recall: 0.9705 - pr_auc: 0.9937 - val_loss: 0.0943 - val_precision: 0.8403 - val_recall: 0.8462 - val_pr_auc: 0.9100\n",
      "Epoch 27/34\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0101 - precision: 0.9912 - recall: 0.9926 - pr_auc: 0.9982 - val_loss: 0.1063 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9054\n",
      "Epoch 28/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0042 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1022 - val_precision: 0.8657 - val_recall: 0.8112 - val_pr_auc: 0.9157\n",
      "Epoch 29/34\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0034 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1115 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8991\n",
      "Epoch 30/34\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0029 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1139 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9010\n",
      "Epoch 31/34\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.0026 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1115 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9051\n",
      "Epoch 32/34\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0023 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1196 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9025\n",
      "Epoch 33/34\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0021 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1190 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9043\n",
      "Epoch 34/34\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0019 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1274 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8991\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 2591, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 38 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/38\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 16ms/step - loss: 0.3325 - precision: 0.7259 - recall: 0.7345 - pr_auc: 0.7258 - val_loss: 0.0827 - val_precision: 0.8571 - val_recall: 0.8811 - val_pr_auc: 0.9364\n",
      "Epoch 2/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0748 - precision: 0.8716 - recall: 0.8614 - pr_auc: 0.9218 - val_loss: 0.0838 - val_precision: 0.7527 - val_recall: 0.9580 - val_pr_auc: 0.9491\n",
      "Epoch 3/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0570 - precision: 0.9062 - recall: 0.8982 - pr_auc: 0.9350 - val_loss: 0.0696 - val_precision: 0.8199 - val_recall: 0.9231 - val_pr_auc: 0.9503\n",
      "Epoch 4/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0413 - precision: 0.9151 - recall: 0.9056 - pr_auc: 0.9736 - val_loss: 0.1086 - val_precision: 0.7818 - val_recall: 0.9021 - val_pr_auc: 0.8822\n",
      "Epoch 5/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0209 - precision: 0.9563 - recall: 0.9690 - pr_auc: 0.9926 - val_loss: 0.0991 - val_precision: 0.9130 - val_recall: 0.7343 - val_pr_auc: 0.9379\n",
      "Epoch 6/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0161 - precision: 0.9704 - recall: 0.9676 - pr_auc: 0.9958 - val_loss: 0.1192 - val_precision: 0.7725 - val_recall: 0.9021 - val_pr_auc: 0.8941\n",
      "Epoch 7/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0060 - precision: 0.9912 - recall: 0.9971 - pr_auc: 0.9997 - val_loss: 0.0903 - val_precision: 0.8561 - val_recall: 0.8322 - val_pr_auc: 0.9254\n",
      "Epoch 8/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0025 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1171 - val_precision: 0.9032 - val_recall: 0.7832 - val_pr_auc: 0.9123\n",
      "Epoch 9/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0019 - precision: 0.9985 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1010 - val_precision: 0.8623 - val_recall: 0.8322 - val_pr_auc: 0.9097\n",
      "Epoch 10/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.8006e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1329 - val_precision: 0.9098 - val_recall: 0.7762 - val_pr_auc: 0.9074\n",
      "Epoch 11/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.7208e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1234 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9124\n",
      "Epoch 12/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.2165e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1250 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9137\n",
      "Epoch 13/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.3154e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1229 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9056\n",
      "Epoch 14/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7104e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1310 - val_precision: 0.8976 - val_recall: 0.7972 - val_pr_auc: 0.9147\n",
      "Epoch 15/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.4856e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1280 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9059\n",
      "Epoch 16/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9956e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1286 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.9072\n",
      "Epoch 17/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7843e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1338 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.8963\n",
      "Epoch 18/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.5798e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1360 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8961\n",
      "Epoch 19/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3827e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1402 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8921\n",
      "Epoch 20/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2154e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1401 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8961\n",
      "Epoch 21/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0737e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1402 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.8905\n",
      "Epoch 22/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0006e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1448 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8969\n",
      "Epoch 23/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.8588e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1490 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8883\n",
      "Epoch 24/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 8.1701e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1518 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8879\n",
      "Epoch 25/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.3394e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1516 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.8829\n",
      "Epoch 26/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.7012e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1535 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.8830\n",
      "Epoch 27/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.0744e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1585 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8849\n",
      "Epoch 28/38\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 5.5302e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1591 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8804\n",
      "Epoch 29/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.1681e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1588 - val_precision: 0.8976 - val_recall: 0.7972 - val_pr_auc: 0.8814\n",
      "Epoch 30/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.7246e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1555 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.8870\n",
      "Epoch 31/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.3612e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1629 - val_precision: 0.8976 - val_recall: 0.7972 - val_pr_auc: 0.8755\n",
      "Epoch 32/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.0437e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1620 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8756\n",
      "Epoch 33/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.7539e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1596 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.8836\n",
      "Epoch 34/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.4923e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1621 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.8758\n",
      "Epoch 35/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.2064e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1686 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8753\n",
      "Epoch 36/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.0044e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1680 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8751\n",
      "Epoch 37/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7661e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1690 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8717\n",
      "Epoch 38/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.6082e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1682 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8715\n",
      "23/23 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 7775, 16)          128       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 2591, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 41456)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 41457     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41585 (162.44 KB)\n",
      "Trainable params: 41585 (162.44 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 16 epochs: 42 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/42\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "426/426 [==============================] - 7s 9ms/step - loss: 0.1486 - precision: 0.7745 - recall: 0.7345 - pr_auc: 0.8109 - val_loss: 0.1080 - val_precision: 0.8559 - val_recall: 0.7063 - val_pr_auc: 0.8296\n",
      "Epoch 2/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.1806 - precision: 0.8066 - recall: 0.7625 - pr_auc: 0.8058 - val_loss: 0.0855 - val_precision: 0.7870 - val_recall: 0.9301 - val_pr_auc: 0.9366\n",
      "Epoch 3/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0474 - precision: 0.9206 - recall: 0.9233 - pr_auc: 0.9601 - val_loss: 0.0927 - val_precision: 0.8699 - val_recall: 0.7483 - val_pr_auc: 0.9120\n",
      "Epoch 4/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0285 - precision: 0.9497 - recall: 0.9469 - pr_auc: 0.9797 - val_loss: 0.0974 - val_precision: 0.9106 - val_recall: 0.7832 - val_pr_auc: 0.9243\n",
      "Epoch 5/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0292 - precision: 0.9472 - recall: 0.9528 - pr_auc: 0.9843 - val_loss: 0.1216 - val_precision: 0.9407 - val_recall: 0.7762 - val_pr_auc: 0.9165\n",
      "Epoch 6/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0352 - precision: 0.9557 - recall: 0.9543 - pr_auc: 0.9766 - val_loss: 0.4822 - val_precision: 0.9068 - val_recall: 0.7483 - val_pr_auc: 0.8140\n",
      "Epoch 7/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0548 - precision: 0.9469 - recall: 0.9469 - pr_auc: 0.9547 - val_loss: 0.1977 - val_precision: 0.8571 - val_recall: 0.7552 - val_pr_auc: 0.8445\n",
      "Epoch 8/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0124 - precision: 0.9836 - recall: 0.9735 - pr_auc: 0.9959 - val_loss: 0.2103 - val_precision: 0.8810 - val_recall: 0.7762 - val_pr_auc: 0.8400\n",
      "Epoch 9/42\n",
      "426/426 [==============================] - 3s 7ms/step - loss: 0.0086 - precision: 0.9867 - recall: 0.9882 - pr_auc: 0.9982 - val_loss: 0.2718 - val_precision: 0.8661 - val_recall: 0.6783 - val_pr_auc: 0.8164\n",
      "Epoch 10/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.2091 - precision: 0.9271 - recall: 0.9189 - pr_auc: 0.9032 - val_loss: 0.3436 - val_precision: 0.8718 - val_recall: 0.7133 - val_pr_auc: 0.7686\n",
      "Epoch 11/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0145 - precision: 0.9749 - recall: 0.9749 - pr_auc: 0.9953 - val_loss: 0.3548 - val_precision: 0.7403 - val_recall: 0.7972 - val_pr_auc: 0.7322\n",
      "Epoch 12/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 0.0015 - precision: 0.9971 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.3876 - val_precision: 0.8783 - val_recall: 0.7063 - val_pr_auc: 0.7804\n",
      "Epoch 13/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 5.7097e-04 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3100 - val_precision: 0.8333 - val_recall: 0.8042 - val_pr_auc: 0.7848\n",
      "Epoch 14/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 9.0264e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3295 - val_precision: 0.8750 - val_recall: 0.7832 - val_pr_auc: 0.7757\n",
      "Epoch 15/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 3.4905e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3089 - val_precision: 0.8507 - val_recall: 0.7972 - val_pr_auc: 0.7836\n",
      "Epoch 16/42\n",
      "426/426 [==============================] - 3s 7ms/step - loss: 1.7587e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3171 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7856\n",
      "Epoch 17/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.1850e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3194 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7814\n",
      "Epoch 18/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.0654e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3190 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7814\n",
      "Epoch 19/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 9.2787e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3164 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7873\n",
      "Epoch 20/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 8.6717e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3211 - val_precision: 0.8750 - val_recall: 0.7832 - val_pr_auc: 0.7809\n",
      "Epoch 21/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 7.3635e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3157 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7872\n",
      "Epoch 22/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 7.1310e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3178 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7872\n",
      "Epoch 23/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 6.4239e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3211 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7866\n",
      "Epoch 24/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 5.4650e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3221 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7882\n",
      "Epoch 25/42\n",
      "426/426 [==============================] - 3s 7ms/step - loss: 5.0099e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3224 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7881\n",
      "Epoch 26/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 4.6158e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3154 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.7815\n",
      "Epoch 27/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 3.9623e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3196 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7809\n",
      "Epoch 28/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 3.5589e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3227 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7767\n",
      "Epoch 29/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 3.1264e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3217 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7811\n",
      "Epoch 30/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 2.6577e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3301 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.7842\n",
      "Epoch 31/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 2.5680e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3274 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7840\n",
      "Epoch 32/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 2.1747e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3246 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7811\n",
      "Epoch 33/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.9023e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3288 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.7769\n",
      "Epoch 34/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.7319e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3297 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7712\n",
      "Epoch 35/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.4819e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3287 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7755\n",
      "Epoch 36/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.2524e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3334 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7828\n",
      "Epoch 37/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 1.0815e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3351 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7715\n",
      "Epoch 38/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 9.2062e-07 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3360 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7713\n",
      "Epoch 39/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 7.9540e-07 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3318 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.7820\n",
      "Epoch 40/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 6.7168e-07 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3396 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.7714\n",
      "Epoch 41/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 5.9140e-07 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3391 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.7715\n",
      "Epoch 42/42\n",
      "426/426 [==============================] - 3s 6ms/step - loss: 5.1503e-07 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3412 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.7727\n",
      "92/92 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 7775, 256)         2048      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 2591, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 663296)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 663297    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665345 (2.54 MB)\n",
      "Trainable params: 665345 (2.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 256 epochs: 17 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/17\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "27/27 [==============================] - 4s 60ms/step - loss: 3.8704 - precision: 0.3483 - recall: 0.4808 - pr_auc: 0.2930 - val_loss: 0.3191 - val_precision: 0.8217 - val_recall: 0.9021 - val_pr_auc: 0.8407\n",
      "Epoch 2/17\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.5303 - precision: 0.8254 - recall: 0.8156 - pr_auc: 0.7852 - val_loss: 0.3255 - val_precision: 0.8025 - val_recall: 0.9091 - val_pr_auc: 0.8148\n",
      "Epoch 3/17\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.3377 - precision: 0.8307 - recall: 0.8392 - pr_auc: 0.8117 - val_loss: 0.1840 - val_precision: 0.8857 - val_recall: 0.8671 - val_pr_auc: 0.8723\n",
      "Epoch 4/17\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.2030 - precision: 0.8544 - recall: 0.8569 - pr_auc: 0.8539 - val_loss: 0.1300 - val_precision: 0.9084 - val_recall: 0.8322 - val_pr_auc: 0.8965\n",
      "Epoch 5/17\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.1477 - precision: 0.8451 - recall: 0.8451 - pr_auc: 0.8757 - val_loss: 0.1619 - val_precision: 0.7337 - val_recall: 0.9441 - val_pr_auc: 0.8875\n",
      "Epoch 6/17\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0904 - precision: 0.8681 - recall: 0.8835 - pr_auc: 0.9179 - val_loss: 0.1046 - val_precision: 0.9120 - val_recall: 0.7972 - val_pr_auc: 0.9206\n",
      "Epoch 7/17\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1263 - precision: 0.8569 - recall: 0.8481 - pr_auc: 0.8751 - val_loss: 0.1143 - val_precision: 0.9412 - val_recall: 0.7832 - val_pr_auc: 0.9104\n",
      "Epoch 8/17\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0825 - precision: 0.8785 - recall: 0.8850 - pr_auc: 0.9323 - val_loss: 0.1762 - val_precision: 0.7458 - val_recall: 0.9231 - val_pr_auc: 0.8783\n",
      "Epoch 9/17\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0533 - precision: 0.9038 - recall: 0.9145 - pr_auc: 0.9532 - val_loss: 0.0913 - val_precision: 0.8872 - val_recall: 0.8252 - val_pr_auc: 0.9293\n",
      "Epoch 10/17\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0503 - precision: 0.8988 - recall: 0.9174 - pr_auc: 0.9598 - val_loss: 0.1567 - val_precision: 0.9691 - val_recall: 0.6573 - val_pr_auc: 0.9018\n",
      "Epoch 11/17\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0804 - precision: 0.8891 - recall: 0.8746 - pr_auc: 0.9284 - val_loss: 0.1933 - val_precision: 0.7692 - val_recall: 0.9091 - val_pr_auc: 0.8457\n",
      "Epoch 12/17\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0389 - precision: 0.9212 - recall: 0.9484 - pr_auc: 0.9753 - val_loss: 0.0865 - val_precision: 0.8561 - val_recall: 0.8322 - val_pr_auc: 0.9283\n",
      "Epoch 13/17\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0199 - precision: 0.9706 - recall: 0.9749 - pr_auc: 0.9922 - val_loss: 0.1011 - val_precision: 0.8299 - val_recall: 0.8531 - val_pr_auc: 0.9206\n",
      "Epoch 14/17\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0236 - precision: 0.9492 - recall: 0.9646 - pr_auc: 0.9910 - val_loss: 0.0991 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.9304\n",
      "Epoch 15/17\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0155 - precision: 0.9724 - recall: 0.9867 - pr_auc: 0.9971 - val_loss: 0.1073 - val_precision: 0.8357 - val_recall: 0.8182 - val_pr_auc: 0.8978\n",
      "Epoch 16/17\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.0139 - precision: 0.9795 - recall: 0.9867 - pr_auc: 0.9978 - val_loss: 0.0961 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9308\n",
      "Epoch 17/17\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.0097 - precision: 0.9868 - recall: 0.9956 - pr_auc: 0.9996 - val_loss: 0.0918 - val_precision: 0.8451 - val_recall: 0.8392 - val_pr_auc: 0.9159\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      ">0, new best f([72.30859375, 33.194580078125]) = 0.882812\n",
      ">0, new best f([162.28662109375, 33.8983154296875]) = 0.884615\n",
      ">0, new best f([56.0048828125, 37.5274658203125]) = 0.892308\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "generation0\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 2591, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 42 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/42\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.2712 - precision: 0.7309 - recall: 0.7330 - pr_auc: 0.7320 - val_loss: 0.1188 - val_precision: 0.9510 - val_recall: 0.6783 - val_pr_auc: 0.9202\n",
      "Epoch 2/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.1275 - precision: 0.8235 - recall: 0.7847 - pr_auc: 0.8416 - val_loss: 0.0892 - val_precision: 0.9464 - val_recall: 0.7413 - val_pr_auc: 0.9446\n",
      "Epoch 3/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0499 - precision: 0.8961 - recall: 0.8909 - pr_auc: 0.9615 - val_loss: 0.0652 - val_precision: 0.8514 - val_recall: 0.8811 - val_pr_auc: 0.9433\n",
      "Epoch 4/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0308 - precision: 0.9372 - recall: 0.9469 - pr_auc: 0.9865 - val_loss: 0.0830 - val_precision: 0.8898 - val_recall: 0.7343 - val_pr_auc: 0.9228\n",
      "Epoch 5/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0165 - precision: 0.9794 - recall: 0.9838 - pr_auc: 0.9964 - val_loss: 0.0815 - val_precision: 0.8750 - val_recall: 0.8322 - val_pr_auc: 0.9221\n",
      "Epoch 6/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0135 - precision: 0.9794 - recall: 0.9838 - pr_auc: 0.9954 - val_loss: 0.1182 - val_precision: 0.9298 - val_recall: 0.7413 - val_pr_auc: 0.9247\n",
      "Epoch 7/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0439 - precision: 0.9365 - recall: 0.9130 - pr_auc: 0.9682 - val_loss: 0.1484 - val_precision: 0.7866 - val_recall: 0.9021 - val_pr_auc: 0.8623\n",
      "Epoch 8/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0525 - precision: 0.9285 - recall: 0.9189 - pr_auc: 0.9642 - val_loss: 0.2857 - val_precision: 0.9535 - val_recall: 0.5734 - val_pr_auc: 0.8015\n",
      "Epoch 9/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0282 - precision: 0.9578 - recall: 0.9366 - pr_auc: 0.9851 - val_loss: 0.2188 - val_precision: 0.9143 - val_recall: 0.6713 - val_pr_auc: 0.8523\n",
      "Epoch 10/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0134 - precision: 0.9778 - recall: 0.9735 - pr_auc: 0.9940 - val_loss: 0.2452 - val_precision: 0.8473 - val_recall: 0.7762 - val_pr_auc: 0.8256\n",
      "Epoch 11/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0066 - precision: 0.9853 - recall: 0.9867 - pr_auc: 0.9993 - val_loss: 0.1795 - val_precision: 0.8025 - val_recall: 0.8811 - val_pr_auc: 0.8477\n",
      "Epoch 12/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0017 - precision: 0.9970 - recall: 0.9956 - pr_auc: 1.0000 - val_loss: 0.1588 - val_precision: 0.8440 - val_recall: 0.8322 - val_pr_auc: 0.8762\n",
      "Epoch 13/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0040 - precision: 0.9926 - recall: 0.9926 - pr_auc: 0.9997 - val_loss: 0.3561 - val_precision: 0.9255 - val_recall: 0.6084 - val_pr_auc: 0.7901\n",
      "Epoch 14/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.1923e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2178 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8350\n",
      "Epoch 15/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.9034e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2122 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.8361\n",
      "Epoch 16/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.0801e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2175 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8357\n",
      "Epoch 17/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.6709e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2173 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8360\n",
      "Epoch 18/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.6761e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2119 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8369\n",
      "Epoch 19/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.2056e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2129 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8372\n",
      "Epoch 20/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.8363e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2134 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8373\n",
      "Epoch 21/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.7259e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2135 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8375\n",
      "Epoch 22/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.1532e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2148 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8377\n",
      "Epoch 23/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.9246e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2148 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8377\n",
      "Epoch 24/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.6700e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2181 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8378\n",
      "Epoch 25/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.4336e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2192 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8380\n",
      "Epoch 26/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.2847e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2194 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8379\n",
      "Epoch 27/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.0517e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2174 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8380\n",
      "Epoch 28/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.9153e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2185 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8380\n",
      "Epoch 29/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7239e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2166 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8383\n",
      "Epoch 30/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.6336e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2240 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.8383\n",
      "Epoch 31/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.4356e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2179 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8387\n",
      "Epoch 32/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.3415e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2190 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8390\n",
      "Epoch 33/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.2185e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2235 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8384\n",
      "Epoch 34/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.1091e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2199 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8389\n",
      "Epoch 35/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.0399e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2230 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8385\n",
      "Epoch 36/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9203e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2260 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8389\n",
      "Epoch 37/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.8007e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2229 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8391\n",
      "Epoch 38/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7420e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2202 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8398\n",
      "Epoch 39/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.6420e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2213 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8394\n",
      "Epoch 40/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.5443e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2276 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8395\n",
      "Epoch 41/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.4796e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2319 - val_precision: 0.9032 - val_recall: 0.7832 - val_pr_auc: 0.8390\n",
      "Epoch 42/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.4485e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2257 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8397\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 2591, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 28 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/28\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 4s 29ms/step - loss: 1.0475 - precision: 0.6122 - recall: 0.6799 - pr_auc: 0.5436 - val_loss: 0.2413 - val_precision: 0.9407 - val_recall: 0.7762 - val_pr_auc: 0.8690\n",
      "Epoch 2/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2047 - precision: 0.8245 - recall: 0.8245 - pr_auc: 0.8445 - val_loss: 0.2778 - val_precision: 0.8288 - val_recall: 0.8462 - val_pr_auc: 0.8180\n",
      "Epoch 3/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1128 - precision: 0.8449 - recall: 0.8599 - pr_auc: 0.8923 - val_loss: 0.0647 - val_precision: 0.9173 - val_recall: 0.8531 - val_pr_auc: 0.9508\n",
      "Epoch 4/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0628 - precision: 0.8737 - recall: 0.8879 - pr_auc: 0.9360 - val_loss: 0.0679 - val_precision: 0.9431 - val_recall: 0.8112 - val_pr_auc: 0.9516\n",
      "Epoch 5/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0499 - precision: 0.9053 - recall: 0.9027 - pr_auc: 0.9625 - val_loss: 0.0743 - val_precision: 0.9127 - val_recall: 0.8042 - val_pr_auc: 0.9447\n",
      "Epoch 6/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0350 - precision: 0.9302 - recall: 0.9440 - pr_auc: 0.9836 - val_loss: 0.0604 - val_precision: 0.8815 - val_recall: 0.8322 - val_pr_auc: 0.9526\n",
      "Epoch 7/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0261 - precision: 0.9514 - recall: 0.9808 - pr_auc: 0.9862 - val_loss: 0.0759 - val_precision: 0.9322 - val_recall: 0.7692 - val_pr_auc: 0.9489\n",
      "Epoch 8/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0214 - precision: 0.9693 - recall: 0.9794 - pr_auc: 0.9955 - val_loss: 0.0687 - val_precision: 0.8714 - val_recall: 0.8531 - val_pr_auc: 0.9478\n",
      "Epoch 9/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0152 - precision: 0.9724 - recall: 0.9867 - pr_auc: 0.9978 - val_loss: 0.0756 - val_precision: 0.8523 - val_recall: 0.8881 - val_pr_auc: 0.9458\n",
      "Epoch 10/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0118 - precision: 0.9825 - recall: 0.9956 - pr_auc: 0.9985 - val_loss: 0.0896 - val_precision: 0.8871 - val_recall: 0.7692 - val_pr_auc: 0.9315\n",
      "Epoch 11/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0074 - precision: 0.9941 - recall: 1.0000 - pr_auc: 0.9998 - val_loss: 0.0841 - val_precision: 0.9113 - val_recall: 0.7902 - val_pr_auc: 0.9411\n",
      "Epoch 12/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0057 - precision: 0.9956 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.0964 - val_precision: 0.8810 - val_recall: 0.7762 - val_pr_auc: 0.9295\n",
      "Epoch 13/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0039 - precision: 0.9971 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0923 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.9346\n",
      "Epoch 14/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0029 - precision: 0.9971 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0903 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9398\n",
      "Epoch 15/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0023 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1120 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.9109\n",
      "Epoch 16/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1323 - val_precision: 0.8750 - val_recall: 0.7832 - val_pr_auc: 0.8948\n",
      "Epoch 17/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1110 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9145\n",
      "Epoch 18/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1090 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9177\n",
      "Epoch 19/28\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0010 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1123 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9146\n",
      "Epoch 20/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.7594e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1204 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9125\n",
      "Epoch 21/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.5465e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1087 - val_precision: 0.8806 - val_recall: 0.8252 - val_pr_auc: 0.9140\n",
      "Epoch 22/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7578e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1201 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9024\n",
      "Epoch 23/28\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 5.7566e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1291 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9116\n",
      "Epoch 24/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.1579e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1308 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9119\n",
      "Epoch 25/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.7633e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1219 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9034\n",
      "Epoch 26/28\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.2014e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1271 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9046\n",
      "Epoch 27/28\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9408e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1302 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8992\n",
      "Epoch 28/28\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.4843e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1303 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8992\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_9 (Conv1D)           (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 2591, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 24 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/24\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 4s 29ms/step - loss: 1.5373 - precision: 0.5129 - recall: 0.6180 - pr_auc: 0.4596 - val_loss: 0.1985 - val_precision: 0.8723 - val_recall: 0.8601 - val_pr_auc: 0.8527\n",
      "Epoch 2/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2516 - precision: 0.8133 - recall: 0.8097 - pr_auc: 0.8279 - val_loss: 0.1277 - val_precision: 0.9244 - val_recall: 0.7692 - val_pr_auc: 0.8965\n",
      "Epoch 3/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0967 - precision: 0.8538 - recall: 0.8525 - pr_auc: 0.9048 - val_loss: 0.0775 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9272\n",
      "Epoch 4/24\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0665 - precision: 0.8765 - recall: 0.8791 - pr_auc: 0.9377 - val_loss: 0.0717 - val_precision: 0.8176 - val_recall: 0.9091 - val_pr_auc: 0.9484\n",
      "Epoch 5/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0504 - precision: 0.9045 - recall: 0.9218 - pr_auc: 0.9555 - val_loss: 0.0648 - val_precision: 0.8487 - val_recall: 0.9021 - val_pr_auc: 0.9446\n",
      "Epoch 6/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0448 - precision: 0.9101 - recall: 0.9263 - pr_auc: 0.9675 - val_loss: 0.0750 - val_precision: 0.8075 - val_recall: 0.9091 - val_pr_auc: 0.9260\n",
      "Epoch 7/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0346 - precision: 0.9401 - recall: 0.9499 - pr_auc: 0.9823 - val_loss: 0.0921 - val_precision: 0.8732 - val_recall: 0.8671 - val_pr_auc: 0.9289\n",
      "Epoch 8/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0257 - precision: 0.9563 - recall: 0.9690 - pr_auc: 0.9912 - val_loss: 0.0674 - val_precision: 0.8889 - val_recall: 0.8392 - val_pr_auc: 0.9470\n",
      "Epoch 9/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0172 - precision: 0.9724 - recall: 0.9882 - pr_auc: 0.9968 - val_loss: 0.0705 - val_precision: 0.8356 - val_recall: 0.8531 - val_pr_auc: 0.9460\n",
      "Epoch 10/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0179 - precision: 0.9781 - recall: 0.9867 - pr_auc: 0.9955 - val_loss: 0.0750 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9420\n",
      "Epoch 11/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0103 - precision: 0.9883 - recall: 0.9971 - pr_auc: 0.9996 - val_loss: 0.0831 - val_precision: 0.8759 - val_recall: 0.8392 - val_pr_auc: 0.9324\n",
      "Epoch 12/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0076 - precision: 0.9956 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.0897 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9327\n",
      "Epoch 13/24\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0058 - precision: 0.9956 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.0809 - val_precision: 0.8806 - val_recall: 0.8252 - val_pr_auc: 0.9349\n",
      "Epoch 14/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0045 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1063 - val_precision: 0.8740 - val_recall: 0.7762 - val_pr_auc: 0.8995\n",
      "Epoch 15/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0039 - precision: 1.0000 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.0948 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9325\n",
      "Epoch 16/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0029 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0960 - val_precision: 0.8741 - val_recall: 0.8252 - val_pr_auc: 0.9178\n",
      "Epoch 17/24\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0023 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1067 - val_precision: 0.8768 - val_recall: 0.8462 - val_pr_auc: 0.9099\n",
      "Epoch 18/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0019 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1186 - val_precision: 0.8750 - val_recall: 0.7832 - val_pr_auc: 0.9054\n",
      "Epoch 19/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1153 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.9078\n",
      "Epoch 20/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1177 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.9074\n",
      "Epoch 21/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1066 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.9155\n",
      "Epoch 22/24\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1169 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9100\n",
      "Epoch 23/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1191 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.9108\n",
      "Epoch 24/24\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0024 - precision: 0.9985 - recall: 0.9956 - pr_auc: 1.0000 - val_loss: 0.1170 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8959\n",
      "12/12 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 7775, 256)         2048      \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 2591, 256)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 663296)            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 663297    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 665345 (2.54 MB)\n",
      "Trainable params: 665345 (2.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 256 epochs: 48 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/48\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "27/27 [==============================] - 4s 63ms/step - loss: 5.4035 - precision: 0.2885 - recall: 0.3894 - pr_auc: 0.2164 - val_loss: 0.6868 - val_precision: 0.7445 - val_recall: 0.7133 - val_pr_auc: 0.6441\n",
      "Epoch 2/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.7132 - precision: 0.7997 - recall: 0.8245 - pr_auc: 0.7603 - val_loss: 0.3252 - val_precision: 0.9070 - val_recall: 0.8182 - val_pr_auc: 0.8260\n",
      "Epoch 3/48\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.3799 - precision: 0.8331 - recall: 0.8392 - pr_auc: 0.7971 - val_loss: 0.2637 - val_precision: 0.8049 - val_recall: 0.9231 - val_pr_auc: 0.8286\n",
      "Epoch 4/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.2319 - precision: 0.8468 - recall: 0.8643 - pr_auc: 0.8399 - val_loss: 0.2695 - val_precision: 0.9429 - val_recall: 0.6923 - val_pr_auc: 0.8377\n",
      "Epoch 5/48\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.2446 - precision: 0.8182 - recall: 0.8230 - pr_auc: 0.8178 - val_loss: 0.1460 - val_precision: 0.8913 - val_recall: 0.8601 - val_pr_auc: 0.8875\n",
      "Epoch 6/48\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.1393 - precision: 0.8574 - recall: 0.8510 - pr_auc: 0.8885 - val_loss: 0.1268 - val_precision: 0.9496 - val_recall: 0.7902 - val_pr_auc: 0.9089\n",
      "Epoch 7/48\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0905 - precision: 0.8745 - recall: 0.8835 - pr_auc: 0.9244 - val_loss: 0.1049 - val_precision: 0.9492 - val_recall: 0.7832 - val_pr_auc: 0.9265\n",
      "Epoch 8/48\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0630 - precision: 0.8869 - recall: 0.8791 - pr_auc: 0.9413 - val_loss: 0.0832 - val_precision: 0.8897 - val_recall: 0.8462 - val_pr_auc: 0.9342\n",
      "Epoch 9/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0445 - precision: 0.9200 - recall: 0.9159 - pr_auc: 0.9619 - val_loss: 0.1099 - val_precision: 0.7831 - val_recall: 0.9091 - val_pr_auc: 0.9079\n",
      "Epoch 10/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0354 - precision: 0.9234 - recall: 0.9425 - pr_auc: 0.9756 - val_loss: 0.0877 - val_precision: 0.8182 - val_recall: 0.8811 - val_pr_auc: 0.9282\n",
      "Epoch 11/48\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.0305 - precision: 0.9289 - recall: 0.9440 - pr_auc: 0.9844 - val_loss: 0.1042 - val_precision: 0.9106 - val_recall: 0.7832 - val_pr_auc: 0.9194\n",
      "Epoch 12/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0308 - precision: 0.9294 - recall: 0.9513 - pr_auc: 0.9838 - val_loss: 0.0868 - val_precision: 0.9127 - val_recall: 0.8042 - val_pr_auc: 0.9427\n",
      "Epoch 13/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0243 - precision: 0.9632 - recall: 0.9646 - pr_auc: 0.9883 - val_loss: 0.0876 - val_precision: 0.9048 - val_recall: 0.7972 - val_pr_auc: 0.9422\n",
      "Epoch 14/48\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0170 - precision: 0.9710 - recall: 0.9882 - pr_auc: 0.9962 - val_loss: 0.0895 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9218\n",
      "Epoch 15/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0158 - precision: 0.9739 - recall: 0.9912 - pr_auc: 0.9979 - val_loss: 0.0961 - val_precision: 0.9008 - val_recall: 0.7622 - val_pr_auc: 0.9309\n",
      "Epoch 16/48\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0165 - precision: 0.9779 - recall: 0.9808 - pr_auc: 0.9978 - val_loss: 0.0873 - val_precision: 0.8623 - val_recall: 0.8322 - val_pr_auc: 0.9174\n",
      "Epoch 17/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0124 - precision: 0.9839 - recall: 0.9912 - pr_auc: 0.9986 - val_loss: 0.1057 - val_precision: 0.8613 - val_recall: 0.8252 - val_pr_auc: 0.9017\n",
      "Epoch 18/48\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0107 - precision: 0.9810 - recall: 0.9926 - pr_auc: 0.9993 - val_loss: 0.0996 - val_precision: 0.8657 - val_recall: 0.8112 - val_pr_auc: 0.9026\n",
      "Epoch 19/48\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0086 - precision: 0.9912 - recall: 1.0000 - pr_auc: 0.9997 - val_loss: 0.0936 - val_precision: 0.8561 - val_recall: 0.8322 - val_pr_auc: 0.9168\n",
      "Epoch 20/48\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0074 - precision: 0.9941 - recall: 1.0000 - pr_auc: 0.9999 - val_loss: 0.1091 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.8990\n",
      "Epoch 21/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0068 - precision: 0.9927 - recall: 1.0000 - pr_auc: 0.9999 - val_loss: 0.1069 - val_precision: 0.8478 - val_recall: 0.8182 - val_pr_auc: 0.9031\n",
      "Epoch 22/48\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.0063 - precision: 0.9941 - recall: 1.0000 - pr_auc: 0.9999 - val_loss: 0.0934 - val_precision: 0.8403 - val_recall: 0.8462 - val_pr_auc: 0.9168\n",
      "Epoch 23/48\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 0.0101 - precision: 0.9882 - recall: 0.9882 - pr_auc: 0.9990 - val_loss: 0.0983 - val_precision: 0.8582 - val_recall: 0.8042 - val_pr_auc: 0.9315\n",
      "Epoch 24/48\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0111 - precision: 0.9853 - recall: 0.9912 - pr_auc: 0.9979 - val_loss: 0.0968 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9264\n",
      "Epoch 25/48\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0049 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1050 - val_precision: 0.8593 - val_recall: 0.8112 - val_pr_auc: 0.9075\n",
      "Epoch 26/48\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.0037 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1090 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9057\n",
      "Epoch 27/48\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 0.0033 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1119 - val_precision: 0.8647 - val_recall: 0.8042 - val_pr_auc: 0.9033\n",
      "Epoch 28/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0031 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1099 - val_precision: 0.8561 - val_recall: 0.8322 - val_pr_auc: 0.9097\n",
      "Epoch 29/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0028 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1191 - val_precision: 0.8647 - val_recall: 0.8042 - val_pr_auc: 0.9012\n",
      "Epoch 30/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0026 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1213 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8996\n",
      "Epoch 31/48\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0022 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1208 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9013\n",
      "Epoch 32/48\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1227 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.9011\n",
      "Epoch 33/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0019 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1207 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9023\n",
      "Epoch 34/48\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1340 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9014\n",
      "Epoch 35/48\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1333 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9025\n",
      "Epoch 36/48\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1266 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8985\n",
      "Epoch 37/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1308 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.9025\n",
      "Epoch 38/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1339 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9027\n",
      "Epoch 39/48\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1381 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9040\n",
      "Epoch 40/48\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1401 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.8989\n",
      "Epoch 41/48\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.0010 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1331 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9035\n",
      "Epoch 42/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 9.6933e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1422 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9001\n",
      "Epoch 43/48\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 9.1860e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1426 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.8956\n",
      "Epoch 44/48\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 8.7846e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1423 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9004\n",
      "Epoch 45/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 8.2527e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1410 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8973\n",
      "Epoch 46/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 7.7576e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1433 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9002\n",
      "Epoch 47/48\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 7.5139e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1399 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8972\n",
      "Epoch 48/48\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 6.9996e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1479 - val_precision: 0.8760 - val_recall: 0.7902 - val_pr_auc: 0.8971\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 38 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/38\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 16ms/step - loss: 0.4936 - precision: 0.7030 - recall: 0.7227 - pr_auc: 0.6440 - val_loss: 0.0978 - val_precision: 0.8239 - val_recall: 0.9161 - val_pr_auc: 0.9156\n",
      "Epoch 2/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0789 - precision: 0.8499 - recall: 0.8599 - pr_auc: 0.9129 - val_loss: 0.0823 - val_precision: 0.9487 - val_recall: 0.7762 - val_pr_auc: 0.9436\n",
      "Epoch 3/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0563 - precision: 0.8936 - recall: 0.9041 - pr_auc: 0.9473 - val_loss: 0.0659 - val_precision: 0.8188 - val_recall: 0.9161 - val_pr_auc: 0.9533\n",
      "Epoch 4/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0402 - precision: 0.9171 - recall: 0.9469 - pr_auc: 0.9721 - val_loss: 0.0811 - val_precision: 0.9120 - val_recall: 0.7972 - val_pr_auc: 0.9282\n",
      "Epoch 5/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0326 - precision: 0.9362 - recall: 0.9528 - pr_auc: 0.9805 - val_loss: 0.0898 - val_precision: 0.9316 - val_recall: 0.7622 - val_pr_auc: 0.9292\n",
      "Epoch 6/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0185 - precision: 0.9751 - recall: 0.9823 - pr_auc: 0.9960 - val_loss: 0.0754 - val_precision: 0.8581 - val_recall: 0.8881 - val_pr_auc: 0.9334\n",
      "Epoch 7/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0095 - precision: 0.9897 - recall: 0.9926 - pr_auc: 0.9996 - val_loss: 0.0758 - val_precision: 0.8872 - val_recall: 0.8252 - val_pr_auc: 0.9330\n",
      "Epoch 8/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0065 - precision: 0.9927 - recall: 0.9971 - pr_auc: 0.9998 - val_loss: 0.1151 - val_precision: 0.8974 - val_recall: 0.7343 - val_pr_auc: 0.8966\n",
      "Epoch 9/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0059 - precision: 0.9912 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.0777 - val_precision: 0.8750 - val_recall: 0.7832 - val_pr_auc: 0.9436\n",
      "Epoch 10/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0031 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1100 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.9182\n",
      "Epoch 11/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0020 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1169 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9177\n",
      "Epoch 12/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1108 - val_precision: 0.8636 - val_recall: 0.7972 - val_pr_auc: 0.9167\n",
      "Epoch 13/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0010 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1095 - val_precision: 0.8667 - val_recall: 0.8182 - val_pr_auc: 0.9196\n",
      "Epoch 14/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.6230e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1168 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9194\n",
      "Epoch 15/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.6544e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1252 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9165\n",
      "Epoch 16/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.9168e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1232 - val_precision: 0.8647 - val_recall: 0.8042 - val_pr_auc: 0.9135\n",
      "Epoch 17/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.9975e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1285 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9135\n",
      "Epoch 18/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.6726e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1331 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.9066\n",
      "Epoch 19/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.9891e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1350 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.9135\n",
      "Epoch 20/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.6578e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1401 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8979\n",
      "Epoch 21/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.2996e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1430 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8986\n",
      "Epoch 22/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.0454e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1444 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8983\n",
      "Epoch 23/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.8140e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1491 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8985\n",
      "Epoch 24/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.6525e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1536 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8947\n",
      "Epoch 25/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.5749e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1471 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8861\n",
      "Epoch 26/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.3232e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1521 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8820\n",
      "Epoch 27/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2103e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1528 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8861\n",
      "Epoch 28/38\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 1.0912e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1612 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8814\n",
      "Epoch 29/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0036e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1563 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8826\n",
      "Epoch 30/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.2452e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1585 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8765\n",
      "Epoch 31/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.4918e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1606 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8827\n",
      "Epoch 32/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.6670e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1615 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8829\n",
      "Epoch 33/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.0063e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1627 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8729\n",
      "Epoch 34/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.6408e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1626 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8776\n",
      "Epoch 35/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 6.1359e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1622 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8768\n",
      "Epoch 36/38\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.5653e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1647 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8728\n",
      "Epoch 37/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.3499e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1655 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8779\n",
      "Epoch 38/38\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.7398e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1722 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8715\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3256 - precision: 0.7169 - recall: 0.7655 - pr_auc: 0.7277 - val_loss: 0.1387 - val_precision: 0.9457 - val_recall: 0.6084 - val_pr_auc: 0.8989\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0827 - precision: 0.8505 - recall: 0.8643 - pr_auc: 0.9131 - val_loss: 0.0647 - val_precision: 0.9077 - val_recall: 0.8252 - val_pr_auc: 0.9436\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0610 - precision: 0.8963 - recall: 0.8540 - pr_auc: 0.9441 - val_loss: 0.0871 - val_precision: 0.8355 - val_recall: 0.8881 - val_pr_auc: 0.9341\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0332 - precision: 0.9331 - recall: 0.9469 - pr_auc: 0.9818 - val_loss: 0.0696 - val_precision: 0.9316 - val_recall: 0.7622 - val_pr_auc: 0.9495\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0188 - precision: 0.9652 - recall: 0.9823 - pr_auc: 0.9961 - val_loss: 0.0747 - val_precision: 0.8077 - val_recall: 0.8811 - val_pr_auc: 0.9310\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0135 - precision: 0.9780 - recall: 0.9838 - pr_auc: 0.9981 - val_loss: 0.0855 - val_precision: 0.8435 - val_recall: 0.8671 - val_pr_auc: 0.9211\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0058 - precision: 0.9927 - recall: 0.9971 - pr_auc: 0.9998 - val_loss: 0.0869 - val_precision: 0.8824 - val_recall: 0.8392 - val_pr_auc: 0.9317\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0030 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0934 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9436\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0016 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0911 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9378\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0015 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1060 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9267\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.5649e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1063 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9317\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.7746e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1163 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9234\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.6299e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1158 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9174\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.7326e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1201 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9166\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.1439e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1243 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9176\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.6924e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1221 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9185\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.3900e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1286 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9176\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.9596e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1284 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9113\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7498e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1299 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9048\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.5567e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1322 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9046\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.4288e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1365 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9035\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2343e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1391 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9006\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1194e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1379 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8947\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0194e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1397 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9010\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.2492e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1393 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8991\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.4157e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1399 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8989\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.6944e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1484 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8966\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 6.9060e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1478 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8967\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 6.3837e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1478 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8905\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.7906e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1528 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8866\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.5219e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1517 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8907\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.9764e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1507 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8906\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.5742e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1539 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8909\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      ">1, new best f([56.0048828125, 32.5225830078125]) = 0.896825\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "generation1\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_13 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.2664 - precision: 0.7519 - recall: 0.7375 - pr_auc: 0.7319 - val_loss: 0.0764 - val_precision: 0.8741 - val_recall: 0.8741 - val_pr_auc: 0.9422\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0791 - precision: 0.8676 - recall: 0.8407 - pr_auc: 0.9138 - val_loss: 0.0779 - val_precision: 0.8366 - val_recall: 0.8951 - val_pr_auc: 0.9419\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0480 - precision: 0.9003 - recall: 0.9189 - pr_auc: 0.9581 - val_loss: 0.0716 - val_precision: 0.9369 - val_recall: 0.7273 - val_pr_auc: 0.9377\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0339 - precision: 0.9365 - recall: 0.9351 - pr_auc: 0.9814 - val_loss: 0.0975 - val_precision: 0.7714 - val_recall: 0.9441 - val_pr_auc: 0.9278\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.1439 - precision: 0.8925 - recall: 0.8938 - pr_auc: 0.8893 - val_loss: 0.4419 - val_precision: 0.9153 - val_recall: 0.7552 - val_pr_auc: 0.8186\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.4747 - precision: 0.8287 - recall: 0.7994 - pr_auc: 0.7727 - val_loss: 0.3555 - val_precision: 0.8777 - val_recall: 0.8531 - val_pr_auc: 0.8565\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0775 - precision: 0.9372 - recall: 0.9248 - pr_auc: 0.9571 - val_loss: 0.2064 - val_precision: 0.8931 - val_recall: 0.8182 - val_pr_auc: 0.8612\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0124 - precision: 0.9794 - recall: 0.9808 - pr_auc: 0.9941 - val_loss: 0.2069 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.8684\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0046 - precision: 0.9897 - recall: 0.9897 - pr_auc: 0.9997 - val_loss: 0.2094 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8608\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0013 - precision: 0.9971 - recall: 0.9971 - pr_auc: 1.0000 - val_loss: 0.2079 - val_precision: 0.8623 - val_recall: 0.8322 - val_pr_auc: 0.8571\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.9100e-04 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2437 - val_precision: 0.8974 - val_recall: 0.7343 - val_pr_auc: 0.8524\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.3036e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2246 - val_precision: 0.8583 - val_recall: 0.7622 - val_pr_auc: 0.8513\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9487e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2176 - val_precision: 0.8636 - val_recall: 0.7972 - val_pr_auc: 0.8543\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9055e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2204 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8534\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.4655e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2213 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8534\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3075e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2231 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8536\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.1864e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2244 - val_precision: 0.8605 - val_recall: 0.7762 - val_pr_auc: 0.8536\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0770e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2288 - val_precision: 0.8594 - val_recall: 0.7692 - val_pr_auc: 0.8435\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.7436e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2258 - val_precision: 0.8605 - val_recall: 0.7762 - val_pr_auc: 0.8490\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 9.3484e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2248 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8539\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.8243e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2224 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.8539\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.9475e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2239 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8542\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.4981e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2221 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.8556\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.0546e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2271 - val_precision: 0.8605 - val_recall: 0.7762 - val_pr_auc: 0.8538\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.8289e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2267 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8538\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.3054e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2275 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8538\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.7731e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2237 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.8559\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 5.7513e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2305 - val_precision: 0.8672 - val_recall: 0.7762 - val_pr_auc: 0.8453\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.3264e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2268 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8545\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.0862e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2267 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.8545\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.8051e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2284 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8541\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.5047e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2275 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.8554\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.3751e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2297 - val_precision: 0.8615 - val_recall: 0.7832 - val_pr_auc: 0.8499\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 42 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/42\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3164 - precision: 0.7277 - recall: 0.7684 - pr_auc: 0.7152 - val_loss: 0.0751 - val_precision: 0.9328 - val_recall: 0.7762 - val_pr_auc: 0.9451\n",
      "Epoch 2/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0868 - precision: 0.8606 - recall: 0.8466 - pr_auc: 0.9017 - val_loss: 0.0644 - val_precision: 0.8302 - val_recall: 0.9231 - val_pr_auc: 0.9427\n",
      "Epoch 3/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0603 - precision: 0.8838 - recall: 0.8864 - pr_auc: 0.9410 - val_loss: 0.0709 - val_precision: 0.9030 - val_recall: 0.8462 - val_pr_auc: 0.9460\n",
      "Epoch 4/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0413 - precision: 0.9232 - recall: 0.9218 - pr_auc: 0.9705 - val_loss: 0.0764 - val_precision: 0.8889 - val_recall: 0.8392 - val_pr_auc: 0.9377\n",
      "Epoch 5/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0297 - precision: 0.9481 - recall: 0.9440 - pr_auc: 0.9851 - val_loss: 0.0824 - val_precision: 0.8086 - val_recall: 0.9161 - val_pr_auc: 0.9420\n",
      "Epoch 6/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0176 - precision: 0.9722 - recall: 0.9808 - pr_auc: 0.9945 - val_loss: 0.1216 - val_precision: 0.9138 - val_recall: 0.7413 - val_pr_auc: 0.8883\n",
      "Epoch 7/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0082 - precision: 0.9883 - recall: 0.9956 - pr_auc: 0.9993 - val_loss: 0.1010 - val_precision: 0.8462 - val_recall: 0.7692 - val_pr_auc: 0.8937\n",
      "Epoch 8/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0035 - precision: 0.9941 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1052 - val_precision: 0.9008 - val_recall: 0.7622 - val_pr_auc: 0.9332\n",
      "Epoch 9/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0028 - precision: 0.9971 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1122 - val_precision: 0.8731 - val_recall: 0.8182 - val_pr_auc: 0.9125\n",
      "Epoch 10/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1203 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9108\n",
      "Epoch 11/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.4566e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1243 - val_precision: 0.9008 - val_recall: 0.7622 - val_pr_auc: 0.9142\n",
      "Epoch 12/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.8145e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1265 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.9130\n",
      "Epoch 13/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.5049e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1281 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.9151\n",
      "Epoch 14/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.9132e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1284 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9088\n",
      "Epoch 15/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.1281e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1372 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9111\n",
      "Epoch 16/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.5574e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1358 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.9084\n",
      "Epoch 17/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.2824e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1409 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.9077\n",
      "Epoch 18/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9821e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1459 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9059\n",
      "Epoch 19/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7814e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1496 - val_precision: 0.8880 - val_recall: 0.7762 - val_pr_auc: 0.8989\n",
      "Epoch 20/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.5283e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1428 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9059\n",
      "Epoch 21/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.4047e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1476 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.9013\n",
      "Epoch 22/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.2539e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1509 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.8921\n",
      "Epoch 23/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1649e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1564 - val_precision: 0.8880 - val_recall: 0.7762 - val_pr_auc: 0.8810\n",
      "Epoch 24/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0308e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1556 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.8829\n",
      "Epoch 25/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 9.1020e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1553 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.8829\n",
      "Epoch 26/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.4565e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1503 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8889\n",
      "Epoch 27/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.7993e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1571 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8854\n",
      "Epoch 28/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 7.0415e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1624 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.8742\n",
      "Epoch 29/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.4415e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1590 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.8858\n",
      "Epoch 30/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.8657e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1654 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.8739\n",
      "Epoch 31/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.4534e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1619 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8822\n",
      "Epoch 32/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.0852e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1657 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8735\n",
      "Epoch 33/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.7235e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1639 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8777\n",
      "Epoch 34/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.3829e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1743 - val_precision: 0.8934 - val_recall: 0.7622 - val_pr_auc: 0.8713\n",
      "Epoch 35/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.0472e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1722 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.8697\n",
      "Epoch 36/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.7668e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1701 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8688\n",
      "Epoch 37/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.4774e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1748 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8699\n",
      "Epoch 38/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.2164e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1721 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8698\n",
      "Epoch 39/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.9656e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1735 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8693\n",
      "Epoch 40/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7337e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1721 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8696\n",
      "Epoch 41/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.5992e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1776 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.8654\n",
      "Epoch 42/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.4286e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1803 - val_precision: 0.8889 - val_recall: 0.7832 - val_pr_auc: 0.8661\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 4s 30ms/step - loss: 1.4489 - precision: 0.5037 - recall: 0.5988 - pr_auc: 0.4427 - val_loss: 0.1816 - val_precision: 0.9167 - val_recall: 0.7692 - val_pr_auc: 0.8717\n",
      "Epoch 2/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.1519 - precision: 0.8268 - recall: 0.8378 - pr_auc: 0.8647 - val_loss: 0.1558 - val_precision: 0.9375 - val_recall: 0.7343 - val_pr_auc: 0.9048\n",
      "Epoch 3/33\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1130 - precision: 0.8338 - recall: 0.8142 - pr_auc: 0.8858 - val_loss: 0.2051 - val_precision: 0.8286 - val_recall: 0.8112 - val_pr_auc: 0.8341\n",
      "Epoch 4/33\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0772 - precision: 0.8828 - recall: 0.8997 - pr_auc: 0.9327 - val_loss: 0.0667 - val_precision: 0.9291 - val_recall: 0.8252 - val_pr_auc: 0.9512\n",
      "Epoch 5/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0511 - precision: 0.8980 - recall: 0.9086 - pr_auc: 0.9563 - val_loss: 0.0733 - val_precision: 0.8939 - val_recall: 0.8252 - val_pr_auc: 0.9450\n",
      "Epoch 6/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0404 - precision: 0.9259 - recall: 0.9395 - pr_auc: 0.9725 - val_loss: 0.0934 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9151\n",
      "Epoch 7/33\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0297 - precision: 0.9518 - recall: 0.9617 - pr_auc: 0.9822 - val_loss: 0.1015 - val_precision: 0.8105 - val_recall: 0.8671 - val_pr_auc: 0.8773\n",
      "Epoch 8/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0296 - precision: 0.9461 - recall: 0.9587 - pr_auc: 0.9841 - val_loss: 0.0676 - val_precision: 0.9077 - val_recall: 0.8252 - val_pr_auc: 0.9460\n",
      "Epoch 9/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0163 - precision: 0.9754 - recall: 0.9941 - pr_auc: 0.9979 - val_loss: 0.0670 - val_precision: 0.8759 - val_recall: 0.8392 - val_pr_auc: 0.9478\n",
      "Epoch 10/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0131 - precision: 0.9825 - recall: 0.9912 - pr_auc: 0.9991 - val_loss: 0.0811 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9336\n",
      "Epoch 11/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0087 - precision: 0.9912 - recall: 0.9971 - pr_auc: 0.9998 - val_loss: 0.0807 - val_precision: 0.8939 - val_recall: 0.8252 - val_pr_auc: 0.9426\n",
      "Epoch 12/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0073 - precision: 0.9898 - recall: 0.9985 - pr_auc: 0.9999 - val_loss: 0.0988 - val_precision: 0.8819 - val_recall: 0.7832 - val_pr_auc: 0.9240\n",
      "Epoch 13/33\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0061 - precision: 0.9971 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.0994 - val_precision: 0.8613 - val_recall: 0.8252 - val_pr_auc: 0.9070\n",
      "Epoch 14/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0040 - precision: 0.9971 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1123 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9050\n",
      "Epoch 15/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0034 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1053 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9200\n",
      "Epoch 16/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0025 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1081 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9046\n",
      "Epoch 17/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0120 - precision: 0.9809 - recall: 0.9853 - pr_auc: 0.9959 - val_loss: 0.1115 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9254\n",
      "Epoch 18/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0060 - precision: 0.9912 - recall: 0.9941 - pr_auc: 0.9988 - val_loss: 0.1073 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9063\n",
      "Epoch 19/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0019 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1055 - val_precision: 0.8593 - val_recall: 0.8112 - val_pr_auc: 0.9113\n",
      "Epoch 20/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1175 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9115\n",
      "Epoch 21/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1028 - val_precision: 0.7974 - val_recall: 0.8531 - val_pr_auc: 0.9202\n",
      "Epoch 22/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0029 - precision: 0.9985 - recall: 0.9971 - pr_auc: 1.0000 - val_loss: 0.1271 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8897\n",
      "Epoch 23/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 9.3246e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1210 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9058\n",
      "Epoch 24/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.3893e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1254 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.8987\n",
      "Epoch 25/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2920e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1264 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9063\n",
      "Epoch 26/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.6444e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1289 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8986\n",
      "Epoch 27/33\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.9405e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1373 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8917\n",
      "Epoch 28/33\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.4524e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1359 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8930\n",
      "Epoch 29/33\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.0481e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1364 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9008\n",
      "Epoch 30/33\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 3.7054e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1359 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9018\n",
      "Epoch 31/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.4140e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1351 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9012\n",
      "Epoch 32/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1678e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1412 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.8892\n",
      "Epoch 33/33\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.8945e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1417 - val_precision: 0.8731 - val_recall: 0.8182 - val_pr_auc: 0.8899\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_16 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 23 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/23\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3003 - precision: 0.7243 - recall: 0.7168 - pr_auc: 0.7102 - val_loss: 0.1083 - val_precision: 0.9268 - val_recall: 0.7972 - val_pr_auc: 0.9207\n",
      "Epoch 2/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0892 - precision: 0.8619 - recall: 0.8378 - pr_auc: 0.8882 - val_loss: 0.1936 - val_precision: 0.9623 - val_recall: 0.3566 - val_pr_auc: 0.8945\n",
      "Epoch 3/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0671 - precision: 0.8787 - recall: 0.8658 - pr_auc: 0.9191 - val_loss: 0.0818 - val_precision: 0.7917 - val_recall: 0.9301 - val_pr_auc: 0.9278\n",
      "Epoch 4/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0370 - precision: 0.9204 - recall: 0.9381 - pr_auc: 0.9787 - val_loss: 0.0755 - val_precision: 0.8012 - val_recall: 0.9021 - val_pr_auc: 0.9404\n",
      "Epoch 5/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0180 - precision: 0.9679 - recall: 0.9779 - pr_auc: 0.9967 - val_loss: 0.0767 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9368\n",
      "Epoch 6/23\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0085 - precision: 0.9825 - recall: 0.9941 - pr_auc: 0.9992 - val_loss: 0.1089 - val_precision: 0.9035 - val_recall: 0.7203 - val_pr_auc: 0.9058\n",
      "Epoch 7/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0056 - precision: 0.9956 - recall: 1.0000 - pr_auc: 0.9999 - val_loss: 0.0944 - val_precision: 0.8442 - val_recall: 0.9091 - val_pr_auc: 0.9128\n",
      "Epoch 8/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0083 - precision: 0.9868 - recall: 0.9897 - pr_auc: 0.9992 - val_loss: 0.0844 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9422\n",
      "Epoch 9/23\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0032 - precision: 0.9941 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1141 - val_precision: 0.8872 - val_recall: 0.8252 - val_pr_auc: 0.9056\n",
      "Epoch 10/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0045 - precision: 0.9941 - recall: 0.9926 - pr_auc: 0.9999 - val_loss: 0.1180 - val_precision: 0.8696 - val_recall: 0.8392 - val_pr_auc: 0.8893\n",
      "Epoch 11/23\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0035 - precision: 0.9941 - recall: 0.9971 - pr_auc: 0.9980 - val_loss: 0.1733 - val_precision: 0.8814 - val_recall: 0.7273 - val_pr_auc: 0.8477\n",
      "Epoch 12/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.3847 - precision: 0.8520 - recall: 0.8407 - pr_auc: 0.8233 - val_loss: 0.5078 - val_precision: 0.9500 - val_recall: 0.6643 - val_pr_auc: 0.7872\n",
      "Epoch 13/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0733 - precision: 0.9506 - recall: 0.9366 - pr_auc: 0.9513 - val_loss: 0.4858 - val_precision: 0.9519 - val_recall: 0.6923 - val_pr_auc: 0.7691\n",
      "Epoch 14/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0189 - precision: 0.9778 - recall: 0.9749 - pr_auc: 0.9874 - val_loss: 0.2640 - val_precision: 0.8603 - val_recall: 0.8182 - val_pr_auc: 0.8399\n",
      "Epoch 15/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0043 - precision: 0.9926 - recall: 0.9897 - pr_auc: 0.9998 - val_loss: 0.2916 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.8292\n",
      "Epoch 16/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0015 - precision: 0.9941 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.2942 - val_precision: 0.8934 - val_recall: 0.7622 - val_pr_auc: 0.8260\n",
      "Epoch 17/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0023 - precision: 0.9971 - recall: 0.9971 - pr_auc: 0.9984 - val_loss: 0.2812 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8398\n",
      "Epoch 18/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.4789e-04 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2781 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.8303\n",
      "Epoch 19/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.3920e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2994 - val_precision: 0.8810 - val_recall: 0.7762 - val_pr_auc: 0.8263\n",
      "Epoch 20/23\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.1886e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2935 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8215\n",
      "Epoch 21/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.9131e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2938 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.8216\n",
      "Epoch 22/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.5905e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2910 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8249\n",
      "Epoch 23/23\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.4155e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2913 - val_precision: 0.8702 - val_recall: 0.7972 - val_pr_auc: 0.8207\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_17 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 25 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/25\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 4s 30ms/step - loss: 1.7255 - precision: 0.4876 - recall: 0.6106 - pr_auc: 0.4393 - val_loss: 0.2913 - val_precision: 0.9320 - val_recall: 0.6713 - val_pr_auc: 0.8008\n",
      "Epoch 2/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2709 - precision: 0.8125 - recall: 0.8053 - pr_auc: 0.8119 - val_loss: 0.1229 - val_precision: 0.8421 - val_recall: 0.8951 - val_pr_auc: 0.8993\n",
      "Epoch 3/25\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1034 - precision: 0.8370 - recall: 0.8481 - pr_auc: 0.8935 - val_loss: 0.0874 - val_precision: 0.9134 - val_recall: 0.8112 - val_pr_auc: 0.9313\n",
      "Epoch 4/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0693 - precision: 0.8724 - recall: 0.8673 - pr_auc: 0.9315 - val_loss: 0.0803 - val_precision: 0.7907 - val_recall: 0.9510 - val_pr_auc: 0.9321\n",
      "Epoch 5/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0498 - precision: 0.8970 - recall: 0.9115 - pr_auc: 0.9602 - val_loss: 0.0708 - val_precision: 0.8165 - val_recall: 0.9021 - val_pr_auc: 0.9449\n",
      "Epoch 6/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0397 - precision: 0.9294 - recall: 0.9322 - pr_auc: 0.9747 - val_loss: 0.0923 - val_precision: 0.9528 - val_recall: 0.7063 - val_pr_auc: 0.9487\n",
      "Epoch 7/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0414 - precision: 0.9303 - recall: 0.9248 - pr_auc: 0.9716 - val_loss: 0.0673 - val_precision: 0.9280 - val_recall: 0.8112 - val_pr_auc: 0.9453\n",
      "Epoch 8/25\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0266 - precision: 0.9518 - recall: 0.9617 - pr_auc: 0.9907 - val_loss: 0.0681 - val_precision: 0.9147 - val_recall: 0.8252 - val_pr_auc: 0.9469\n",
      "Epoch 9/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0188 - precision: 0.9668 - recall: 0.9882 - pr_auc: 0.9975 - val_loss: 0.0712 - val_precision: 0.8897 - val_recall: 0.8462 - val_pr_auc: 0.9436\n",
      "Epoch 10/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0132 - precision: 0.9840 - recall: 0.9956 - pr_auc: 0.9991 - val_loss: 0.0803 - val_precision: 0.8806 - val_recall: 0.8252 - val_pr_auc: 0.9408\n",
      "Epoch 11/25\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0111 - precision: 0.9825 - recall: 0.9941 - pr_auc: 0.9994 - val_loss: 0.0889 - val_precision: 0.9016 - val_recall: 0.7692 - val_pr_auc: 0.9353\n",
      "Epoch 12/25\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0081 - precision: 0.9927 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.0919 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.9325\n",
      "Epoch 13/25\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0083 - precision: 0.9897 - recall: 0.9956 - pr_auc: 0.9999 - val_loss: 0.0870 - val_precision: 0.8456 - val_recall: 0.8811 - val_pr_auc: 0.9341\n",
      "Epoch 14/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0050 - precision: 0.9956 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0916 - val_precision: 0.8759 - val_recall: 0.8392 - val_pr_auc: 0.9220\n",
      "Epoch 15/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0041 - precision: 0.9971 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1117 - val_precision: 0.8871 - val_recall: 0.7692 - val_pr_auc: 0.9062\n",
      "Epoch 16/25\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0049 - precision: 0.9927 - recall: 0.9971 - pr_auc: 0.9997 - val_loss: 0.1140 - val_precision: 0.9550 - val_recall: 0.7413 - val_pr_auc: 0.9345\n",
      "Epoch 17/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0156 - precision: 0.9808 - recall: 0.9808 - pr_auc: 0.9932 - val_loss: 0.0919 - val_precision: 0.9015 - val_recall: 0.8322 - val_pr_auc: 0.9372\n",
      "Epoch 18/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0060 - precision: 0.9985 - recall: 0.9956 - pr_auc: 1.0000 - val_loss: 0.1007 - val_precision: 0.9008 - val_recall: 0.8252 - val_pr_auc: 0.9185\n",
      "Epoch 19/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0033 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0980 - val_precision: 0.8947 - val_recall: 0.8322 - val_pr_auc: 0.9245\n",
      "Epoch 20/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0018 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1040 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9215\n",
      "Epoch 21/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0016 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1184 - val_precision: 0.8898 - val_recall: 0.7902 - val_pr_auc: 0.9155\n",
      "Epoch 22/25\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1087 - val_precision: 0.8939 - val_recall: 0.8252 - val_pr_auc: 0.9170\n",
      "Epoch 23/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0011 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1223 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9086\n",
      "Epoch 24/25\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 9.6851e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1171 - val_precision: 0.8931 - val_recall: 0.8182 - val_pr_auc: 0.9178\n",
      "Epoch 25/25\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.3621e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1166 - val_precision: 0.8931 - val_recall: 0.8182 - val_pr_auc: 0.9180\n",
      "12/12 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.4117 - precision: 0.7101 - recall: 0.7080 - pr_auc: 0.6868 - val_loss: 0.0684 - val_precision: 0.8963 - val_recall: 0.8462 - val_pr_auc: 0.9421\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0780 - precision: 0.8571 - recall: 0.8496 - pr_auc: 0.9182 - val_loss: 0.0981 - val_precision: 0.9596 - val_recall: 0.6643 - val_pr_auc: 0.9487\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0630 - precision: 0.8856 - recall: 0.8791 - pr_auc: 0.9307 - val_loss: 0.0882 - val_precision: 0.8217 - val_recall: 0.9021 - val_pr_auc: 0.9263\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0434 - precision: 0.9266 - recall: 0.9130 - pr_auc: 0.9650 - val_loss: 0.0599 - val_precision: 0.9191 - val_recall: 0.8741 - val_pr_auc: 0.9541\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0240 - precision: 0.9592 - recall: 0.9720 - pr_auc: 0.9910 - val_loss: 0.0854 - val_precision: 0.8917 - val_recall: 0.7483 - val_pr_auc: 0.9185\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0152 - precision: 0.9765 - recall: 0.9823 - pr_auc: 0.9969 - val_loss: 0.0679 - val_precision: 0.9044 - val_recall: 0.8601 - val_pr_auc: 0.9512\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0084 - precision: 0.9868 - recall: 0.9941 - pr_auc: 0.9996 - val_loss: 0.1037 - val_precision: 0.8148 - val_recall: 0.9231 - val_pr_auc: 0.9174\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0085 - precision: 0.9839 - recall: 0.9926 - pr_auc: 0.9994 - val_loss: 0.0884 - val_precision: 0.8943 - val_recall: 0.7692 - val_pr_auc: 0.9413\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0030 - precision: 0.9971 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1073 - val_precision: 0.8960 - val_recall: 0.7832 - val_pr_auc: 0.9150\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0019 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1136 - val_precision: 0.8943 - val_recall: 0.7692 - val_pr_auc: 0.9123\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1023 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9193\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.0173e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1124 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9200\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 5.6328e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1195 - val_precision: 0.8976 - val_recall: 0.7972 - val_pr_auc: 0.9207\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.3486e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1151 - val_precision: 0.8872 - val_recall: 0.8252 - val_pr_auc: 0.9089\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.0017e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1234 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9080\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.0556e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1297 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9176\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7712e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1303 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9045\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.3258e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1290 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9084\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9916e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1367 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.8995\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.8962e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1359 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9008\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.5406e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1313 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9032\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3953e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1429 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.8950\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.2562e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1379 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8983\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1320e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1419 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8955\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.9686e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1464 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8949\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.1415e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1462 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8888\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.3006e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1509 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.8804\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 12ms/step - loss: 7.6262e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1495 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8959\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.8393e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1481 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8895\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.4149e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1487 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8896\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 5.8712e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1563 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8883\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.3574e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1520 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8921\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.0993e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1538 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8853\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "generation2\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_19 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 42 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/42\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3875 - precision: 0.6638 - recall: 0.6903 - pr_auc: 0.6538 - val_loss: 0.0775 - val_precision: 0.8759 - val_recall: 0.8392 - val_pr_auc: 0.9258\n",
      "Epoch 2/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0860 - precision: 0.8576 - recall: 0.8437 - pr_auc: 0.9023 - val_loss: 0.0654 - val_precision: 0.8442 - val_recall: 0.9091 - val_pr_auc: 0.9450\n",
      "Epoch 3/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0559 - precision: 0.8978 - recall: 0.8938 - pr_auc: 0.9545 - val_loss: 0.0658 - val_precision: 0.8188 - val_recall: 0.9161 - val_pr_auc: 0.9524\n",
      "Epoch 4/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0430 - precision: 0.9246 - recall: 0.9218 - pr_auc: 0.9726 - val_loss: 0.0645 - val_precision: 0.8639 - val_recall: 0.8881 - val_pr_auc: 0.9490\n",
      "Epoch 5/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0267 - precision: 0.9515 - recall: 0.9543 - pr_auc: 0.9901 - val_loss: 0.0758 - val_precision: 0.9298 - val_recall: 0.7413 - val_pr_auc: 0.9451\n",
      "Epoch 6/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0152 - precision: 0.9765 - recall: 0.9823 - pr_auc: 0.9967 - val_loss: 0.0752 - val_precision: 0.8741 - val_recall: 0.8741 - val_pr_auc: 0.9433\n",
      "Epoch 7/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0107 - precision: 0.9853 - recall: 0.9867 - pr_auc: 0.9990 - val_loss: 0.1084 - val_precision: 0.9304 - val_recall: 0.7483 - val_pr_auc: 0.9306\n",
      "Epoch 8/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0070 - precision: 0.9898 - recall: 0.9971 - pr_auc: 0.9992 - val_loss: 0.1173 - val_precision: 0.9211 - val_recall: 0.7343 - val_pr_auc: 0.9171\n",
      "Epoch 9/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0029 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0903 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9392\n",
      "Epoch 10/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1021 - val_precision: 0.8872 - val_recall: 0.8252 - val_pr_auc: 0.9177\n",
      "Epoch 11/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.0641e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1277 - val_precision: 0.8880 - val_recall: 0.7762 - val_pr_auc: 0.9024\n",
      "Epoch 12/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.4421e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1135 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9096\n",
      "Epoch 13/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.8459e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1197 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9095\n",
      "Epoch 14/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.9618e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1289 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9060\n",
      "Epoch 15/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.3645e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1235 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9062\n",
      "Epoch 16/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.7608e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1273 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9066\n",
      "Epoch 17/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.4004e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1254 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.8949\n",
      "Epoch 18/42\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 2.1293e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1345 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8949\n",
      "Epoch 19/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.8748e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1309 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8968\n",
      "Epoch 20/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.6706e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1367 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8962\n",
      "Epoch 21/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.4659e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1356 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.8884\n",
      "Epoch 22/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3441e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1392 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8915\n",
      "Epoch 23/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.2217e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1370 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.8980\n",
      "Epoch 24/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0832e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1443 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8910\n",
      "Epoch 25/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 9.7922e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1451 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.8840\n",
      "Epoch 26/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.9194e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1492 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8971\n",
      "Epoch 27/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.1610e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1466 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8860\n",
      "Epoch 28/42\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 7.4729e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1503 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8843\n",
      "Epoch 29/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.7993e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1491 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.8858\n",
      "Epoch 30/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.4721e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1524 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8847\n",
      "Epoch 31/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.7327e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1537 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.8839\n",
      "Epoch 32/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.3420e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1577 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8848\n",
      "Epoch 33/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.9676e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1548 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.8860\n",
      "Epoch 34/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.4823e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1607 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8807\n",
      "Epoch 35/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.2384e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1626 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8750\n",
      "Epoch 36/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.8809e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1602 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.8797\n",
      "Epoch 37/42\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 3.6236e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1620 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8811\n",
      "Epoch 38/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.3588e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1581 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.8859\n",
      "Epoch 39/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.2258e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1646 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8758\n",
      "Epoch 40/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.9525e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1641 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8756\n",
      "Epoch 41/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7128e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1704 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8755\n",
      "Epoch 42/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.5096e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1717 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.8745\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 42 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/42\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3113 - precision: 0.6987 - recall: 0.7389 - pr_auc: 0.6926 - val_loss: 0.0880 - val_precision: 0.7904 - val_recall: 0.9231 - val_pr_auc: 0.9354\n",
      "Epoch 2/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0769 - precision: 0.8584 - recall: 0.8496 - pr_auc: 0.9206 - val_loss: 0.0643 - val_precision: 0.8611 - val_recall: 0.8671 - val_pr_auc: 0.9442\n",
      "Epoch 3/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0544 - precision: 0.8950 - recall: 0.9056 - pr_auc: 0.9527 - val_loss: 0.0883 - val_precision: 0.7684 - val_recall: 0.9510 - val_pr_auc: 0.9489\n",
      "Epoch 4/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0392 - precision: 0.9235 - recall: 0.9263 - pr_auc: 0.9744 - val_loss: 0.0692 - val_precision: 0.9160 - val_recall: 0.8392 - val_pr_auc: 0.9455\n",
      "Epoch 5/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0180 - precision: 0.9737 - recall: 0.9838 - pr_auc: 0.9965 - val_loss: 0.0719 - val_precision: 0.8411 - val_recall: 0.8881 - val_pr_auc: 0.9411\n",
      "Epoch 6/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0184 - precision: 0.9680 - recall: 0.9808 - pr_auc: 0.9949 - val_loss: 0.0887 - val_precision: 0.9113 - val_recall: 0.7902 - val_pr_auc: 0.9327\n",
      "Epoch 7/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0113 - precision: 0.9853 - recall: 0.9853 - pr_auc: 0.9976 - val_loss: 0.0855 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9334\n",
      "Epoch 8/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0038 - precision: 0.9941 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0986 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9189\n",
      "Epoch 9/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0032 - precision: 0.9971 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1152 - val_precision: 0.9076 - val_recall: 0.7552 - val_pr_auc: 0.9070\n",
      "Epoch 10/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1059 - val_precision: 0.8582 - val_recall: 0.8462 - val_pr_auc: 0.9156\n",
      "Epoch 11/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.3626e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1095 - val_precision: 0.8750 - val_recall: 0.8322 - val_pr_auc: 0.9152\n",
      "Epoch 12/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.4915e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1171 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.9207\n",
      "Epoch 13/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 4.2463e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1167 - val_precision: 0.8984 - val_recall: 0.8042 - val_pr_auc: 0.9153\n",
      "Epoch 14/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.6375e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1155 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.9159\n",
      "Epoch 15/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.0053e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1238 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.9118\n",
      "Epoch 16/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.4534e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1212 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9137\n",
      "Epoch 17/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.0866e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1237 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9135\n",
      "Epoch 18/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.8605e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1252 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9136\n",
      "Epoch 19/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.6367e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1266 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.9081\n",
      "Epoch 20/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.4967e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1300 - val_precision: 0.8906 - val_recall: 0.7972 - val_pr_auc: 0.9100\n",
      "Epoch 21/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2982e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1360 - val_precision: 0.8968 - val_recall: 0.7902 - val_pr_auc: 0.9023\n",
      "Epoch 22/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1698e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1312 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9044\n",
      "Epoch 23/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0559e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1328 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9047\n",
      "Epoch 24/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.6911e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1338 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9046\n",
      "Epoch 25/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.5922e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1362 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9047\n",
      "Epoch 26/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.9286e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1398 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8972\n",
      "Epoch 27/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.1287e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1417 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8974\n",
      "Epoch 28/42\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 6.4542e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1375 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9050\n",
      "Epoch 29/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 6.0768e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1406 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9050\n",
      "Epoch 30/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.5188e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1449 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8933\n",
      "Epoch 31/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.0960e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1475 - val_precision: 0.8819 - val_recall: 0.7832 - val_pr_auc: 0.8894\n",
      "Epoch 32/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.6423e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1407 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9060\n",
      "Epoch 33/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.4729e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1470 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9015\n",
      "Epoch 34/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.0213e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1484 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.8937\n",
      "Epoch 35/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.7400e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1467 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9059\n",
      "Epoch 36/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.4605e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1502 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.8984\n",
      "Epoch 37/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.2090e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1502 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9022\n",
      "Epoch 38/42\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.9820e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1534 - val_precision: 0.8819 - val_recall: 0.7832 - val_pr_auc: 0.8902\n",
      "Epoch 39/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.7880e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1534 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8907\n",
      "Epoch 40/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.5796e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1507 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9065\n",
      "Epoch 41/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.4292e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1563 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.8907\n",
      "Epoch 42/42\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.2929e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1537 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9026\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_21 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 23 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/23\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 4s 30ms/step - loss: 1.2385 - precision: 0.5344 - recall: 0.6534 - pr_auc: 0.5041 - val_loss: 0.1410 - val_precision: 0.8312 - val_recall: 0.8951 - val_pr_auc: 0.8842\n",
      "Epoch 2/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1756 - precision: 0.8328 - recall: 0.8378 - pr_auc: 0.8594 - val_loss: 0.0809 - val_precision: 0.8732 - val_recall: 0.8671 - val_pr_auc: 0.9309\n",
      "Epoch 3/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0931 - precision: 0.8464 - recall: 0.8614 - pr_auc: 0.9032 - val_loss: 0.0665 - val_precision: 0.8671 - val_recall: 0.8671 - val_pr_auc: 0.9479\n",
      "Epoch 4/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0654 - precision: 0.8698 - recall: 0.8673 - pr_auc: 0.9276 - val_loss: 0.0613 - val_precision: 0.9077 - val_recall: 0.8252 - val_pr_auc: 0.9518\n",
      "Epoch 5/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0540 - precision: 0.8994 - recall: 0.9100 - pr_auc: 0.9516 - val_loss: 0.0898 - val_precision: 0.8582 - val_recall: 0.8462 - val_pr_auc: 0.9091\n",
      "Epoch 6/23\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0422 - precision: 0.9192 - recall: 0.9395 - pr_auc: 0.9689 - val_loss: 0.0756 - val_precision: 0.8931 - val_recall: 0.8182 - val_pr_auc: 0.9235\n",
      "Epoch 7/23\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0319 - precision: 0.9371 - recall: 0.9454 - pr_auc: 0.9838 - val_loss: 0.0851 - val_precision: 0.8531 - val_recall: 0.8531 - val_pr_auc: 0.9192\n",
      "Epoch 8/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0242 - precision: 0.9617 - recall: 0.9631 - pr_auc: 0.9914 - val_loss: 0.0880 - val_precision: 0.8643 - val_recall: 0.8462 - val_pr_auc: 0.9161\n",
      "Epoch 9/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0146 - precision: 0.9768 - recall: 0.9926 - pr_auc: 0.9983 - val_loss: 0.1000 - val_precision: 0.8976 - val_recall: 0.7972 - val_pr_auc: 0.9121\n",
      "Epoch 10/23\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0134 - precision: 0.9737 - recall: 0.9838 - pr_auc: 0.9985 - val_loss: 0.0769 - val_precision: 0.8258 - val_recall: 0.8951 - val_pr_auc: 0.9433\n",
      "Epoch 11/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0088 - precision: 0.9869 - recall: 0.9971 - pr_auc: 0.9995 - val_loss: 0.0972 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9209\n",
      "Epoch 12/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0140 - precision: 0.9794 - recall: 0.9838 - pr_auc: 0.9964 - val_loss: 0.0810 - val_precision: 0.8581 - val_recall: 0.8881 - val_pr_auc: 0.9379\n",
      "Epoch 13/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0065 - precision: 0.9927 - recall: 0.9971 - pr_auc: 0.9998 - val_loss: 0.0826 - val_precision: 0.8976 - val_recall: 0.7972 - val_pr_auc: 0.9440\n",
      "Epoch 14/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0035 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1016 - val_precision: 0.8676 - val_recall: 0.8252 - val_pr_auc: 0.9072\n",
      "Epoch 15/23\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0028 - precision: 0.9971 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0974 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9204\n",
      "Epoch 16/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0021 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1065 - val_precision: 0.8806 - val_recall: 0.8252 - val_pr_auc: 0.9119\n",
      "Epoch 17/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0019 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1239 - val_precision: 0.8952 - val_recall: 0.7762 - val_pr_auc: 0.9183\n",
      "Epoch 18/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0020 - precision: 1.0000 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1052 - val_precision: 0.8686 - val_recall: 0.8322 - val_pr_auc: 0.9216\n",
      "Epoch 19/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0012 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1144 - val_precision: 0.8779 - val_recall: 0.8042 - val_pr_auc: 0.9199\n",
      "Epoch 20/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 9.9692e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1203 - val_precision: 0.8769 - val_recall: 0.7972 - val_pr_auc: 0.9176\n",
      "Epoch 21/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 9.0750e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1241 - val_precision: 0.8819 - val_recall: 0.7832 - val_pr_auc: 0.9126\n",
      "Epoch 22/23\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0064 - precision: 0.9911 - recall: 0.9897 - pr_auc: 0.9992 - val_loss: 0.1004 - val_precision: 0.8741 - val_recall: 0.8252 - val_pr_auc: 0.9408\n",
      "Epoch 23/23\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0019 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1146 - val_precision: 0.8667 - val_recall: 0.8182 - val_pr_auc: 0.9228\n",
      "12/12 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_22 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 25 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/25\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.2694 - precision: 0.7447 - recall: 0.7699 - pr_auc: 0.7541 - val_loss: 0.0654 - val_precision: 0.8581 - val_recall: 0.8881 - val_pr_auc: 0.9398\n",
      "Epoch 2/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0727 - precision: 0.8664 - recall: 0.8510 - pr_auc: 0.9178 - val_loss: 0.0880 - val_precision: 0.7816 - val_recall: 0.9510 - val_pr_auc: 0.9227\n",
      "Epoch 3/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0635 - precision: 0.8752 - recall: 0.8687 - pr_auc: 0.9349 - val_loss: 0.0642 - val_precision: 0.8250 - val_recall: 0.9231 - val_pr_auc: 0.9489\n",
      "Epoch 4/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0278 - precision: 0.9476 - recall: 0.9602 - pr_auc: 0.9891 - val_loss: 0.1434 - val_precision: 0.9307 - val_recall: 0.6573 - val_pr_auc: 0.8524\n",
      "Epoch 5/25\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0218 - precision: 0.9705 - recall: 0.9690 - pr_auc: 0.9939 - val_loss: 0.0753 - val_precision: 0.9000 - val_recall: 0.8182 - val_pr_auc: 0.9483\n",
      "Epoch 6/25\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0143 - precision: 0.9735 - recall: 0.9735 - pr_auc: 0.9971 - val_loss: 0.1011 - val_precision: 0.9098 - val_recall: 0.7762 - val_pr_auc: 0.9264\n",
      "Epoch 7/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0059 - precision: 0.9912 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.1009 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9131\n",
      "Epoch 8/25\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0152 - precision: 0.9736 - recall: 0.9794 - pr_auc: 0.9939 - val_loss: 0.1256 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9179\n",
      "Epoch 9/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0028 - precision: 0.9941 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1332 - val_precision: 0.8828 - val_recall: 0.7902 - val_pr_auc: 0.9079\n",
      "Epoch 10/25\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0039 - precision: 0.9941 - recall: 0.9956 - pr_auc: 0.9998 - val_loss: 0.1276 - val_precision: 0.8507 - val_recall: 0.7972 - val_pr_auc: 0.9132\n",
      "Epoch 11/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0016 - precision: 1.0000 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.1270 - val_precision: 0.8561 - val_recall: 0.7902 - val_pr_auc: 0.9096\n",
      "Epoch 12/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.7277e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1292 - val_precision: 0.8561 - val_recall: 0.7902 - val_pr_auc: 0.9075\n",
      "Epoch 13/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.9290e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1425 - val_precision: 0.8750 - val_recall: 0.7832 - val_pr_auc: 0.9124\n",
      "Epoch 14/25\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.9930e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1354 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9108\n",
      "Epoch 15/25\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 2.3176e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1369 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9053\n",
      "Epoch 16/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9680e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1424 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9074\n",
      "Epoch 17/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7165e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1385 - val_precision: 0.8626 - val_recall: 0.7902 - val_pr_auc: 0.9069\n",
      "Epoch 18/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.5114e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1408 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9074\n",
      "Epoch 19/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3379e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1413 - val_precision: 0.8692 - val_recall: 0.7902 - val_pr_auc: 0.9073\n",
      "Epoch 20/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1792e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1484 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9026\n",
      "Epoch 21/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1033e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1473 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9037\n",
      "Epoch 22/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.9305e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1479 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9038\n",
      "Epoch 23/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.9784e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1478 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9040\n",
      "Epoch 24/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.4992e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1469 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9047\n",
      "Epoch 25/25\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.4775e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1510 - val_precision: 0.8682 - val_recall: 0.7832 - val_pr_auc: 0.9042\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_23 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.2437 - precision: 0.7096 - recall: 0.7640 - pr_auc: 0.7705 - val_loss: 0.0637 - val_precision: 0.8750 - val_recall: 0.8811 - val_pr_auc: 0.9473\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0794 - precision: 0.8491 - recall: 0.8628 - pr_auc: 0.9085 - val_loss: 0.0752 - val_precision: 0.8012 - val_recall: 0.9301 - val_pr_auc: 0.9475\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0687 - precision: 0.8744 - recall: 0.8628 - pr_auc: 0.9267 - val_loss: 0.0732 - val_precision: 0.8943 - val_recall: 0.7692 - val_pr_auc: 0.9164\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0344 - precision: 0.9411 - recall: 0.9425 - pr_auc: 0.9787 - val_loss: 0.0664 - val_precision: 0.8750 - val_recall: 0.8322 - val_pr_auc: 0.9462\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0190 - precision: 0.9721 - recall: 0.9779 - pr_auc: 0.9921 - val_loss: 0.0749 - val_precision: 0.8411 - val_recall: 0.8881 - val_pr_auc: 0.9342\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0092 - precision: 0.9839 - recall: 0.9912 - pr_auc: 0.9992 - val_loss: 0.0938 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9132\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0051 - precision: 0.9912 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.1361 - val_precision: 0.8947 - val_recall: 0.7133 - val_pr_auc: 0.8903\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0028 - precision: 0.9956 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.0995 - val_precision: 0.8984 - val_recall: 0.8042 - val_pr_auc: 0.9207\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0013 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1073 - val_precision: 0.8750 - val_recall: 0.8322 - val_pr_auc: 0.9208\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.8153e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1086 - val_precision: 0.9000 - val_recall: 0.8182 - val_pr_auc: 0.9234\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.5905e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1220 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9178\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.5446e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1251 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9172\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.8131e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1231 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9180\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 3.0859e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1291 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9177\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.6533e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1352 - val_precision: 0.8984 - val_recall: 0.8042 - val_pr_auc: 0.9167\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.2929e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1312 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9062\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9860e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1380 - val_precision: 0.8864 - val_recall: 0.8182 - val_pr_auc: 0.9058\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7579e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1396 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9114\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.5475e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1403 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9060\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3346e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1434 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9061\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2173e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1477 - val_precision: 0.8984 - val_recall: 0.8042 - val_pr_auc: 0.9079\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.0965e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1456 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9019\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.7425e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1490 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9022\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.9601e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1450 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8968\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.0287e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1500 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9028\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.2407e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1551 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8989\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 6.5724e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1563 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8950\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 6.2046e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1572 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8867\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.6556e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1559 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8972\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 5.0880e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1599 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8870\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.7336e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1590 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8910\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.3194e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1631 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8770\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.0356e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1648 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.8642\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 331648)            0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 331649    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332673 (1.27 MB)\n",
      "Trainable params: 332673 (1.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 128 epochs: 27 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/27\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "54/54 [==============================] - 4s 29ms/step - loss: 0.9956 - precision: 0.5711 - recall: 0.6755 - pr_auc: 0.5391 - val_loss: 0.1918 - val_precision: 0.9519 - val_recall: 0.6923 - val_pr_auc: 0.8697\n",
      "Epoch 2/27\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1541 - precision: 0.8298 - recall: 0.8127 - pr_auc: 0.8554 - val_loss: 0.1453 - val_precision: 0.7243 - val_recall: 0.9371 - val_pr_auc: 0.8857\n",
      "Epoch 3/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1064 - precision: 0.8416 - recall: 0.8466 - pr_auc: 0.8881 - val_loss: 0.0701 - val_precision: 0.8571 - val_recall: 0.8811 - val_pr_auc: 0.9073\n",
      "Epoch 4/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0596 - precision: 0.8788 - recall: 0.8879 - pr_auc: 0.9426 - val_loss: 0.0716 - val_precision: 0.9147 - val_recall: 0.8252 - val_pr_auc: 0.9477\n",
      "Epoch 5/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0462 - precision: 0.9191 - recall: 0.9218 - pr_auc: 0.9651 - val_loss: 0.0666 - val_precision: 0.8493 - val_recall: 0.8671 - val_pr_auc: 0.9424\n",
      "Epoch 6/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0318 - precision: 0.9491 - recall: 0.9617 - pr_auc: 0.9845 - val_loss: 0.0655 - val_precision: 0.8832 - val_recall: 0.8462 - val_pr_auc: 0.9498\n",
      "Epoch 7/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0247 - precision: 0.9582 - recall: 0.9808 - pr_auc: 0.9909 - val_loss: 0.0672 - val_precision: 0.8462 - val_recall: 0.8462 - val_pr_auc: 0.9445\n",
      "Epoch 8/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0261 - precision: 0.9575 - recall: 0.9631 - pr_auc: 0.9896 - val_loss: 0.0919 - val_precision: 0.7654 - val_recall: 0.9580 - val_pr_auc: 0.9451\n",
      "Epoch 9/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0155 - precision: 0.9695 - recall: 0.9853 - pr_auc: 0.9981 - val_loss: 0.0769 - val_precision: 0.8915 - val_recall: 0.8042 - val_pr_auc: 0.9443\n",
      "Epoch 10/27\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0096 - precision: 0.9912 - recall: 0.9926 - pr_auc: 0.9997 - val_loss: 0.1003 - val_precision: 0.9187 - val_recall: 0.7902 - val_pr_auc: 0.9341\n",
      "Epoch 11/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0067 - precision: 0.9941 - recall: 1.0000 - pr_auc: 0.9999 - val_loss: 0.0978 - val_precision: 0.8797 - val_recall: 0.8182 - val_pr_auc: 0.9203\n",
      "Epoch 12/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0128 - precision: 0.9810 - recall: 0.9897 - pr_auc: 0.9954 - val_loss: 0.1117 - val_precision: 0.9244 - val_recall: 0.7692 - val_pr_auc: 0.9301\n",
      "Epoch 13/27\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0126 - precision: 0.9738 - recall: 0.9882 - pr_auc: 0.9952 - val_loss: 0.1131 - val_precision: 0.9211 - val_recall: 0.7343 - val_pr_auc: 0.9175\n",
      "Epoch 14/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0037 - precision: 0.9971 - recall: 0.9985 - pr_auc: 1.0000 - val_loss: 0.0953 - val_precision: 0.8613 - val_recall: 0.8252 - val_pr_auc: 0.9262\n",
      "Epoch 15/27\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0026 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1012 - val_precision: 0.8788 - val_recall: 0.8112 - val_pr_auc: 0.9239\n",
      "Epoch 16/27\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0017 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.0992 - val_precision: 0.8633 - val_recall: 0.8392 - val_pr_auc: 0.9292\n",
      "Epoch 17/27\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0014 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1052 - val_precision: 0.8923 - val_recall: 0.8112 - val_pr_auc: 0.9230\n",
      "Epoch 18/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0010 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1085 - val_precision: 0.8731 - val_recall: 0.8182 - val_pr_auc: 0.9246\n",
      "Epoch 19/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.7165e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1204 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9197\n",
      "Epoch 20/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.4842e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1234 - val_precision: 0.8819 - val_recall: 0.7832 - val_pr_auc: 0.9203\n",
      "Epoch 21/27\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.7051e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1210 - val_precision: 0.8855 - val_recall: 0.8112 - val_pr_auc: 0.9203\n",
      "Epoch 22/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.9727e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1345 - val_precision: 0.8880 - val_recall: 0.7762 - val_pr_auc: 0.9146\n",
      "Epoch 23/27\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.5706e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1367 - val_precision: 0.8810 - val_recall: 0.7762 - val_pr_auc: 0.9107\n",
      "Epoch 24/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.7670e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1227 - val_precision: 0.8712 - val_recall: 0.8042 - val_pr_auc: 0.9200\n",
      "Epoch 25/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2382e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1283 - val_precision: 0.8846 - val_recall: 0.8042 - val_pr_auc: 0.9067\n",
      "Epoch 26/27\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8542e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1379 - val_precision: 0.8837 - val_recall: 0.7972 - val_pr_auc: 0.9127\n",
      "Epoch 27/27\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 3.4767e-04 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.1283 - val_precision: 0.8722 - val_recall: 0.8112 - val_pr_auc: 0.9010\n",
      "12/12 [==============================] - 1s 3ms/step\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "generation3\n",
      "Runtime:  1002.982027053833\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_25 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 165824)            0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 165825    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166337 (649.75 KB)\n",
      "Trainable params: 166337 (649.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "batch: 64 epochs: 33 LR: 0.01 momentum: 0.5 kernel: 7 maxpool: 3\n",
      "Epoch 1/33\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 4 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "107/107 [==============================] - 4s 17ms/step - loss: 0.3104 - precision: 0.7252 - recall: 0.7434 - pr_auc: 0.7337 - val_loss: 0.0582 - val_precision: 0.9118 - val_recall: 0.8794 - val_pr_auc: 0.9351\n",
      "Epoch 2/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0765 - precision: 0.8571 - recall: 0.8584 - pr_auc: 0.9140 - val_loss: 0.0685 - val_precision: 0.9623 - val_recall: 0.7234 - val_pr_auc: 0.9568\n",
      "Epoch 3/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0585 - precision: 0.8847 - recall: 0.8717 - pr_auc: 0.9472 - val_loss: 0.0559 - val_precision: 0.9051 - val_recall: 0.8794 - val_pr_auc: 0.9457\n",
      "Epoch 4/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0340 - precision: 0.9467 - recall: 0.9440 - pr_auc: 0.9815 - val_loss: 0.0940 - val_precision: 0.7556 - val_recall: 0.9645 - val_pr_auc: 0.9420\n",
      "Epoch 5/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0238 - precision: 0.9562 - recall: 0.9661 - pr_auc: 0.9914 - val_loss: 0.0622 - val_precision: 0.8912 - val_recall: 0.9291 - val_pr_auc: 0.9396\n",
      "Epoch 6/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0136 - precision: 0.9750 - recall: 0.9794 - pr_auc: 0.9977 - val_loss: 0.0687 - val_precision: 0.8707 - val_recall: 0.9078 - val_pr_auc: 0.9206\n",
      "Epoch 7/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0078 - precision: 0.9868 - recall: 0.9912 - pr_auc: 0.9992 - val_loss: 0.0768 - val_precision: 0.8533 - val_recall: 0.9078 - val_pr_auc: 0.9238\n",
      "Epoch 8/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0051 - precision: 0.9926 - recall: 0.9956 - pr_auc: 0.9997 - val_loss: 0.0790 - val_precision: 0.9134 - val_recall: 0.8227 - val_pr_auc: 0.9308\n",
      "Epoch 9/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.0126 - precision: 0.9765 - recall: 0.9794 - pr_auc: 0.9977 - val_loss: 0.1265 - val_precision: 0.9237 - val_recall: 0.7730 - val_pr_auc: 0.8835\n",
      "Epoch 10/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0070 - precision: 0.9853 - recall: 0.9867 - pr_auc: 0.9994 - val_loss: 0.1215 - val_precision: 0.8433 - val_recall: 0.8014 - val_pr_auc: 0.8675\n",
      "Epoch 11/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.2708 - precision: 0.8769 - recall: 0.8407 - pr_auc: 0.8423 - val_loss: 0.2528 - val_precision: 0.8446 - val_recall: 0.8865 - val_pr_auc: 0.8437\n",
      "Epoch 12/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.1332 - precision: 0.9125 - recall: 0.8923 - pr_auc: 0.9095 - val_loss: 0.5330 - val_precision: 0.9326 - val_recall: 0.5887 - val_pr_auc: 0.6978\n",
      "Epoch 13/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0319 - precision: 0.9689 - recall: 0.9661 - pr_auc: 0.9796 - val_loss: 0.2857 - val_precision: 0.8898 - val_recall: 0.8014 - val_pr_auc: 0.8367\n",
      "Epoch 14/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0135 - precision: 0.9837 - recall: 0.9779 - pr_auc: 0.9933 - val_loss: 0.2696 - val_precision: 0.8176 - val_recall: 0.8582 - val_pr_auc: 0.8194\n",
      "Epoch 15/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0029 - precision: 0.9956 - recall: 0.9956 - pr_auc: 0.9984 - val_loss: 0.2841 - val_precision: 0.9068 - val_recall: 0.7589 - val_pr_auc: 0.8357\n",
      "Epoch 16/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0019 - precision: 0.9971 - recall: 0.9971 - pr_auc: 0.9999 - val_loss: 0.3067 - val_precision: 0.9266 - val_recall: 0.7163 - val_pr_auc: 0.8126\n",
      "Epoch 17/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 4.7014e-04 - precision: 0.9985 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3645 - val_precision: 0.9423 - val_recall: 0.6950 - val_pr_auc: 0.7844\n",
      "Epoch 18/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0092 - precision: 0.9867 - recall: 0.9838 - pr_auc: 0.9968 - val_loss: 0.3465 - val_precision: 0.9346 - val_recall: 0.7092 - val_pr_auc: 0.7937\n",
      "Epoch 19/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 0.0012 - precision: 1.0000 - recall: 0.9985 - pr_auc: 0.9989 - val_loss: 0.2870 - val_precision: 0.9292 - val_recall: 0.7447 - val_pr_auc: 0.8079\n",
      "Epoch 20/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 3.5443e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.3097 - val_precision: 0.9273 - val_recall: 0.7234 - val_pr_auc: 0.8065\n",
      "Epoch 21/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 2.6221e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2988 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8058\n",
      "Epoch 22/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.9157e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2971 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8058\n",
      "Epoch 23/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.7436e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2942 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8057\n",
      "Epoch 24/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.5319e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2963 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8060\n",
      "Epoch 25/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.3906e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2909 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8105\n",
      "Epoch 26/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.2511e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2921 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8107\n",
      "Epoch 27/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 1.1022e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2913 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8107\n",
      "Epoch 28/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 1.0414e-05 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2907 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8112\n",
      "Epoch 29/33\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 9.6116e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2923 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8060\n",
      "Epoch 30/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 9.0592e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2910 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8112\n",
      "Epoch 31/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.5644e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2924 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8065\n",
      "Epoch 32/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 8.1408e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2924 - val_precision: 0.9286 - val_recall: 0.7376 - val_pr_auc: 0.8065\n",
      "Epoch 33/33\n",
      "107/107 [==============================] - 1s 9ms/step - loss: 7.7253e-06 - precision: 1.0000 - recall: 1.0000 - pr_auc: 1.0000 - val_loss: 0.2910 - val_precision: 0.9292 - val_recall: 0.7447 - val_pr_auc: 0.8113\n",
      "23/23 [==============================] - 1s 2ms/step\n",
      "Completed\n",
      "FINISHED, Runtime: 17.41 minutes\n"
     ]
    }
   ],
   "source": [
    "model = CNN_model1\n",
    "#bounds = [[16, 64], [100, 200], [0.0001, 0.01], [0.1, 0.9], [2, 8], [2, 3]]\n",
    "bounds = [[16, 256], [10, 50]]\n",
    "\n",
    "\n",
    "print(\"Starting\")\n",
    "res_opt_method, CM_opt, hyperparam_optim, optim_results = train_CNN_js(model, bounds, x_train, y_train, x_valid, y_valid, x_test, y_test, strategy)\n",
    "print(\"Completed\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# # SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# use a dictionary with keys using the right names.\n",
    "results = {'results': res_opt_method, 'confusion matrix': CM_opt, 'hyperparameters': hyperparam_optim,\n",
    "           'y_test': list(y_test)}\n",
    "a_file = open(results_path + \"results2.pkl\", \"wb\")\n",
    "pickle.dump(results, a_file)\n",
    "a_file.close()\n",
    "\n",
    "# export optimization results\n",
    "a_file = open(results_path + \"GA_results2.pkl\", \"wb\")\n",
    "pickle.dump(optim_results, a_file)\n",
    "a_file.close()\n",
    "\n",
    "## OUT\n",
    "end_global = time.time()\n",
    "print(f\"FINISHED, Runtime: {(end_global - start_global) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5edb4c-6fcb-4f01-8898-f31c4a798f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHzklEQVR4nO3dd3wVVf7/8ffNrSmkQQol9C6ClKWERRARZCmyimJDQHDFXUVk1R8sKoIoVlRUcBcRLIgsKi66SLEhiCIl7BdFAeklARLSSM+98/sjcOWaAElIcsnwej4e92HunJm5nxmumXfOnJmxGIZhCAAAwCQC/F0AAABARSLcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcALggCxYskMVi8b5sNpvq1aunUaNG6fDhw5Kkr7/+2mceq9WqqKgoDRo0SJs2bSrT5x09elQTJ07U5ZdfrpCQELlcLjVr1kz333+/du3aVRmbCKCasfm7AADmMH/+fLVs2VI5OTn65ptvNGPGDK1Zs0bbtm3zzvPUU0/pqquuUkFBgRISEjR16lT17NlTW7duVbNmzc77GT/88IMGDhwowzB07733qlu3bnI4HNqxY4feffddde7cWampqZW5mQCqAcINgArRpk0bderUSZJ01VVXye1264knntDHH3+sunXrSpKaNWumrl27SpJ69Oih8PBwjRgxQu+++66mTp16zvVnZGTouuuuk8vl0vr161WvXj1vW69evXT33Xfrgw8+qJBtcbvdKiwslNPprJD1AahanJYCUClOh5j9+/efdZ7TYejo0aPnXd/cuXOVlJSkZ5991ifYnGno0KHen3v16qVevXoVm2fkyJFq2LCh9/2+fftksVj07LPPavr06WrUqJGcTqf+/e9/y+Fw6NFHHy22jl9++UUWi0WzZs3yTktKStLdd9+tevXqyeFwqFGjRpo6daoKCwvPu20AKhY9NwAqxa+//ipJioqKOus8e/fulSQ1b978vOtbtWqVrFarBg0aVDEF/s6sWbPUvHlzPf/88woNDVWzZs00cOBAvfXWW5o6daoCAn77W3D+/PlyOBy67bbbJBUFm86dOysgIECPPfaYmjRpou+++07Tp0/Xvn37NH/+/EqpGUDJCDcAKsTpUzm5ublas2aNpk+frho1amjw4MH6+eefJUkej0eFhYXeMTd///vf1bp1a915553nXf+BAwcUFRWl4ODgSqnf5XJp5cqVstvt3mmjRo3S0qVL9cUXX+iaa67xbue7776rQYMGqWbNmpKkxx9/XKmpqfrpp59Uv359SdLVV1+twMBAPfjgg3rooYfUunXrSqkbQHGclgJQIbp27Sq73a4aNWpo4MCBio2N1WeffaaYmBjvPMOGDZPdbldQUJC6d++ujIwM/fe//1V4eLh3nsLCQp+XYRhVUv/gwYN9go0k9e/fX7GxsT49LytXrtSRI0d8Atmnn36qq666SnXq1PGpvX///pKkNWvWVMk2AChCuAFQId5++21t3LhRCQkJOnLkiP7v//5P3bt395nnmWee0caNG7VmzRpNnjxZR48e1ZAhQ5SXl+edx263+7zeeustSVL9+vV1/PhxZWVlVUr9tWvXLjbNZrNp+PDhWrp0qdLS0iQVXfpeu3Zt9evXzzvf0aNH9cknnxSr/bLLLpMkJScnV0rNAErGaSkAFaJVq1beAcJn07hxY+88V155pQIDA/XII4/olVde0YMPPihJ2rhxo88yjRo1kiT169dPq1at0ieffKKbb775vPW4XC6lp6cXm362oGGxWEqcPmrUKD333HN6//33NWzYMC1btkzjx4+X1Wr1zlOrVi21bdtWTz75ZInrqFOnznnrBVBxCDcA/Obhhx/WggUL9PTTT+vuu+9WjRo1zhqQRo8ereeee04PP/ywevTo4b28/EwfffSRrr/+eklSw4YNtWTJEuXl5Xkv6U5JSdH69esVGhpa6hpbtWqlLl26aP78+XK73crLy9OoUaN85hk4cKCWL1+uJk2aKCIiotTrBlA5OC0FwG/sdrueeuoppaSk6OWXXz7nvGFhYfrPf/6j3NxctW/fXtOmTdPq1au1Zs0avfHGG+rVq5dGjx7tnX/48OE6ceKEbr/9dq1atUqLFi1Snz59yhRsTrvzzjv1ww8/6Omnn1Z8fLxatGjh0z5t2jTZ7XbFx8drzpw5+vLLL7V8+XLNnj1bAwcO1KFDh8r8mQDKj3ADwK9uvPFGdenSRTNnzizxNNKZOnfurG3btunOO+/Uv//9bw0ZMkT9+vXTM888o5YtW2rt2rXeebt376633npLP/30k6677jpNnz5dkyZNKvHeN+dz8803KzAwUIcOHSrWayMVjdfZtGmT+vbtq+eee07XXnuthg8frjfffFNXXHEFvTlAFbMYVXUpAgAAQBWg5wYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJjKJXeHYo/HoyNHjqhGjRpnvd06AAC4uBiGoczMTNWpU0cBAefum7nkws2RI0cUFxfn7zIAAEA5HDx4UPXq1TvnPJdcuKlRo4akop1TntuwAwCAqpeRkaG4uDjvcfxcLrlwc/pUVGhoKOEGAIBqpjRDShhQDAAATIVwAwAATIVwAwAATOWSG3MDACg9j8ej/Px8f5eBS4TD4TjvZd6lQbgBAJQoPz9fe/fulcfj8XcpuEQEBASoUaNGcjgcF7Qewg0AoBjDMJSYmCir1aq4uLgK+WsaOJfTN9lNTExU/fr1L+hGu4QbAEAxhYWFys7OVp06dRQUFOTvcnCJiIqK0pEjR1RYWCi73V7u9RDFAQDFuN1uSbrg0wNAWZz+vp3+/pUX4QYAcFY8gw9VqaK+b4QbAABgKn4NN998840GDRqkOnXqyGKx6OOPPz7vMmvWrFHHjh3lcrnUuHFjvf7665VfKAAAKLdt27apXr16ysrKqpLP82u4ycrKUrt27fTqq6+Wav69e/fqT3/6k3r06KGEhAT94x//0Lhx4/Thhx9WcqUAgOpg5MiRslgsslgsstvtaty4sR588EFlZWVp37593jaLxaKwsDB17dpVn3zySanX36JFCzkcDh0+fLhYW8OGDfXSSy8Vm/7SSy+pYcOGPtMyMjI0efJktWzZUi6XS7GxserTp48++ugjGYZR1s2WJKWmpmr48OEKCwtTWFiYhg8frrS0tHMuc/ToUY0cOdI7cPzaa6/Vrl27vO0nTpzQfffdpxYtWigoKEj169fXuHHjlJ6e7p3n66+/9tmvZ742btwoSbr88svVuXNnvfjii+XatrLya7jp37+/pk+fruuvv75U87/++uuqX7++XnrpJbVq1UpjxozRnXfeqeeff76SKwUAVBfXXnutEhMTtWfPHk2fPl2zZ8/Wgw8+6G3//PPPlZiYqA0bNqhz58664YYb9OOPP553vevWrVNubq5uvPFGLViwoNz1paWlKT4+Xm+//bYmTZqkLVu26JtvvtGwYcP08MMP+wSHsrj11lu1detWrVixQitWrNDWrVs1fPjws85vGIaGDBmiPXv26D//+Y8SEhLUoEED9enTx9vDcuTIER05ckTPP/+8tm3bpgULFmjFihUaPXq0dz3x8fFKTEz0eY0ZM0YNGzZUp06dvPONGjVKc+bMueDBwqVRrS4F/+6779S3b1+faf369dO8efNUUFBQ4mVjeXl5ysvL877PyMiotPoe+8+P2pGUqSCHVUEOmwIdVgU7rAp02E5NK5oe5LAq0Pv+99NsCrJbFRDAID4AKA+n06nY2FhJRQf8r776Sh9//LH+3//7f5KkmjVrKjY2VrGxsXryySf1yiuv6KuvvlKbNm3Oud558+bp1ltvVc+ePfW3v/1N//jHP8o1APYf//iH9u3bp507d6pOnTre6c2bN9ctt9wil8tV5nX+/PPPWrFihb7//nt16dJFkjR37lx169ZNO3bsUIsWLYots2vXLn3//ff68ccfddlll0mSZs+erejoaC1atEhjxoxRmzZtfM6ONGnSRE8++aRuv/12FRYWymazyeFwePe3JBUUFGjZsmW69957ffZPv379lJKSojVr1qh3795l3sayqFbhJikpSTExMT7TYmJiVFhYqOTkZNWuXbvYMjNmzNDUqVOrpL464YHKyClQdr5b6TkFSkzPUXa+WzkFbmXluZWTX6jsArdK0+PosgcUBSS7VcHOUwHJbvWGoOBT4elsASn4zLB0xjIuewBXPwC4pAQGBqqgoKDY9IKCAs2dO1eSzntPlczMTC1ZskQbNmxQy5YtlZWVpa+//lpXXXVVmWrxeDx6//33ddttt/kEm9NCQkK8P48dO1bvvvvuOde3fft21a9fX999953CwsK8wUaSunbtqrCwMK1fv77EcHP6D/8zw5TVapXD4dC6des0ZsyYEj8zPT1doaGhstlKjhDLli1TcnKyRo4c6TPd4XCoXbt2Wrt2LeHm935/YD59bvJsB+xJkyZpwoQJ3vcZGRmKi4urlNrG9mxy3nkMw1BeoUfZ+W5l5RUqp8Ct7Hy3svMLlZ3nVnbBqRCUf8b0fLdyznh/Iitfh1JzlJPvVlZ+obctp+D8XX0WixRoL7kXKdBuU7Dzt5+DHFYFOa2nQtWpnijnGW2/C1pOG8EJMLOcfLd2Hz9Z5Z/bJCpEgQ5ruZb94Ycf9N577+nqq6/2TouPj1dAQIBycnLk8XjUsGFD3XTTTedcz/vvv69mzZp5ezhuvvlmzZs3r8zhJjk5WampqWrZsuV55502bZrP6bSSnA5ISUlJio6OLtYeHR2tpKSkEpdt2bKlGjRooEmTJumf//yngoODNXPmTCUlJSkxMbHEZVJSUvTEE0/o7rvvPmtN8+bNU79+/Uo81tatW1f79u075zZVhGoVbmJjY4v9Ix07dkw2m001a9YscRmn0ymn01kV5ZWKxWKRy26Vy25VZHDF3hzL4zG8YSkn363sglMhKa8oFJ1uy8o7FYgKToemQmWdWuZoRu6p0PRbW3a+W3mF53+2TIBF3sAUVOx03G8BKchuVZDzjPnsVgU7z2g7I0gF2Yt+dti4awHgb7uPn9TAV9ZV+ed+et8f1aZuWOnn//RThYSEqLCwUAUFBbruuuv0yiuvKDs7W5K0ePFitWzZUjt37tT48eP1+uuvKzIyUlLx3pKTJ4vC3Lx583T77bd7p99+++268sorlZaWpvDw8FLXdr4/yM8UHR1dYmA5m5LWaRjGWT/Lbrfrww8/1OjRoxUZGSmr1ao+ffqof//+Jc6fkZGhAQMGqHXr1poyZUqJ8xw6dEgrV67Uv//97xLbAwMDvf8OlalahZtu3boVG9W+atUqderU6YJu02wWAQEWBTttCnZW/D+r22MUBSRvD9Jvwaeo16jw1Km3U20FRfNm5RW1Zee7lZqdU6wnKiffrXz3+YOTLcBSrLfpzFNzp//rO63o9NyZQet0kPIuY7fKZiU4AaXRJCpEn973R798bllcddVVmjNnjux2u+rUqeM9PpzuMYiLi1OzZs3UrFkzhYSE6IYbbtD27dsVHR1dYm/J9u3btWHDBm3cuNE7bkcquovuokWLdM8990iSQkNDSxwMnJaWprCwonAWFRWliIgI/fzzz+fdjrKcloqNjdXRo0eLtR8/frzYcI4zdezYUVu3blV6erry8/MVFRWlLl26+AwElopOy1177bUKCQnR0qVLz3rMnT9/vmrWrKnBgweX2H7ixAk1aXL+sxwXyq/h5uTJk/r111+97/fu3autW7cqMjJS9evX16RJk3T48GG9/fbbkor+oV999VVNmDBBd911l7777jvNmzdPixYt8tcmXDKsARbVcNlVw1XxIbLA7Tkj8PiekvutF+nMIHVG79Op9uOZed62M9fh9px/gJPDFlAUnOynQpPT5nPqjoHhQJFAh7VMPSj+EhwcrKZNm5Zq3p49e6pNmzZ68skn9fLLL5fYWzJv3jxdeeWVeu2113ymv/POO5o3b5433LRs2dJ76fOZNm7c6B3zEhAQoGHDhumdd97RlClTio27ycrKktPplM1mK9NpqW7duik9PV0//PCDOnfuLEnasGGD0tPTFR8ff979cDp87dq1S5s2bdITTzzhbcvIyFC/fv3kdDq1bNmysw54NgxD8+fP1x133HHW8PPjjz9q6NCh563nQvk13GzatMnnfOXpsTEjRozQggULlJiYqAMHDnjbGzVqpOXLl+uBBx7Qa6+9pjp16mjWrFm64YYbqrx2VBy7NUBhgQEKC6zY4GQYhvLdHp/xStln9Bhl/37M0qnTc9lnhKnfDwwvOs3HwHDATP7+97/rxhtv1MMPP6y6dev6tBUUFOidd97RtGnTil1NNWbMGD377LP63//+p3bt2mnChAnq3r27pk2b5j2Af/jhh1qxYoXWr1/vXe6pp57S119/rS5duujJJ5/0nn1Yu3atZsyYoY0bNyo8PLxMp6VatWqla6+9VnfddZf++c9/SpL+8pe/aODAgT6DiVu2bKkZM2boz3/+syRpyZIlioqKUv369bVt2zbdf//9GjJkiPfK5MzMTPXt21fZ2dl69913lZGR4b3qOCoqSlbrb2OhvvzyS+3du9fnMvEz7du3T4cPH1afPn1KtU0Xwq/hplevXue8WVFJ9xHo2bOntmzZUolVwSwsFoucNqucNqvCK/ihxucaGF5Sb9P5BoZnF5waUF6BA8P7tIrRoHbFr8YA4GvgwIFq2LChnnzySc2ePdunbdmyZUpJSfGGgTM1a9ZMl19+uebNm6dZs2apa9euWrlypaZNm+a9md9ll12mlStX+lzFFBERoe+//15PP/20pk+frv379ysiIkKXX365nnvuOW8vSlktXLhQ48aN8waTwYMHF7tJ7o4dO3xOnSUmJmrChAk6evSoateurTvuuEOPPvqot33z5s3asGGDJBXrDdu7d6/PzQnnzZun+Ph4tWrVqsT6Fi1apL59+6pBgwbl2r6ysBjlvRViNZWRkaGwsDDvpWzAxcbjMZRb6P5tDFPBb8HIN0j91otU0sDwX5Iy9cHYbmpfP8Lfm4RqKDc3V3v37lWjRo3Kdd8V4Ex5eXlq1qyZFi1apO7du591vnN978py/K5WA4qBS0FAgOVUb0z5//cscHs09PXv9MDirfrvuB6VMsgcAEpr//79mjx58jmDTUXiMhHAhOzWAL007Aody8zTtE+2+7scAJe45s2bn/PeOBWNcAOYVKNawZoyqLUWbzqoFT+WfEMuADAjwg1gYjd1ilO/y2I08aNtSkrP9Xc5AFAlCDeAiVksFj19fVs5bQF6cMn/5CnFfX+AM11i15zAzyrq+0a4AUwuItih529sp3W/JuvNb/f6uxxUE6fvX5Kfn+/nSnApOf19O/P+OeXBJRTAJaBHsyiN/mMjPbtih+Kb1FLrOtwGAedms9kUFBSk48ePy263KyCAv4VRuTwej44fP66goKCzPnG8tLjPDXCJyC1wa8hr38pjGFp27x/lsl/YX0Ywv/z8fO3du1cez/mf/wZUhICAADVq1EgOR/EHS5fl+E24AS4hO49mauAr63Rr5/p6fPBl/i4H1YDH4+HUFKqMw+E4ay8hN/EDUKLmMTU0qX9LTf1ku3q1iFKvFqV7bg0uXQEBAdyhGNUOJ1GBS8zI+Ia6snmUHlzyf0o5mefvcgCgwnFaCrgEHcvI1bUvr1WH+hGae0dHnjDuZx6Pocy8QqVnFygtJ1+p2QVKy85Xek6B0rJPvXLyT/2cr7ScAqVnFyjf7dHHf+uuJlEh/t4EoNJxWgrAOUWHuvTMDW1119ubtOiHg7q1S31/l2QaBW6PUrPylZKVr5ST+UrJylNadoFSs4vCSVFgKQooaWeEmJJuQWS3WhQW6FBEkF3hQXaFBTrUOCpE4YF2SdIb6/bqaHou4Qb4HcINcIm6pnWMbulcX098ul1dGkdygDyLvEK3UrMKlHwyTyey8nXiVHA5kVX0Pvlk/m/TT+YpI7ew2Doc1gCFnwoo4YEOhQXZ1TQqRBHBDoUF/jbdO0+QQ+GBdgU5rGftVTt4IltvrCvdfYvyCz1Kyy7qEXLaAtSwVvAF7RPgYke4AS5hjw5spQ17UjT+/a368J54OWyXxjC8/EKPUrLydDzzt9exM34+fjKvKMyczFdmXvGw4rIHqGawUzVDHIoMdqhBzSB1qB+uyGCnagYXTYsMcahWsFORIQ4FnyOkXKhvdiVrx9FM76ms3/6br9Ssop+z8t3e+e1Wi7Y93o9bAcDUCDfAJSzIYdPLN7fXn2d/q5c+36mHr23p75IuSE6+W0kZuUpMzykKLBlFQcU3xOQqNbvAZzmLRaoZ7FRUjaJXw5rB6tQg4lR4OSOwBDtUM8ShIIf/f3WGOG2yWy16fc1uOW0Biggq6vmJCHIoItiuuMggRZx6Hx5UdGpr2+F0vfT5LhXyGA6YnP//DwXgV5fXC9MD1zTX86t2qGfzKHVpXNPfJRVjGIbScwpOBZdcHU0/9d9T75PSc5WUkav0HN/QEuK0FQWWkKLQ0jQ6xBtgTk+PruFUZLBDNmv16rWKCHYo4bG+slosCnSUrhcm+4weHOnUQObcQqVk5Sk1O18nsgqUmpWvE9n5urJZFHeyRrVFuAGgsT2b6KtfjmnS0m1acf+VVX56Kju/UIdTc3QoLUeHU3N0JC1HielFPTBHM/KUmJ6j3ILf7pJrsUhRIU7VDnMpNsylro0jFRsWqNgwp2JDA1U7zKXoUOdF0cNSmUKc5du+wa+uU0ZOgVKzC+QuoRfHYpF2JGXqxWFXXGCFJcvJd+tEdr5Ss/JPhap8ZeYWasDltRURXPzOtEBZmfv/fAClYg2waPqf22jArHWau3aP/nZV0wpdf3Z+oQ6eyNH+lCwdOJGtw6dCzOG0olfaGaeJrAEWxYa6VCfcpdiwQLWtF66YUJc3yMSGuhRVwyl7NetpuRj8oWGkhnWKU6DDqprBDkWcOtUWEVR0uu30qa3h8zbIU8q7hOQWuJWWXaATZwSV0/8tNv1Ur9CZQfVMhmFoeLeGFbjFuFQRbgBIklrGhurO7g31ype7dN0VdVQvIqjUyxqGoZSsfO1PydaBE1mn/putAynZ2n8iW8czf7tZoMseoLrhgaobEaS29cLVv02s6kYEqm54kOpGBCqmhrPanSKqLmLDXHpmaNtSzZtyMl9f/Hz01OXsRVeCpZy6Uiw163R48R2sfJrdalFEUFFwCg+yKzLYofqRQd4gFXk6WJ0aHxQZ7FD7aatL7EUCyoNwA8Dr/j7Ntex/RzT1k+2ae0cnnzaPx9DhtBztTc7S/hPZOngiW/tTioLMwRPZPge5WiFFB7P6kUGKb1pLDSKDVL9mkBpEBimqhpObBl7kgh02ffHLMa37NVmSFBZoV83g33p32tQN/S2klBBWQpy2Mv8bWyzSmp3HdTA1R6nZ+RpyRV1d2TyqMjYPlwDCDQCvEKdNjw5srXvfS9CLq3eq0OPRnuNZ2ptc9MorLDqdYA2wqF5EoOpHBqljgwhd36Gu6kcGFwWamkHlHguCi8MLN7XT4bQc1QpxKiLIUSVjsJpF19DWg2k6cCJbiem5sshCuEG58RsIgI8Bl9fWkuaH9PIXuxQb6lLjqGB1ahihGzvFqXFUsBrXClbd8EBOHZlY+KnLx6vSJ/f90fvz0Dnrq/SzYT6EGwA+LBaL3hjRSfmFHgXTAwOgGuI3F4Bi7NYArkYCUG3x2wsAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgKV0sBAKqd3AK3jmXkKSmj6Onwqdn5Gti2jiJ58CZEuAEAXISST+Zp1U9JOpqZp6PpRQEmKSPXG2jScwqKLWMNsOi2Lg38UC0uNoQbAMBFJdBh1Zqdx7Vm53HZAiyKruFUdGjRE+G7Ng5WTJhLMTVcigl1KTasqK3jE6vl8RgyDENp2QVK8oahXDWNDlHHBpH+3ixUIYthlPK59iaRkZGhsLAwpaenKzQ01N/lAAB+J/lknpLScxUT6lLNYIcCAs7/EM7mkz+T0x6gvEKP8k89A+20NnVD9el9PUr12dn5hTqWkafa4S45bdZy1Y/KUZbjNz03AICLSq0Qp2qFOMu0zMPXtlDyyXzFhjoVE+pSTFhRT88rX/6qrQfT5PYYSjlZdEor6YzTXEnpeTqa8dv7zNxCSdJdPRpp8oDWlbF5qAKEGwBAtTemR+MSpzusFu1IylDzRz6T2/PbiQpbgEUxoS5FhzoVG+pS0+haij0ViF7+YpdO5hWFnNMnNyyW8/ce4eJBuAEAmNbNnesrLMih6BpFISY2zHXe013z1+/Typ+O6ttfv1JSRq6ubhmtObd3rOLKcSEINwAA02pVO1StapdtfOVNnepp494TiglzacOeEzqYml1J1aGyEG4AADjDbV0aeC8pf+Tjbdp6MM2/BaHMuEMxAAAwFcINAAAwFcINAAAwFcbcAABwHh6PoeMn82SxSNE1XP4uB+dBuAEA4Bx+TsxUi0c/U4HbUIjTph+n9vN3STgPwg0AAGdxU6c4hTjtqhPu0o6kTC3ccEB5hW4dSctVdn6hLqsTdkHrL3B7lJSeqyNpOTqclqMjaTlKTM/Vn9vXVaeGPA+rvAg3AACcRdt64WpbL1yStHjjAS3cILV4ZIW3/Yu/91STqJCzLp+ZW+ANLYfTcnU4NccnyBzNyNUZN05WRJBdWXluBVgsPuEmr9CtpPRc2a0BqhMeWOHbaTaEGwAASuHqVjF6qF++okKcyit069H//KQDKdlKyz4jwJwRXg6n5XifVSUVPfIhNsyluuGBahAZpG6Na6puRKDqhAeqbnig6oS7FOSwacCstfp+T4rGvrNZielFoSj5ZJ4kKdRl0/89zmmx8yHcAABQCrVCnPrbVU0lSb8kZUiSRi3Y6G2v4bKp7qmg8oeGkRriDS4u1Q0PUlQNp6yleMJ5h/oRWr87WVn5hWoZG6reLWNUO9ylbYfSteiHA5WzcSZDuAEAoIyaR9fQK7e0V7DTqjrhRSEm1GWvkHU/MaRNidPzCj0Vsv5LAeEGAIAyCgiwaFC7Ov4uA2fBTfwAAICp0HMDAEA1YUjaffykDqXmKCe/UP0ui5XFcv5xPJcawg0AANWAPcAit8fQ1S+s8U77fEJPNY0++6XolyrCDQAA1cCAtrUV5LQpuoZTadn5GvvuFhV6GGRcEsINAADVQA2XXYNPDWLeejCtxHmy8gp1JC1HcZFBctmtVVjdxYVwAwBANTX3m73KLXDrYGq2DqXm6ERWviTpr72a6OFrW/rMW+j2yG0YctrMH3oINwAAVDPRNZwKD7Jr474TqhcRqFaxobqmVYziIoP0/Kod2nIgVbO+2KWDJ4pCz8HUbCWm5yo21KVvJ/b2d/mVjnADAEA1Uyc8UFsf61ti2783HdT63SnadfSk6kUEql5kkNrGhWl/cra+3HGsiiv1D8INAAAmsmBUZxV6PApy+B7i31q/j3ADAACqH4ctQI5L/B69l/bWAwAA0yHcAAAAU/F7uJk9e7YaNWokl8uljh07au3ateecf+HChWrXrp2CgoJUu3ZtjRo1SikpKVVULQAA1Z9hGMo38VPG/RpuFi9erPHjx2vy5MlKSEhQjx491L9/fx04cKDE+detW6c77rhDo0eP1k8//aQlS5Zo48aNGjNmTBVXDgBA9VPg9qj/y2vVZspKtZmyUscycv1dUqXwa7iZOXOmRo8erTFjxqhVq1Z66aWXFBcXpzlz5pQ4//fff6+GDRtq3LhxatSokf74xz/q7rvv1qZNm6q4cgAAqpeODSLUu0W0OtQP15D2dZXv9igtp8DfZVUKv4Wb/Px8bd68WX37+l6n37dvX61fv77EZeLj43Xo0CEtX75chmHo6NGj+uCDDzRgwICzfk5eXp4yMjJ8XgAAXGra1A3TvJF/0JN/vlzXd6jn73Iqld/CTXJystxut2JiYnymx8TEKCkpqcRl4uPjtXDhQg0bNkwOh0OxsbEKDw/XK6+8ctbPmTFjhsLCwryvuLi4Ct0OAABwcfH7gGKLxeLz3jCMYtNO2759u8aNG6fHHntMmzdv1ooVK7R3716NHTv2rOufNGmS0tPTva+DBw9WaP0AAODi4reb+NWqVUtWq7VYL82xY8eK9eacNmPGDHXv3l0PPfSQJKlt27YKDg5Wjx49NH36dNWuXbvYMk6nU06ns+I3AAAAXJT81nPjcDjUsWNHrV692mf66tWrFR8fX+Iy2dnZCgjwLdlqLXq6qWEYlVMoAAAmted4llb9lKR3vtundBMNLvbr4xcmTJig4cOHq1OnTurWrZv+9a9/6cCBA97TTJMmTdLhw4f19ttvS5IGDRqku+66S3PmzFG/fv2UmJio8ePHq3PnzqpTp44/NwUAgGrDbi0a/jH23c3eaaGBdl13RV1/lVSh/Bpuhg0bppSUFE2bNk2JiYlq06aNli9frgYNGkiSEhMTfe55M3LkSGVmZurVV1/V3//+d4WHh6t379565pln/LUJAABUO23qhOn12zsqIsiuuhGB+uMzX8ntMc8ZEItxiZ3PycjIUFhYmNLT0xUaGurvcgAA8Kv8Qo+aP/KZZt7U7qK+RLwsx2+/Xy0FAABQkfx6WgoAAFwcliYc1mc/JulASrbu6dVEQ9pX3/E39NwAAHAJswVY1DgqWPtSspRf6NGR9Bz971Cav8u6IPTcAABwCQsIsOjLv/fyvu/74hr/FVNB6LkBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAAA+DEM6lJqtNTuPa29ylr/LKTOulgIAAF4WWbRg/T4tWL9PkhTfpKbeu6urf4sqI8INAADwevjaFtqbnKUm0SF697v9ysitfk8LJ9wAAACvq1vFeH/+5H9HCDcAAMB88gs92peSJWuARU2iQvxdznkRbgAAwFklHEhTq8dWyO0xFBns0JZHr/F3SedFuAEAACW6qVOcwgMdahIdrO1HMvTRlsP+LqlUCDcAAKBEXRvXVNfGNSVJ87/d6+dqSo/73AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFOxlWehrKwsPf300/riiy907NgxeTwen/Y9e/ZUSHEAAABlVa5wM2bMGK1Zs0bDhw9X7dq1ZbFYKrouAACAcilXuPnss8/03//+V927d6/oegAAAC5IucbcREREKDIyskIKmD17tho1aiSXy6WOHTtq7dq155w/Ly9PkydPVoMGDeR0OtWkSRO9+eabFVILAACo/soVbp544gk99thjys7OvqAPX7x4scaPH6/JkycrISFBPXr0UP/+/XXgwIGzLnPTTTfpiy++0Lx587Rjxw4tWrRILVu2vKA6AACAeVgMwzDKulD79u21e/duGYahhg0bym63+7Rv2bKlVOvp0qWLOnTooDlz5nintWrVSkOGDNGMGTOKzb9ixQrdfPPN2rNnT7l7jjIyMhQWFqb09HSFhoaWax0AAFxq5n+7V09/9oveHdNF2w6lK/lkniZc01w2a9VceF2W43e5xtwMGTKkPIv5yM/P1+bNmzVx4kSf6X379tX69etLXGbZsmXq1KmTnn32Wb3zzjsKDg7W4MGD9cQTTygwMPCCawIAACWzBViUV+jRja9/pwCL5DGk6zvUU9PoEH+XVky5ws2UKVMu+IOTk5PldrsVExPjMz0mJkZJSUklLrNnzx6tW7dOLpdLS5cuVXJysv7617/qxIkTZx13k5eXp7y8PO/7jIyMC64dAIBLzeB2dRUaaFez6BpKy8nXrXM3+LuksypXuDlt8+bN+vnnn2WxWNS6dWu1b9++zOv4/WXkhmGc9dJyj8cji8WihQsXKiwsTJI0c+ZMDR06VK+99lqJvTczZszQ1KlTy1wXAAD4TViQXdddUVeStHHfCT9Xc27lOlF27Ngx9e7dW3/4wx80btw43XvvverYsaOuvvpqHT9+vFTrqFWrlqxWa7FemmPHjhXrzTmtdu3aqlu3rjfYSEVjdAzD0KFDh0pcZtKkSUpPT/e+Dh48WMqtBAAA1VG5ws19992njIwM/fTTTzpx4oRSU1P1448/KiMjQ+PGjSvVOhwOhzp27KjVq1f7TF+9erXi4+NLXKZ79+46cuSITp486Z22c+dOBQQEqF69eiUu43Q6FRoa6vMCAADmVa5ws2LFCs2ZM0etWrXyTmvdurVee+01ffbZZ6Vez4QJE/TGG2/ozTff1M8//6wHHnhABw4c0NixYyUV9brccccd3vlvvfVW1axZU6NGjdL27dv1zTff6KGHHtKdd97JgGIAACCpnGNuPB5Pscu/Jclutxd7ztS5DBs2TCkpKZo2bZoSExPVpk0bLV++XA0aNJAkJSYm+tzzJiQkRKtXr9Z9992nTp06qWbNmrrppps0ffr08mwGAAAwoXLd5+a6665TWlqaFi1apDp16kiSDh8+rNtuu00RERFaunRphRdaUbjPDQAAF2bjvhO68fXv9PmEnlV2KXhZjt/lOi316quvKjMzUw0bNlSTJk3UtGlTNWrUSJmZmXrllVfKVTQAAEBFKNdpqbi4OG3ZskWrV6/WL7/8IsMw1Lp1a/Xp06ei6wMAACiTC7rPzTXXXKNrrrmmomoBAAC4YKUON7NmzdJf/vIXuVwuzZo165zzlvZycAAAgIpW6nDz4osv6rbbbpPL5dKLL7541vksFgvhBgAA+E2pw83evXtL/BkAAOBiUiHPKXe73dq6datSU1MrYnUAAADlVq5wM378eM2bN09SUbC58sor1aFDB8XFxenrr7+uyPoAAADKpFzh5oMPPlC7du0kSZ988on27dunX375RePHj9fkyZMrtEAAAICyKFe4SU5OVmxsrCRp+fLluvHGG9W8eXONHj1a27Ztq9ACAQAAyqJc4SYmJkbbt2+X2+3WihUrvDfvy87OltVqrdACAQAAyqJcN/EbNWqUbrrpJtWuXVsWi8V7I78NGzaoZcuWFVogAABAWZQr3Dz++ONq06aNDh48qBtvvFFOp1OSZLVaNXHixAotEAAAoCzK/fiFoUOHFps2YsSICyoGAADgQvH4BQAAYCo8fgEAAJgKj18AAACmUiGPXwAAALhYlCvcDB06VE8//XSx6c8995xuvPHGCy4KAABUH4Vuj79L8FGucLNmzRoNGDCg2PRrr71W33zzzQUXBQAALn7T/7tdvZ//Ws0f+Uzrf032dzle5Qo3J0+elMPhKDbdbrcrIyPjgosCAAAXr9hQl2qFOJSWXaCuTWrKY0jHMvP8XZZXucJNmzZttHjx4mLT33//fbVu3fqCiwIAABevuMggbXrkGn38t+56bODFd9wv1038Hn30Ud1www3avXu3evfuLUn64osvtGjRIi1ZsqRCCwQAACiLcoWbwYMH6+OPP9ZTTz2lDz74QIGBgWrbtq0+//xz9ezZs6JrBAAAKLVyP35hwIABJQ4qBgAA8Kdy3+cmLS1Nb7zxhv7xj3/oxIkTkqQtW7bo8OHDFVYcAABAWZWr5+b//u//1KdPH4WFhWnfvn0aM2aMIiMjtXTpUu3fv19vv/12RdcJAABQKuXquZkwYYJGjhypXbt2yeVyeaf379+f+9wAAAC/Kle42bhxo+6+++5i0+vWraukpKQLLgoAAKC8yhVuXC5XiTfr27Fjh6Kioi64KAAAgPIqV7i57rrrNG3aNBUUFEiSLBaLDhw4oIkTJ+qGG26o0AIBAADKolzh5vnnn9fx48cVHR2tnJwc9ezZU02bNlWNGjX05JNPVnSNAAAApVauq6VCQ0O1bt06ffnll9qyZYs8Ho86dOigPn36VHR9AAAAZVLmcFNYWCiXy6WtW7eqd+/e3scvAAAAXAzKfFrKZrOpQYMGcrvdlVEPAADABSnXmJtHHnlEkyZN8t6ZGAAA4GJRrjE3s2bN0q+//qo6deqoQYMGCg4O9mnfsmVLhRQHAABQVuUKN0OGDJHFYpFhGBVdDwAAwAUpU7jJzs7WQw89pI8//lgFBQW6+uqr9corr6hWrVqVVR8AAECZlGnMzZQpU7RgwQINGDBAt9xyiz7//HPdc889lVUbAABAmZWp5+ajjz7SvHnzdPPNN0uSbrvtNnXv3l1ut1tWq7VSCgQAANWD22NoX0qW6oYHymX3Xy4oU8/NwYMH1aNHD+/7zp07y2az6ciRIxVeGAAAqD5eWL1Dlz++Ule/sEZzvt7t11rK1HPjdrvlcDh8V2CzqbCwsEKLAgAA1YPDGqC+rWNktwaobb0wvfntXmXl+TcXlCncGIahkSNHyul0eqfl5uZq7NixPpeDf/TRRxVXIQAAuGgFBFj0rzs6ed8v2XzIj9UUKVO4GTFiRLFpt99+e4UVAwAAcKHKFG7mz59fWXUAAABUiHI9fgEAAOBiRbgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACm4vdwM3v2bDVq1Egul0sdO3bU2rVrS7Xct99+K5vNpiuuuKJyCwQAANWKX8PN4sWLNX78eE2ePFkJCQnq0aOH+vfvrwMHDpxzufT0dN1xxx26+uqrq6hSAABQXfg13MycOVOjR4/WmDFj1KpVK7300kuKi4vTnDlzzrnc3XffrVtvvVXdunWrokoBAEB14bdwk5+fr82bN6tv374+0/v27av169efdbn58+dr9+7dmjJlSqk+Jy8vTxkZGT4vAABgXn4LN8nJyXK73YqJifGZHhMTo6SkpBKX2bVrlyZOnKiFCxfKZrOV6nNmzJihsLAw7ysuLu6CawcAABcvvw8otlgsPu8Nwyg2TZLcbrduvfVWTZ06Vc2bNy/1+idNmqT09HTv6+DBgxdcMwAAuHiVrvujEtSqVUtWq7VYL82xY8eK9eZIUmZmpjZt2qSEhATde++9kiSPxyPDMGSz2bRq1Sr17t272HJOp1NOp7NyNgIAAFx0/NZz43A41LFjR61evdpn+urVqxUfH19s/tDQUG3btk1bt271vsaOHasWLVpo69at6tKlS1WVDgAALmJ+67mRpAkTJmj48OHq1KmTunXrpn/96186cOCAxo4dK6nolNLhw4f19ttvKyAgQG3atPFZPjo6Wi6Xq9h0AABw6fJruBk2bJhSUlI0bdo0JSYmqk2bNlq+fLkaNGggSUpMTDzvPW8AAADOZDEMw/B3EVUpIyNDYWFhSk9PV2hoqL/LAQDAVPrMXKNezaP0yMDWFbreshy//X61FAAAQEUi3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFPxe7iZPXu2GjVqJJfLpY4dO2rt2rVnnfejjz7SNddco6ioKIWGhqpbt25auXJlFVYLAAAudn4NN4sXL9b48eM1efJkJSQkqEePHurfv78OHDhQ4vzffPONrrnmGi1fvlybN2/WVVddpUGDBikhIaGKKwcAABcri2EYhr8+vEuXLurQoYPmzJnjndaqVSsNGTJEM2bMKNU6LrvsMg0bNkyPPfZYqebPyMhQWFiY0tPTFRoaWq66AQBAyfrMXKNezaP0yMDWFbreshy//dZzk5+fr82bN6tv374+0/v27av169eXah0ej0eZmZmKjIw86zx5eXnKyMjweQEAAPPyW7hJTk6W2+1WTEyMz/SYmBglJSWVah0vvPCCsrKydNNNN511nhkzZigsLMz7iouLu6C6AQDAxc3vA4otFovPe8Mwik0ryaJFi/T4449r8eLFio6OPut8kyZNUnp6uvd18ODBC64ZAABcvGz++uBatWrJarUW66U5duxYsd6c31u8eLFGjx6tJUuWqE+fPuec1+l0yul0XnC9AACgevBbz43D4VDHjh21evVqn+mrV69WfHz8WZdbtGiRRo4cqffee08DBgyo7DIBAEA147eeG0maMGGChg8frk6dOqlbt27617/+pQMHDmjs2LGSik4pHT58WG+//bakomBzxx136OWXX1bXrl29vT6BgYEKCwvz23YAAICLh1/DzbBhw5SSkqJp06YpMTFRbdq00fLly9WgQQNJUmJios89b/75z3+qsLBQf/vb3/S3v/3NO33EiBFasGBBVZcPAAAuQn69z40/cJ8bAAAqzyV9nxsAAIDKQLgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmYvN3AWaTmZmpkydP+kxzuVyKiIhQYWGhjh8/XmyZ2rVrS5KSk5NVUFDg0xYeHq7AwEBlZWUpIyPDp83hcKhmzZryeDw6evRosfVGR0fLarXqxIkTysvL82mrUaOGQkJClJOTo7S0NJ82m82mqKgoSVJiYmKx9daqVUt2u11paWnKycnxaQsODlZoaKjy8vJ04sQJn7aAgADFxMRIko4ePSqPx+PTHhkZKafTqYyMDGVlZfm0BQYGKjw8XAUFBUpOTi5W0+l9ePz4cRUWFvq0nd6HJ0+eVGZmpk+b0+lUZGSk3G63jh07Vmy9MTExCggIUEpKivLz833aQkNDFRwcXOI+tNvtqlWrlqSS92FUVJRsNptSU1OVm5vr0xYSEqIaNWqUuA+tVquio6MllbwPa9asKYfDUeI+DAoKUlhYWIn70GKxKDY2VlLJ+zAiIkIul6vEfXj6+322fRgbGyuLxVLiPgwLC1NQUJCys7OVnp7u03b6+20YhpKSkoqt9/T3u6R9ePr7nZubq9TUVJ+2M7/fSUlJMgzDp/309zs9PV3Z2dk+bae/3/n5+UpJSfFpO/P7fezYMbndbp/2099vfkfwO0Iy9++IYHemjIKQYttUlQg3FWzz5s1as2aNz7TLL79c119/vTIyMvSvf/2r2DJTpkyRJP3nP//RoUOHfNr+/Oc/q23btvrpp5/02Wef+bQ1adJEt99+uwoKCkpc74MPPqjg4GCtXLlSO3fu9Gnr27evunXrpj179uiDDz7waYuNjdXdd98tSZo3b16xX9L33HOPoqOj9c033yghIcGnrXv37urTp48SExP11ltv+bTVqFFDEyZMkCQtXLiw2C+RESNGqGHDhvrhhx/07bff+rS1b99egwcPVmpqarFttVqteuSRRyRJH330UbED4dChQ3XZZZdp27ZtWrVqlU9b8+bNdcsttyg3N7fEfThx4kQ5nU599tln2r17t09b//791blzZ+3atUtLly71aatXr55Gjx4tSSWu97777lNkZKS++uorbdu2zaetZ8+e6tWrlw4ePKiFCxf6tEVERGjcuHGSpLfffrvYwffOO+9UXFycvvvuO33//fc+bZ06ddKAAQOUnJxcrCaHw6FJkyZJkpYsWVLsAHvzzTerRYsWSkhI0JdffunT1rp1a914443KysoqcVsnT54sm82mTz75RPv37/dpGzRokDp06KBffvlFn3zyiU9bgwYNNHLkSLnd7hLX+8ADDyg0NFSff/65tm/f7tPWu3dv9ejRQ/v379f777/v0xYVFaW//vWvkqT58+cXOyD95S9/Ue3atbVu3Tpt2rTJp61r167q16+fjh49qjfffNOnLSgoSA899JAk6f333y8Wqm677TY1bdqU3xH8jpBk7t8RHbI3Kzqvg6SOxbarqliM3//ZYnIZGRkKCwtTenq6QkNDK3z9/FXGX2WSuf8qo+eGnht+R/yG3xFFfv874nSNFaksx2/CDQAAuOiV5fjNgGIAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqNn8XUNVOPwQ9IyPDz5UAAIDSOn3cPn0cP5dLLtxkZmZKkuLi4vxcCQAAKKvMzEyFhYWdcx6LUZoIZCIej0dHjhxRjRo1ZLFYKnTdGRkZiouL08GDBxUaGlqh68Zv2M9Vg/1cNdjPVYd9XTUqaz8bhqHMzEzVqVNHAQHnHlVzyfXcBAQEqF69epX6GaGhofyPUwXYz1WD/Vw12M9Vh31dNSpjP5+vx+Y0BhQDAABTIdwAAABTIdxUIKfTqSlTpsjpdPq7FFNjP1cN9nPVYD9XHfZ11bgY9vMlN6AYAACYGz03AADAVAg3AADAVAg3AADAVAg3AADAVAg3ZTR79mw1atRILpdLHTt21Nq1a885/5o1a9SxY0e5XC41btxYr7/+ehVVWr2VZT9/9NFHuuaaaxQVFaXQ0FB169ZNK1eurMJqq6+yfp9P+/bbb2Wz2XTFFVdUboEmUdb9nJeXp8mTJ6tBgwZyOp1q0qSJ3nzzzSqqtvoq635euHCh2rVrp6CgINWuXVujRo1SSkpKFVVbPX3zzTcaNGiQ6tSpI4vFoo8//vi8y/jlOGig1N5//33Dbrcbc+fONbZv327cf//9RnBwsLF///4S59+zZ48RFBRk3H///cb27duNuXPnGna73fjggw+quPLqpaz7+f777zeeeeYZ44cffjB27txpTJo0ybDb7caWLVuquPLqpaz7+bS0tDSjcePGRt++fY127dpVTbHVWHn28+DBg40uXboYq1evNvbu3Wts2LDB+Pbbb6uw6uqnrPt57dq1RkBAgPHyyy8be/bsMdauXWtcdtllxpAhQ6q48upl+fLlxuTJk40PP/zQkGQsXbr0nPP76zhIuCmDzp07G2PHjvWZ1rJlS2PixIklzv/www8bLVu29Jl29913G127dq20Gs2grPu5JK1btzamTp1a0aWZSnn387Bhw4xHHnnEmDJlCuGmFMq6nz/77DMjLCzMSElJqYryTKOs+/m5554zGjdu7DNt1qxZRr169SqtRrMpTbjx13GQ01KllJ+fr82bN6tv374+0/v27av169eXuMx3331XbP5+/fpp06ZNKigoqLRaq7Py7Off83g8yszMVGRkZGWUaArl3c/z58/X7t27NWXKlMou0RTKs5+XLVumTp066dlnn1XdunXVvHlzPfjgg8rJyamKkqul8uzn+Ph4HTp0SMuXL5dhGDp69Kg++OADDRgwoCpKvmT46zh4yT04s7ySk5PldrsVExPjMz0mJkZJSUklLpOUlFTi/IWFhUpOTlbt2rUrrd7qqjz7+fdeeOEFZWVl6aabbqqMEk2hPPt5165dmjhxotauXSubjV8dpVGe/bxnzx6tW7dOLpdLS5cuVXJysv7617/qxIkTjLs5i/Ls5/j4eC1cuFDDhg1Tbm6uCgsLNXjwYL3yyitVUfIlw1/HQXpuyshisfi8Nwyj2LTzzV/SdPgq634+bdGiRXr88ce1ePFiRUdHV1Z5plHa/ex2u3Xrrbdq6tSpat68eVWVZxpl+T57PB5ZLBYtXLhQnTt31p/+9CfNnDlTCxYsoPfmPMqyn7dv365x48bpscce0+bNm7VixQrt3btXY8eOrYpSLyn+OA7y51cp1apVS1artdhfAceOHSuWSk+LjY0tcX6bzaaaNWtWWq3VWXn282mLFy/W6NGjtWTJEvXp06cyy6z2yrqfMzMztWnTJiUkJOjee++VVHQQNgxDNptNq1atUu/evauk9uqkPN/n2rVrq27dugoLC/NOa9WqlQzD0KFDh9SsWbNKrbk6Ks9+njFjhrp3766HHnpIktS2bVsFBwerR48emj59Oj3rFcRfx0F6bkrJ4XCoY8eOWr16tc/01atXKz4+vsRlunXrVmz+VatWqVOnTrLb7ZVWa3VWnv0sFfXYjBw5Uu+99x7nzEuhrPs5NDRU27Zt09atW72vsWPHqkWLFtq6dau6dOlSVaVXK+X5Pnfv3l1HjhzRyZMnvdN27typgIAA1atXr1Lrra7Ks5+zs7MVEOB7CLRarZJ+61nAhfPbcbBShyubzOlLDefNm2ds377dGD9+vBEcHGzs27fPMAzDmDhxojF8+HDv/KcvgXvggQeM7du3G/PmzeNS8FIo635+7733DJvNZrz22mtGYmKi95WWluavTagWyrqff4+rpUqnrPs5MzPTqFevnjF06FDjp59+MtasWWM0a9bMGDNmjL82oVoo636eP3++YbPZjNmzZxu7d+821q1bZ3Tq1Mno3LmzvzahWsjMzDQSEhKMhIQEQ5Ixc+ZMIyEhwXvJ/cVyHCTclNFrr71mNGjQwHA4HEaHDh2MNWvWeNtGjBhh9OzZ02f+r7/+2mjfvr3hcDiMhg0bGnPmzKniiqunsuznnj17GpKKvUaMGFH1hVczZf0+n4lwU3pl3c8///yz0adPHyMwMNCoV6+eMWHCBCM7O7uKq65+yrqfZ82aZbRu3doIDAw0ateubdx2223GoUOHqrjq6uWrr7465+/bi+U4aDEM+t8AAIB5MOYGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGACQ1bNhQL730kve9xWLRxx9/7Ld6AJQf4QaA340cOVIWi0UWi0U2m03169fXPffco9TUVH+XBqAaItwAuChce+21SkxM1L59+/TGG2/ok08+0V//+ld/lwWgGiLcALgoOJ1OxcbGql69eurbt6+GDRumVatWedvnz5+vVq1ayeVyqWXLlpo9e7bP8ocOHdLNN9+syMhIBQcHq1OnTtqwYYMkaffu3bruuusUExOjkJAQ/eEPf9Dnn39epdsHoOrY/F0AAPzenj17tGLFCtntdknS3LlzNWXKFL366qtq3769EhISdNdddyk4OFgjRozQyZMn1bNnT9WtW1fLli1TbGystmzZIo/HI0k6efKk/vSnP2n69OlyuVx66623NGjQIO3YsUP169f356YCqASEGwAXhU8//VQhISFyu93Kzc2VJM2cOVOS9MQTT+iFF17Q9ddfL0lq1KiRtm/frn/+858aMWKE3nvvPR0/flwbN25UZGSkJKlp06bedbdr107t2rXzvp8+fbqWLl2qZcuW6d57762qTQRQRQg3AC4KV111lebMmaPs7Gy98cYb2rlzp+677z4dP35cBw8e1OjRo3XXXXd55y8sLFRYWJgkaevWrWrfvr032PxeVlaWpk6dqk8//VRHjhxRYWGhcnJydODAgSrZNgBVi3AD4KIQHBzs7W2ZNWuWrrrqKk2dOtXbszJ37lx16dLFZxmr1SpJCgwMPOe6H3roIa1cuVLPP/+8mjZtqsDAQA0dOlT5+fmVsCUA/I1wA+CiNGXKFPXv31/33HOP6tatqz179ui2224rcd62bdvqjTfe0IkTJ0rsvVm7dq1GjhypP//5z5KKxuDs27evMssH4EdcLQXgotSrVy9ddtlleuqpp/T4449rxowZevnll7Vz505t27ZN8+fP947JueWWWxQbG6shQ4bo22+/1Z49e/Thhx/qu+++k1Q0/uajjz7S1q1b9b///U+33nqrd7AxAPMh3AC4aE2YMEFz585Vv3799MYbb2jBggW6/PLL1bNnTy1YsECNGjWSJDkcDq1atUrR0dH605/+pMsvv1xPP/2097TViy++qIiICMXHx2vQoEHq16+fOnTo4M9NA1CJLIZhGP4uAgAAoKLQcwMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEzl/wPOqyQHaVB2kAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utility_functions import FDRthreshold_js, ROC_PR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# # =============================================================================\n",
    "# # ROC & PR curves\n",
    "# # =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "y_test = np.array(results['y_test'])\n",
    "y_pred_prob = np.array(results['results']['Y_pred_prob'])\n",
    "\n",
    "ls_roc_auc, ls_fpr, ls_tpr, ls_pr_auc, ls_precision, ls_recall, pr_no_skill, ls_roc_auc_noskill, ls_fpr_noskill, ls_tpr_noskill = ROC_PR(y_pred_prob, y_test)\n",
    "\n",
    "#ROC\n",
    "plt.figure()\n",
    "#plt.plot(ls_fpr, ls_tpr, lw=1, color=color_ls[met], label=met+\" (AUC={})\".format(np.round(ls_roc_auc[met],3)))\n",
    "plt.plot(ls_fpr, ls_tpr, lw=1, label=f\"ROC-AUC={ls_roc_auc:.3f})\")\n",
    "plt.plot(ls_fpr_noskill, ls_tpr_noskill, linestyle='--', lw=1, color='gray')  #'No Skill'\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title('ROC-Curve')\n",
    "plt.legend()\n",
    "# plt.savefig(visualisation_path + 'ROC_' + planet + '_alpha' + str(alpha) + '_bal' + str(bal) + '_combined_CV_' + str(plotname) + '_version' + str(version) + 'frame' + str(frame) + '_fold' + str(j) + '_js.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#PR\n",
    "plt.figure()\n",
    "#plt.plot(ls_recall, ls_precision[met], lw=1, color=color_ls[met], label=met + \" (AUC={})\".format(np.round(ls_pr_auc[met],3)))\n",
    "plt.plot(ls_recall, ls_precision, lw=1, label=f\"PR-AUC={ls_pr_auc:.3f})\")\n",
    "plt.plot([0, 1], [pr_no_skill, pr_no_skill], linestyle='--', lw=1, color='gray')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('PR-Curve')\n",
    "plt.legend()\n",
    "#plt.savefig(visualisation_path + 'PR_' + planet + '_alpha' + str(alpha) + '_bal' + str(bal) + '_combined_CV_' + str(plotname) + '_version' + str(version) + 'frame' + str(frame) + '_fold' + str(j) + '_js.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7751ff-c72b-4932-9e91-f7cd8f7839e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.15.0",
   "language": "python",
   "name": "tensorflow-2.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

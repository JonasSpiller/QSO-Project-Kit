{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544a1e96-521c-4bd0-b109-e0edbcb7ae1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fitsio\n",
      "  Using cached fitsio-1.2.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy in /global/common/software/nersc9/tensorflow/2.15.0/lib/python3.9/site-packages (from fitsio) (1.26.3)\n",
      "Using cached fitsio-1.2.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (825 kB)\n",
      "Installing collected packages: fitsio\n",
      "Successfully installed fitsio-1.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d4c4e9-3db6-4b9a-8d86-5fb249727bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 09:39:58.762701: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-22 09:39:58.762737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-22 09:39:58.806602: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-22 09:40:03.728887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n",
      "GPU Devices:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from utility_functions import extract_data_from_fits\n",
    "from utility_functions import train_CNN_js\n",
    "from MLmodels import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pytz\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Devices: \", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# For saving the progress to txt file\n",
    "zurich_timezone = pytz.timezone('Europe/Zurich')\n",
    "\n",
    "start_global = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f4272e-ee07-4049-896c-16a5b44e5f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch42.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch39.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch3.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch9.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch48.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch6.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch59.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch54.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch17.fits\n",
      "Processing file: /pscratch/sd/j/jspiller/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/modified_minsignal2_desi_bright_qso_batch43.fits\n",
      "88678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.expandvars('$SCRATCH/DATA/modifiedMainQSO/modifiedMainQSO_minsignal2_amplified5/A/')\n",
    "results_path = os.path.expandvars('$SCRATCH/RESULTS/modifiedMainQSO_minsignal2_amplified5/A/')\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "flux_list = []\n",
    "labels_list = []\n",
    "\n",
    "fits_files = [os.path.join(data_path, file) for file in os.listdir(data_path)[:10] if file.endswith('.fits')]\n",
    "\n",
    "for fits_file in fits_files:\n",
    "    flux, labels, _ = extract_data_from_fits(fits_file)\n",
    "    flux_list.append(flux)\n",
    "    labels_list.append(labels)\n",
    "\n",
    "# Concatenate all flux and labels arrays\n",
    "all_flux = np.concatenate(flux_list, axis=0)\n",
    "all_labels = np.concatenate(labels_list, axis=0)\n",
    "print(len(all_labels))\n",
    "\n",
    "x_train, x_testvalid, y_train, y_testvalid = train_test_split(all_flux, all_labels, train_size=0.7, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_testvalid, y_testvalid, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize and then normalize each spectrum individually\n",
    "x_train = np.array([(x - np.mean(x)) / np.std(x) for x in x_train])\n",
    "x_valid = np.array([(x - np.mean(x)) / np.std(x) for x in x_valid])\n",
    "x_test = np.array([(x - np.mean(x)) / np.std(x) for x in x_test])\n",
    "\n",
    "# Normalize each standardized spectrum (min-max normalization to [-1, 1])\n",
    "x_train = np.array([x / np.max(np.abs(x)) for x in x_train])\n",
    "x_valid = np.array([x / np.max(np.abs(x)) for x in x_valid])\n",
    "x_test = np.array([x / np.max(np.abs(x)) for x in x_test])\n",
    "\n",
    "# Expand Dimensions to Channels\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_valid = np.expand_dims(x_valid, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_valid = y_valid.astype('float32')\n",
    "y_test  = y_test.astype('float32')\n",
    "\n",
    "del all_flux, all_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059d7c64-3fd7-44c8-97bd-d2095204b24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 7777, 64)          384       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 2592, 64)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 2588, 32)          10272     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1294, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 41408)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 41408)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 41409     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52065 (203.38 KB)\n",
      "Trainable params: 52065 (203.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[54.5234375, 62.18780517578125, 0.005394393920898438, 0.46049804687500007, 5.65716552734375, 78.08477783203125, 0.21668090820312502]\n",
      "Epoch 1/62\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "nid001184:731735:735250 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn\n",
      "nid001184:731735:735250 [0] NCCL INFO Bootstrap : Using hsn0:10.249.5.56<0>\n",
      "nid001184:731735:735250 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\n",
      "nid001184:731735:735250 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\n",
      "nid001184:731735:735252 [0] NCCL INFO cudaDriverVersion 12040\n",
      "NCCL version 2.16.5+cudaCUDA_MAJOR.CUDA_MINOR\n",
      "nid001184:731735:735261 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.6.0-hcopy\n",
      "nid001184:731735:735261 [0] NCCL INFO NET/OFI Selected Provider is cxi (found 8 nics)\n",
      "nid001184:731735:735261 [0] NCCL INFO Using network AWS Libfabric\n",
      "nid001184:731735:735262 [1] NCCL INFO Using network AWS Libfabric\n",
      "nid001184:731735:735263 [2] NCCL INFO Using network AWS Libfabric\n",
      "nid001184:731735:735264 [3] NCCL INFO Using network AWS Libfabric\n",
      "nid001184:731735:735261 [0] NCCL INFO DMA-BUF is available on GPU device 0\n",
      "nid001184:731735:735262 [1] NCCL INFO DMA-BUF is available on GPU device 1\n",
      "nid001184:731735:735263 [2] NCCL INFO DMA-BUF is available on GPU device 2\n",
      "nid001184:731735:735264 [3] NCCL INFO DMA-BUF is available on GPU device 3\n",
      "nid001184:731735:735261 [0] NCCL INFO NCCL_NET_GDR_LEVEL set by environment to PHB\n",
      "nid001184:731735:735261 [0] NCCL INFO Setting affinity for GPU 0 to ffff0000,00000000,ffff0000,00000000\n",
      "nid001184:731735:735261 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.\n",
      "nid001184:731735:735264 [3] NCCL INFO Setting affinity for GPU 3 to ffff,00000000,0000ffff\n",
      "nid001184:731735:735263 [2] NCCL INFO Setting affinity for GPU 2 to ffff0000,00000000,ffff0000\n",
      "nid001184:731735:735262 [1] NCCL INFO Setting affinity for GPU 1 to ffff,00000000,0000ffff,00000000\n",
      "nid001184:731735:735263 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] -1/-1/-1->2->0 [3] -1/-1/-1->2->0 [4] 0/-1/-1->2->-1 [5] 0/-1/-1->2->-1 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->0 [11] -1/-1/-1->2->0 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] -1/-1/-1->2->0 [15] -1/-1/-1->2->0 [16] 0/-1/-1->2->-1 [17] 0/-1/-1->2->-1 [18] 1/-1/-1->2->3 [19] 1/-1/-1->2->3 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] -1/-1/-1->2->0 [23] -1/-1/-1->2->0\n",
      "nid001184:731735:735262 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 3/-1/-1->1->-1 [3] 3/-1/-1->1->-1 [4] -1/-1/-1->1->3 [5] -1/-1/-1->1->3 [6] 0/-1/-1->1->2 [7] 0/-1/-1->1->2 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 3/-1/-1->1->-1 [11] 3/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 3/-1/-1->1->-1 [15] 3/-1/-1->1->-1 [16] -1/-1/-1->1->3 [17] -1/-1/-1->1->3 [18] 0/-1/-1->1->2 [19] 0/-1/-1->1->2 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 3/-1/-1->1->-1 [23] 3/-1/-1->1->-1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 00/24 :    0   1   2   3\n",
      "nid001184:731735:735263 [2] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001184:731735:735262 [1] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001184:731735:735264 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->1 [3] 0/-1/-1->3->1 [4] 1/-1/-1->3->0 [5] 1/-1/-1->3->0 [6] 2/-1/-1->3->-1 [7] 2/-1/-1->3->-1 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 0/-1/-1->3->1 [11] 0/-1/-1->3->1 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] 0/-1/-1->3->1 [15] 0/-1/-1->3->1 [16] 1/-1/-1->3->0 [17] 1/-1/-1->3->0 [18] 2/-1/-1->3->-1 [19] 2/-1/-1->3->-1 [20] -1/-1/-1->3->2 [21] -1/-1/-1->3->2 [22] 0/-1/-1->3->1 [23] 0/-1/-1->3->1\n",
      "nid001184:731735:735264 [3] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 01/24 :    0   1   3   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 02/24 :    0   2   3   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 03/24 :    0   2   1   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 04/24 :    0   3   1   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 05/24 :    0   3   2   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 06/24 :    0   1   2   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 07/24 :    0   1   3   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 08/24 :    0   2   3   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 09/24 :    0   2   1   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 10/24 :    0   3   1   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 11/24 :    0   3   2   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 12/24 :    0   1   2   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 13/24 :    0   1   3   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 14/24 :    0   2   3   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 15/24 :    0   2   1   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 16/24 :    0   3   1   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 17/24 :    0   3   2   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 18/24 :    0   1   2   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 19/24 :    0   1   3   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 20/24 :    0   2   3   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 21/24 :    0   2   1   3\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 22/24 :    0   3   1   2\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 23/24 :    0   3   2   1\n",
      "nid001184:731735:735261 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 2/-1/-1->0->3 [3] 2/-1/-1->0->3 [4] 3/-1/-1->0->2 [5] 3/-1/-1->0->2 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 2/-1/-1->0->3 [11] 2/-1/-1->0->3 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 2/-1/-1->0->3 [15] 2/-1/-1->0->3 [16] 3/-1/-1->0->2 [17] 3/-1/-1->0->2 [18] -1/-1/-1->0->1 [19] -1/-1/-1->0->1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 2/-1/-1->0->3 [23] 2/-1/-1->0->3\n",
      "nid001184:731735:735261 [0] NCCL INFO P2P Chunksize set to 524288\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 00/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 00/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 00/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 00/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 03/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 02/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 01/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 04/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 06/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 06/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 06/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 06/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 09/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 08/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 07/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 10/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 12/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 12/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 12/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 12/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 15/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 14/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 13/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 16/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 18/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 18/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 18/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 18/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 21/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 20/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 19/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 22/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 02/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 02/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 01/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 01/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 04/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 03/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 03/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 04/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 08/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 08/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 07/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 07/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 10/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 09/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 09/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 10/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 14/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 14/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 13/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 13/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 16/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 15/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 15/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 16/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 20/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 20/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 19/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 19/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 22/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 21/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 21/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 22/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 01/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 02/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 04/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 03/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 05/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 05/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 05/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 05/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 07/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 08/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 10/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 09/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 11/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 11/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 11/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 11/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 13/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 14/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 16/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 15/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 17/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 17/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 17/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 17/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 19/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 20/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 22/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 21/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 23/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 23/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 23/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 23/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Connected all rings\n",
      "nid001184:731735:735261 [0] NCCL INFO Connected all rings\n",
      "nid001184:731735:735262 [1] NCCL INFO Connected all rings\n",
      "nid001184:731735:735263 [2] NCCL INFO Connected all rings\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 01/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 07/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 02/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 08/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 04/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 09/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 05/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 13/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 01/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 10/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 19/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 07/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 08/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 11/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 20/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 09/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 09/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 14/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 21/0 : 1[41000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 13/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 20/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 16/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 19/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 21/0 : 0[3000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 17/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 21/0 : 2[82000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 22/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 23/0 : 3[c1000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 02/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 04/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 05/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 10/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 02/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 04/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 11/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 03/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 05/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 14/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 05/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 10/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 03/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 16/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 11/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 11/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 05/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 17/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 14/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 16/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 11/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 22/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 15/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "via P2P/direct pointer/read NCCL INFO Channel 17/0 : 0[3000] -> 2[82000] \n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 15/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 23/0 : 1[41000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 17/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 22/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 17/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 23/0 : 2[82000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 23/0 : 0[3000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 23/0 : 3[c1000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 00/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 06/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 08/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 09/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 00/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 12/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 01/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 18/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 06/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 02/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 00/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 20/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 07/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 03/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 01/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Channel 21/0 : 3[c1000] -> 2[82000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 08/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 14/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 06/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 12/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735261 [0] NCCL INFO Channel 15/0 : 0[3000] -> 3[c1000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 07/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 13/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 09/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 18/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 12/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 19/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 13/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735263 [2] NCCL INFO Channel 20/0 : 2[82000] -> 1[41000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 18/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735262 [1] NCCL INFO Channel 19/0 : 1[41000] -> 0[3000] via P2P/direct pointer/read\n",
      "nid001184:731735:735264 [3] NCCL INFO Connected all trees\n",
      "nid001184:731735:735264 [3] NCCL INFO threadThres"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747932165.815912  734117 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970/970 [==============================] - 20s 9ms/step - loss: 0.3403 - auc: 0.1055 - f1_score: 0.0050 - val_loss: 0.3277 - val_auc: 0.1038 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3326 - auc: 0.1112 - f1_score: 0.0000e+00 - val_loss: 0.3576 - val_auc: 0.1092 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 1.0506 - auc: 0.1293 - f1_score: 0.0331 - val_loss: 0.3222 - val_auc: 0.1070 - val_f1_score: 0.0016\n",
      "Epoch 4/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3137 - auc: 0.1688 - f1_score: 0.0077 - val_loss: 0.3263 - val_auc: 0.1079 - val_f1_score: 0.0016\n",
      "Epoch 5/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3151 - auc: 0.1754 - f1_score: 0.0225 - val_loss: 0.3310 - val_auc: 0.1105 - val_f1_score: 0.0015\n",
      "Epoch 6/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.8200 - auc: 0.1666 - f1_score: 0.0639 - val_loss: 0.3511 - val_auc: 0.1027 - val_f1_score: 0.0197\n",
      "Epoch 7/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.2932 - auc: 0.2552 - f1_score: 0.0653 - val_loss: 0.3398 - val_auc: 0.1047 - val_f1_score: 0.0045\n",
      "Epoch 8/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.2841 - auc: 0.2992 - f1_score: 0.0981 - val_loss: 0.3471 - val_auc: 0.1069 - val_f1_score: 0.0046\n",
      "208/208 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 7777, 64)          384       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 2592, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 2588, 32)          10272     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 1294, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 41408)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 41408)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 41409     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52065 (203.38 KB)\n",
      "Trainable params: 52065 (203.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[54.5234375, 62.18780517578125, 0.005394393920898438, 0.46049804687500007, 5.65716552734375, 78.08477783203125, 0.21668090820312502]\n",
      "Epoch 1/62\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 11s 8ms/step - loss: 0.3380 - auc_1: 0.1074 - f1_score: 0.0047 - val_loss: 0.3266 - val_auc_1: 0.1084 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3373 - auc_1: 0.1105 - f1_score: 3.2098e-04 - val_loss: 0.3965 - val_auc_1: 0.1097 - val_f1_score: 0.0061\n",
      "Epoch 3/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 1.9653 - auc_1: 0.1292 - f1_score: 0.0357 - val_loss: 0.3234 - val_auc_1: 0.1063 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3128 - auc_1: 0.1722 - f1_score: 0.0061 - val_loss: 0.3268 - val_auc_1: 0.1067 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3083 - auc_1: 0.1910 - f1_score: 0.0118 - val_loss: 0.3300 - val_auc_1: 0.1082 - val_f1_score: 0.0015\n",
      "Epoch 6/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3058 - auc_1: 0.2033 - f1_score: 0.0239 - val_loss: 0.3327 - val_auc_1: 0.1085 - val_f1_score: 0.0046\n",
      "Epoch 7/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3032 - auc_1: 0.2179 - f1_score: 0.0494 - val_loss: 0.3373 - val_auc_1: 0.1059 - val_f1_score: 0.0060\n",
      "Epoch 8/62\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3034 - auc_1: 0.2290 - f1_score: 0.0891 - val_loss: 0.8339 - val_auc_1: 0.1059 - val_f1_score: 0.1787\n",
      "208/208 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPoolin  (None, 2593, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 1295, 64)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.06591796875, 10.970916748046875, 0.008190277099609376, 0.637451171875, 2.98748779296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/11\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 10s 14ms/step - loss: 0.5930 - auc_2: 0.1093 - f1_score: 0.0264 - val_loss: 0.3236 - val_auc_2: 0.1050 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3263 - auc_2: 0.1153 - f1_score: 0.0000e+00 - val_loss: 0.3226 - val_auc_2: 0.1148 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3263 - auc_2: 0.1156 - f1_score: 0.0000e+00 - val_loss: 0.3179 - val_auc_2: 0.1143 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3233 - auc_2: 0.1295 - f1_score: 3.2191e-04 - val_loss: 0.3184 - val_auc_2: 0.1102 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3174 - auc_2: 0.1547 - f1_score: 0.0045 - val_loss: 0.3287 - val_auc_2: 0.1073 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3122 - auc_2: 0.1852 - f1_score: 0.0271 - val_loss: 0.3466 - val_auc_2: 0.1109 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3039 - auc_2: 0.2271 - f1_score: 0.0864 - val_loss: 0.3523 - val_auc_2: 0.1095 - val_f1_score: 0.0161\n",
      "Epoch 8/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 14.0886 - auc_2: 0.1787 - f1_score: 0.1412 - val_loss: 8.3104 - val_auc_2: 0.0971 - val_f1_score: 0.0076\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 7777, 32)          192       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 2592, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 2588, 16)          2576      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 1294, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 20704)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20704)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 20705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23473 (91.69 KB)\n",
      "Trainable params: 23473 (91.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[35.64599609375, 24.89471435546875, 0.006360366821289063, 0.46669921875, 5.459320068359375, 26.94158935546875, 0.5570571899414063]\n",
      "Epoch 1/25\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "1940/1940 [==============================] - 17s 7ms/step - loss: 0.3533 - auc_3: 0.1021 - f1_score: 0.0019 - val_loss: 0.3177 - val_auc_3: 0.1120 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3525 - auc_3: 0.1050 - f1_score: 0.0078 - val_loss: 0.3194 - val_auc_3: 0.1028 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3505 - auc_3: 0.1051 - f1_score: 0.0041 - val_loss: 0.3211 - val_auc_3: 0.1043 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3486 - auc_3: 0.1054 - f1_score: 0.0051 - val_loss: 0.3198 - val_auc_3: 0.0970 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3487 - auc_3: 0.1046 - f1_score: 0.0041 - val_loss: 0.3604 - val_auc_3: 0.1062 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3479 - auc_3: 0.1054 - f1_score: 0.0054 - val_loss: 0.3209 - val_auc_3: 0.1068 - val_f1_score: 0.0000e+00\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPoolin  (None, 2593, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPoolin  (None, 1295, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[107.7705078125, 16.61651611328125, 0.007990051269531251, 0.7704956054687501, 3.9207763671875, 46.54364013671875, 0.4668975830078126]\n",
      "Epoch 1/17\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3391 - auc_4: 0.1072 - f1_score: 0.0081 - val_loss: 0.3215 - val_auc_4: 0.1126 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/17\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3306 - auc_4: 0.1106 - f1_score: 0.0000e+00 - val_loss: 0.3302 - val_auc_4: 0.1138 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/17\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3302 - auc_4: 0.1153 - f1_score: 3.2185e-04 - val_loss: 0.3453 - val_auc_4: 0.1129 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/17\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3299 - auc_4: 0.1219 - f1_score: 6.4309e-04 - val_loss: 0.3221 - val_auc_4: 0.1101 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/17\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3270 - auc_4: 0.1311 - f1_score: 9.6277e-04 - val_loss: 0.3241 - val_auc_4: 0.1091 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/17\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3247 - auc_4: 0.1402 - f1_score: 0.0032 - val_loss: 0.3226 - val_auc_4: 0.1041 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 7775, 64)          512       \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPooli  (None, 2591, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 2585, 32)          14368     \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPooli  (None, 1292, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 41344)             0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 41344)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 41345     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56225 (219.63 KB)\n",
      "Trainable params: 56225 (219.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[46.19140625, 24.937286376953125, 0.006541915893554688, 0.78238525390625, 7.094818115234375, 62.632080078125, 0.5133392333984376]\n",
      "Epoch 1/25\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "1940/1940 [==============================] - 18s 7ms/step - loss: 0.6874 - auc_5: 0.1062 - f1_score: 0.0219 - val_loss: 0.3366 - val_auc_5: 0.1098 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3394 - auc_5: 0.1102 - f1_score: 0.0019 - val_loss: 0.3175 - val_auc_5: 0.1057 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3652 - auc_5: 0.1076 - f1_score: 0.0144 - val_loss: 0.3259 - val_auc_5: 0.1074 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3920 - auc_5: 0.1058 - f1_score: 0.0312 - val_loss: 0.3356 - val_auc_5: 0.1053 - val_f1_score: 0.0016\n",
      "Epoch 5/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3972 - auc_5: 0.1032 - f1_score: 0.0327 - val_loss: 0.3246 - val_auc_5: 0.0998 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3916 - auc_5: 0.1064 - f1_score: 0.0379 - val_loss: 0.3252 - val_auc_5: 0.1020 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/25\n",
      "1940/1940 [==============================] - 12s 6ms/step - loss: 0.3869 - auc_5: 0.1090 - f1_score: 0.0367 - val_loss: 0.3529 - val_auc_5: 0.1059 - val_f1_score: 0.0000e+00\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.002309158325195313, 0.64439697265625, 7.45635986328125, 103.03009033203125, 0.23824615478515626]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 10s 13ms/step - loss: 0.3349 - auc_6: 0.1052 - f1_score: 0.0047 - val_loss: 0.3161 - val_auc_6: 0.1143 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3282 - auc_6: 0.1144 - f1_score: 3.2191e-04 - val_loss: 0.3181 - val_auc_6: 0.1111 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3206 - auc_6: 0.1499 - f1_score: 0.0042 - val_loss: 0.3251 - val_auc_6: 0.1061 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3079 - auc_6: 0.2074 - f1_score: 0.0513 - val_loss: 0.3487 - val_auc_6: 0.1085 - val_f1_score: 0.0046\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2854 - auc_6: 0.2946 - f1_score: 0.1625 - val_loss: 0.3783 - val_auc_6: 0.1048 - val_f1_score: 0.0479\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2607 - auc_6: 0.3955 - f1_score: 0.2795 - val_loss: 0.3921 - val_auc_6: 0.1060 - val_f1_score: 0.0536\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 7775, 8)           64        \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 2591, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 2585, 4)           228       \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 1292, 4)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 5168)              0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 5168)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 5169      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5461 (21.33 KB)\n",
      "Trainable params: 5461 (21.33 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[104.04541015625, 68.14102172851562, 0.008622863769531251, 0.2497802734375, 7.7535400390625, 9.26568603515625, 0.26067657470703126]\n",
      "Epoch 1/68\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 10s 13ms/step - loss: 0.3331 - auc_7: 0.1074 - f1_score: 0.0035 - val_loss: 0.3242 - val_auc_7: 0.1140 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3270 - auc_7: 0.1166 - f1_score: 0.0000e+00 - val_loss: 0.3195 - val_auc_7: 0.1140 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3247 - auc_7: 0.1249 - f1_score: 3.2191e-04 - val_loss: 0.3275 - val_auc_7: 0.1052 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3224 - auc_7: 0.1384 - f1_score: 0.0026 - val_loss: 0.3198 - val_auc_7: 0.1138 - val_f1_score: 0.0016\n",
      "Epoch 5/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3197 - auc_7: 0.1471 - f1_score: 0.0022 - val_loss: 0.3184 - val_auc_7: 0.1109 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3186 - auc_7: 0.1526 - f1_score: 0.0022 - val_loss: 0.3217 - val_auc_7: 0.1073 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3159 - auc_7: 0.1619 - f1_score: 0.0064 - val_loss: 0.3224 - val_auc_7: 0.1091 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/68\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3145 - auc_7: 0.1675 - f1_score: 0.0077 - val_loss: 0.3244 - val_auc_7: 0.1031 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/68\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3127 - auc_7: 0.1755 - f1_score: 0.0105 - val_loss: 0.3260 - val_auc_7: 0.1041 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/68\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3125 - auc_7: 0.1779 - f1_score: 0.0118 - val_loss: 0.3255 - val_auc_7: 0.1064 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_16 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[86.15380859375, 94.09210205078125, 0.002765090942382813, 0.83255615234375, 2.847686767578125, 42.07452392578125, 0.4786788940429688]\n",
      "Epoch 1/94\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 11s 8ms/step - loss: 0.3315 - auc_8: 0.1081 - f1_score: 6.4226e-04 - val_loss: 0.3207 - val_auc_8: 0.1132 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3269 - auc_8: 0.1146 - f1_score: 0.0000e+00 - val_loss: 0.3188 - val_auc_8: 0.1023 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3252 - auc_8: 0.1236 - f1_score: 0.0000e+00 - val_loss: 0.3186 - val_auc_8: 0.1120 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3209 - auc_8: 0.1415 - f1_score: 6.4298e-04 - val_loss: 0.3195 - val_auc_8: 0.1077 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3160 - auc_8: 0.1623 - f1_score: 0.0042 - val_loss: 0.3243 - val_auc_8: 0.1082 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3110 - auc_8: 0.1839 - f1_score: 0.0168 - val_loss: 0.3313 - val_auc_8: 0.1063 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3051 - auc_8: 0.2066 - f1_score: 0.0285 - val_loss: 0.3261 - val_auc_8: 0.1079 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3030 - auc_8: 0.2137 - f1_score: 0.0465 - val_loss: 0.3273 - val_auc_8: 0.1050 - val_f1_score: 0.0031\n",
      "208/208 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_19 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[92.58447265625, 10.781402587890625, 0.00197613525390625, 0.4994140625, 7.95880126953125, 97.65277099609375, 0.19400482177734377]\n",
      "Epoch 1/11\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 12s 9ms/step - loss: 0.3340 - auc_9: 0.1055 - f1_score: 0.0013 - val_loss: 0.3180 - val_auc_9: 0.1078 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/11\n",
      "970/970 [==============================] - 7s 8ms/step - loss: 0.3309 - auc_9: 0.1162 - f1_score: 3.2139e-04 - val_loss: 0.3215 - val_auc_9: 0.1055 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/11\n",
      "970/970 [==============================] - 7s 8ms/step - loss: 0.3210 - auc_9: 0.1552 - f1_score: 0.0133 - val_loss: 0.3287 - val_auc_9: 0.1062 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/11\n",
      "970/970 [==============================] - 7s 7ms/step - loss: 0.3047 - auc_9: 0.2249 - f1_score: 0.0832 - val_loss: 0.3495 - val_auc_9: 0.1044 - val_f1_score: 0.0200\n",
      "Epoch 5/11\n",
      "970/970 [==============================] - 7s 8ms/step - loss: 0.2772 - auc_9: 0.3306 - f1_score: 0.2069 - val_loss: 0.3612 - val_auc_9: 0.1083 - val_f1_score: 0.0328\n",
      "Epoch 6/11\n",
      "970/970 [==============================] - 7s 8ms/step - loss: 0.2497 - auc_9: 0.4475 - f1_score: 0.3553 - val_loss: 0.4124 - val_auc_9: 0.1031 - val_f1_score: 0.0089\n",
      "208/208 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_20 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_21 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005506866455078125, 0.26265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 10ms/step - loss: 0.3324 - auc_10: 0.1066 - f1_score: 0.0022 - val_loss: 0.3286 - val_auc_10: 0.1145 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3309 - auc_10: 0.1066 - f1_score: 0.0000e+00 - val_loss: 0.3177 - val_auc_10: 0.1136 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3302 - auc_10: 0.1092 - f1_score: 0.0000e+00 - val_loss: 0.3157 - val_auc_10: 0.1164 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3294 - auc_10: 0.1130 - f1_score: 0.0000e+00 - val_loss: 0.3160 - val_auc_10: 0.1128 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3281 - auc_10: 0.1158 - f1_score: 6.4392e-04 - val_loss: 0.3161 - val_auc_10: 0.1145 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3283 - auc_10: 0.1180 - f1_score: 3.2201e-04 - val_loss: 0.3197 - val_auc_10: 0.1165 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3298 - auc_10: 0.1183 - f1_score: 3.2185e-04 - val_loss: 0.3195 - val_auc_10: 0.1154 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3254 - auc_10: 0.1253 - f1_score: 6.4381e-04 - val_loss: 0.3196 - val_auc_10: 0.1127 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      ">0, new best f([98.06591796875, 10.970916748046875, 0.008190277099609376, 0.637451171875, 2.98748779296875, 104.02911376953125, 0.19485931396484377]) = 0.114288\n",
      ">0, new best f([124.22509765625, 97.04330444335938, 0.005506866455078125, 0.26265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]) = 0.116374\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "generation0\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_22 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_23 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15673828125, 97.04330444335938, 0.005506866455078125, 0.26265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 10ms/step - loss: 0.3330 - auc_11: 0.1054 - f1_score: 0.0022 - val_loss: 0.3177 - val_auc_11: 0.1119 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3288 - auc_11: 0.1094 - f1_score: 0.0000e+00 - val_loss: 0.3159 - val_auc_11: 0.1131 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3309 - auc_11: 0.1086 - f1_score: 0.0000e+00 - val_loss: 0.3168 - val_auc_11: 0.1127 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3302 - auc_11: 0.1132 - f1_score: 0.0000e+00 - val_loss: 0.3170 - val_auc_11: 0.1096 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3286 - auc_11: 0.1137 - f1_score: 0.0000e+00 - val_loss: 0.3198 - val_auc_11: 0.1124 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3280 - auc_11: 0.1164 - f1_score: 0.0000e+00 - val_loss: 0.3173 - val_auc_11: 0.1111 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3280 - auc_11: 0.1190 - f1_score: 3.2196e-04 - val_loss: 0.3186 - val_auc_11: 0.1106 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_24 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_25 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_25 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[123.845703125, 20.63201904296875, 0.002309158325195313, 0.64439697265625, 7.45635986328125, 103.03009033203125, 0.23824615478515626]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 12ms/step - loss: 0.3326 - auc_12: 0.1075 - f1_score: 0.0038 - val_loss: 0.3541 - val_auc_12: 0.1041 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.8949 - auc_12: 0.1125 - f1_score: 0.0406 - val_loss: 0.3351 - val_auc_12: 0.1132 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3163 - auc_12: 0.1611 - f1_score: 0.0067 - val_loss: 0.3251 - val_auc_12: 0.1105 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3073 - auc_12: 0.2008 - f1_score: 0.0064 - val_loss: 0.3235 - val_auc_12: 0.1121 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3028 - auc_12: 0.2206 - f1_score: 0.0165 - val_loss: 0.3251 - val_auc_12: 0.1119 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2964 - auc_12: 0.2517 - f1_score: 0.0315 - val_loss: 0.3288 - val_auc_12: 0.1131 - val_f1_score: 0.0015\n",
      "Epoch 7/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2913 - auc_12: 0.2683 - f1_score: 0.0603 - val_loss: 0.3337 - val_auc_12: 0.1096 - val_f1_score: 0.0061\n",
      "Epoch 8/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2838 - auc_12: 0.3016 - f1_score: 0.0947 - val_loss: 0.3390 - val_auc_12: 0.1119 - val_f1_score: 0.0106\n",
      "Epoch 9/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2758 - auc_12: 0.3343 - f1_score: 0.1495 - val_loss: 0.3487 - val_auc_12: 0.1074 - val_f1_score: 0.0147\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_26 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_26 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_27 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_27 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005542022705078126, 0.43255615234375, 2.847686767578125, 42.07452392578125, 0.4786788940429688]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3338 - auc_13: 0.1079 - f1_score: 0.0016 - val_loss: 0.3247 - val_auc_13: 0.1124 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3290 - auc_13: 0.1104 - f1_score: 0.0000e+00 - val_loss: 0.3245 - val_auc_13: 0.1090 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3273 - auc_13: 0.1177 - f1_score: 0.0000e+00 - val_loss: 0.3174 - val_auc_13: 0.1116 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3263 - auc_13: 0.1266 - f1_score: 0.0022 - val_loss: 0.3273 - val_auc_13: 0.1100 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3234 - auc_13: 0.1398 - f1_score: 0.0038 - val_loss: 0.3218 - val_auc_13: 0.1096 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3189 - auc_13: 0.1561 - f1_score: 0.0061 - val_loss: 0.3288 - val_auc_13: 0.1114 - val_f1_score: 0.0031\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3163 - auc_13: 0.1677 - f1_score: 0.0130 - val_loss: 0.3660 - val_auc_13: 0.1084 - val_f1_score: 0.0076\n",
      "Epoch 8/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3166 - auc_13: 0.1719 - f1_score: 0.0247 - val_loss: 0.3222 - val_auc_13: 0.1104 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_28 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_28 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_29 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_29 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[86.15380859375, 94.09210205078125, 0.0027606964111328127, 0.66265869140625, 5.257171630859375, 16.9381103515625, 0.338232421875]\n",
      "Epoch 1/94\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 11s 8ms/step - loss: 0.3298 - auc_14: 0.1088 - f1_score: 6.4226e-04 - val_loss: 0.3168 - val_auc_14: 0.1055 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3265 - auc_14: 0.1137 - f1_score: 0.0000e+00 - val_loss: 0.3175 - val_auc_14: 0.1085 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3232 - auc_14: 0.1264 - f1_score: 6.4402e-04 - val_loss: 0.3206 - val_auc_14: 0.1067 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3182 - auc_14: 0.1488 - f1_score: 0.0019 - val_loss: 0.3285 - val_auc_14: 0.1093 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3136 - auc_14: 0.1688 - f1_score: 0.0042 - val_loss: 0.3280 - val_auc_14: 0.1094 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3087 - auc_14: 0.1894 - f1_score: 0.0130 - val_loss: 0.3324 - val_auc_14: 0.1074 - val_f1_score: 0.0016\n",
      "208/208 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_30 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_30 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 96.69174194335938, 0.0055771789550781254, 0.637451171875, 3.01092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 11ms/step - loss: 0.3588 - auc_15: 0.1078 - f1_score: 0.0148 - val_loss: 0.3169 - val_auc_15: 0.1143 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 2.6821 - auc_15: 0.1092 - f1_score: 0.0496 - val_loss: 0.3265 - val_auc_15: 0.1014 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3341 - auc_15: 0.1179 - f1_score: 0.0019 - val_loss: 0.3634 - val_auc_15: 0.1008 - val_f1_score: 0.0016\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3261 - auc_15: 0.1267 - f1_score: 6.4381e-04 - val_loss: 0.3179 - val_auc_15: 0.1093 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3177 - auc_15: 0.1440 - f1_score: 6.4371e-04 - val_loss: 0.3174 - val_auc_15: 0.1163 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3150 - auc_15: 0.1587 - f1_score: 9.6479e-04 - val_loss: 0.3210 - val_auc_15: 0.1163 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_32 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.06591796875, 10.970916748046875, 0.008190277099609376, 0.26265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/11\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 10ms/step - loss: 0.3358 - auc_16: 0.1047 - f1_score: 0.0035 - val_loss: 0.3211 - val_auc_16: 0.1112 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3322 - auc_16: 0.1079 - f1_score: 0.0000e+00 - val_loss: 0.3215 - val_auc_16: 0.1086 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3347 - auc_16: 0.1083 - f1_score: 0.0000e+00 - val_loss: 0.3355 - val_auc_16: 0.1070 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3331 - auc_16: 0.1091 - f1_score: 3.2196e-04 - val_loss: 0.3171 - val_auc_16: 0.1136 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3318 - auc_16: 0.1097 - f1_score: 3.2180e-04 - val_loss: 0.3220 - val_auc_16: 0.1128 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3314 - auc_16: 0.1090 - f1_score: 3.2201e-04 - val_loss: 0.3172 - val_auc_16: 0.1081 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3305 - auc_16: 0.1097 - f1_score: 3.2196e-04 - val_loss: 0.3168 - val_auc_16: 0.1075 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3294 - auc_16: 0.1111 - f1_score: 0.0000e+00 - val_loss: 0.3170 - val_auc_16: 0.1070 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3306 - auc_16: 0.1115 - f1_score: 3.2165e-04 - val_loss: 0.3192 - val_auc_16: 0.1037 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3309 - auc_16: 0.1122 - f1_score: 3.2165e-04 - val_loss: 0.3172 - val_auc_16: 0.1033 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/11\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3315 - auc_16: 0.1136 - f1_score: 9.6386e-04 - val_loss: 0.3184 - val_auc_16: 0.1006 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_34 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.06591796875, 10.970916748046875, 0.008190277099609376, 0.637451171875, 2.98748779296875, 103.99884033203125, 0.23824615478515626]\n",
      "Epoch 1/11\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 12ms/step - loss: 0.4754 - auc_17: 0.1069 - f1_score: 0.0158 - val_loss: 0.3282 - val_auc_17: 0.1130 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 4.8035 - auc_17: 0.1042 - f1_score: 0.0487 - val_loss: 0.3276 - val_auc_17: 0.1086 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3353 - auc_17: 0.1130 - f1_score: 0.0019 - val_loss: 0.3310 - val_auc_17: 0.1072 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3262 - auc_17: 0.1223 - f1_score: 6.4360e-04 - val_loss: 0.3192 - val_auc_17: 0.1077 - val_f1_score: 0.0031\n",
      "Epoch 5/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3209 - auc_17: 0.1368 - f1_score: 0.0016 - val_loss: 0.3179 - val_auc_17: 0.1164 - val_f1_score: 0.0016\n",
      "Epoch 6/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3183 - auc_17: 0.1466 - f1_score: 0.0016 - val_loss: 0.3190 - val_auc_17: 0.1130 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3127 - auc_17: 0.1672 - f1_score: 0.0016 - val_loss: 0.3208 - val_auc_17: 0.1108 - val_f1_score: 0.0031\n",
      "Epoch 8/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3106 - auc_17: 0.1788 - f1_score: 0.0073 - val_loss: 0.3296 - val_auc_17: 0.1105 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3035 - auc_17: 0.2098 - f1_score: 0.0251 - val_loss: 0.3415 - val_auc_17: 0.1119 - val_f1_score: 0.0031\n",
      "Epoch 10/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 17.7562 - auc_17: 0.1159 - f1_score: 0.1231 - val_loss: 0.8132 - val_auc_17: 0.0991 - val_f1_score: 0.1652\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_36 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.002309158325195313, 0.64439697265625, 7.45635986328125, 103.06036376953125, 0.19485931396484377]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3330 - auc_18: 0.1068 - f1_score: 0.0051 - val_loss: 0.3238 - val_auc_18: 0.1150 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.8646 - auc_18: 0.1122 - f1_score: 0.0326 - val_loss: 0.3281 - val_auc_18: 0.1157 - val_f1_score: 0.0031\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3104 - auc_18: 0.1861 - f1_score: 0.0074 - val_loss: 0.3226 - val_auc_18: 0.1107 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3019 - auc_18: 0.2271 - f1_score: 0.0124 - val_loss: 0.3258 - val_auc_18: 0.1122 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2948 - auc_18: 0.2575 - f1_score: 0.0268 - val_loss: 0.3364 - val_auc_18: 0.1127 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2886 - auc_18: 0.2865 - f1_score: 0.0516 - val_loss: 0.3334 - val_auc_18: 0.1121 - val_f1_score: 0.0031\n",
      "Epoch 7/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2806 - auc_18: 0.3164 - f1_score: 0.0935 - val_loss: 0.3379 - val_auc_18: 0.1107 - val_f1_score: 0.0090\n",
      "Epoch 8/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2727 - auc_18: 0.3498 - f1_score: 0.1356 - val_loss: 0.3501 - val_auc_18: 0.1095 - val_f1_score: 0.0283\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_38 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_39 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_39 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005507415771484375, 0.43255615234375, 2.847686767578125, 42.07452392578125, 0.4786788940429688]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3337 - auc_19: 0.1074 - f1_score: 0.0035 - val_loss: 0.3232 - val_auc_19: 0.1139 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3299 - auc_19: 0.1114 - f1_score: 0.0000e+00 - val_loss: 0.3166 - val_auc_19: 0.1183 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3261 - auc_19: 0.1224 - f1_score: 0.0000e+00 - val_loss: 0.3262 - val_auc_19: 0.1136 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3265 - auc_19: 0.1290 - f1_score: 0.0019 - val_loss: 0.3546 - val_auc_19: 0.1140 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3212 - auc_19: 0.1422 - f1_score: 0.0019 - val_loss: 0.3206 - val_auc_19: 0.1137 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3185 - auc_19: 0.1579 - f1_score: 0.0089 - val_loss: 0.3195 - val_auc_19: 0.1086 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3163 - auc_19: 0.1646 - f1_score: 0.0108 - val_loss: 0.3283 - val_auc_19: 0.1163 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_40 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_40 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_41 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_41 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[86.15380859375, 94.09210205078125, 0.002765090942382813, 0.66265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/94\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 10s 8ms/step - loss: 0.3309 - auc_20: 0.1058 - f1_score: 0.0013 - val_loss: 0.3163 - val_auc_20: 0.1145 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3282 - auc_20: 0.1085 - f1_score: 0.0000e+00 - val_loss: 0.3179 - val_auc_20: 0.1110 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3277 - auc_20: 0.1113 - f1_score: 0.0000e+00 - val_loss: 0.3330 - val_auc_20: 0.1077 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3267 - auc_20: 0.1157 - f1_score: 0.0000e+00 - val_loss: 0.3167 - val_auc_20: 0.1098 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3259 - auc_20: 0.1196 - f1_score: 3.2206e-04 - val_loss: 0.3205 - val_auc_20: 0.1139 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3248 - auc_20: 0.1246 - f1_score: 0.0000e+00 - val_loss: 0.3179 - val_auc_20: 0.1109 - val_f1_score: 0.0000e+00\n",
      "208/208 [==============================] - 1s 2ms/step\n",
      ">1, new best f([124.22509765625, 97.04330444335938, 0.005507415771484375, 0.43255615234375, 2.847686767578125, 42.07452392578125, 0.4786788940429688]) = 0.118293\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "generation1\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_42 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_43 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_43 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.2236328125, 96.77963256835938, 0.005507415771484375, 0.23255615234375002, 2.847686767578125, 42.07452392578125, 0.4786788940429688]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3339 - auc_21: 0.1055 - f1_score: 0.0022 - val_loss: 0.3204 - val_auc_21: 0.1126 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3304 - auc_21: 0.1133 - f1_score: 0.0000e+00 - val_loss: 0.3166 - val_auc_21: 0.1110 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3265 - auc_21: 0.1210 - f1_score: 0.0000e+00 - val_loss: 0.3244 - val_auc_21: 0.1061 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3253 - auc_21: 0.1325 - f1_score: 9.6572e-04 - val_loss: 0.3181 - val_auc_21: 0.1048 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3218 - auc_21: 0.1440 - f1_score: 0.0042 - val_loss: 0.3231 - val_auc_21: 0.1058 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3189 - auc_21: 0.1576 - f1_score: 0.0073 - val_loss: 0.3226 - val_auc_21: 0.1093 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3179 - auc_21: 0.1632 - f1_score: 0.0139 - val_loss: 0.3289 - val_auc_21: 0.1048 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_44 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_44 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_45 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_45 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.0055771789550781254, 0.637451171875, 3.01092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 11ms/step - loss: 0.3823 - auc_22: 0.1057 - f1_score: 0.0143 - val_loss: 0.3196 - val_auc_22: 0.1073 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3374 - auc_22: 0.1069 - f1_score: 9.6277e-04 - val_loss: 0.3167 - val_auc_22: 0.1133 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3240 - auc_22: 0.1238 - f1_score: 0.0000e+00 - val_loss: 0.3241 - val_auc_22: 0.1067 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3200 - auc_22: 0.1495 - f1_score: 0.0042 - val_loss: 0.3214 - val_auc_22: 0.1079 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3109 - auc_22: 0.1901 - f1_score: 0.0357 - val_loss: 0.3330 - val_auc_22: 0.1079 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 5.0257 - auc_22: 0.1870 - f1_score: 0.1136 - val_loss: 5.5143 - val_auc_22: 0.1019 - val_f1_score: 0.1480\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.4195 - auc_22: 0.2620 - f1_score: 0.2590 - val_loss: 0.3980 - val_auc_22: 0.1110 - val_f1_score: 0.0148\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_46 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_46 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_47 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_47 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[86.15380859375, 94.09210205078125, 0.00276495361328125, 0.43255615234375, 2.847686767578125, 42.13507080078125, 0.48961639404296875]\n",
      "Epoch 1/94\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 10s 7ms/step - loss: 0.3317 - auc_23: 0.1076 - f1_score: 0.0016 - val_loss: 0.3308 - val_auc_23: 0.1117 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3273 - auc_23: 0.1125 - f1_score: 0.0000e+00 - val_loss: 0.3167 - val_auc_23: 0.1129 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3260 - auc_23: 0.1192 - f1_score: 0.0000e+00 - val_loss: 0.3258 - val_auc_23: 0.1080 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3221 - auc_23: 0.1352 - f1_score: 3.2170e-04 - val_loss: 0.3187 - val_auc_23: 0.1057 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3202 - auc_23: 0.1465 - f1_score: 0.0016 - val_loss: 0.3195 - val_auc_23: 0.1104 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/94\n",
      "970/970 [==============================] - 6s 6ms/step - loss: 0.3144 - auc_23: 0.1676 - f1_score: 0.0080 - val_loss: 0.3213 - val_auc_23: 0.1094 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3100 - auc_23: 0.1859 - f1_score: 0.0121 - val_loss: 0.3213 - val_auc_23: 0.1119 - val_f1_score: 0.0000e+00\n",
      "208/208 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_48 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_48 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_49 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005507278442382813, 0.66265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3325 - auc_24: 0.1069 - f1_score: 0.0032 - val_loss: 0.3186 - val_auc_24: 0.1107 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3291 - auc_24: 0.1092 - f1_score: 0.0000e+00 - val_loss: 0.3168 - val_auc_24: 0.1131 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3295 - auc_24: 0.1101 - f1_score: 0.0000e+00 - val_loss: 0.3186 - val_auc_24: 0.1120 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3290 - auc_24: 0.1133 - f1_score: 0.0000e+00 - val_loss: 0.3166 - val_auc_24: 0.1093 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3284 - auc_24: 0.1143 - f1_score: 0.0000e+00 - val_loss: 0.3245 - val_auc_24: 0.1105 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3289 - auc_24: 0.1156 - f1_score: 0.0000e+00 - val_loss: 0.3182 - val_auc_24: 0.1137 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3288 - auc_24: 0.1162 - f1_score: 6.4392e-04 - val_loss: 0.3205 - val_auc_24: 0.1098 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3266 - auc_24: 0.1184 - f1_score: 0.0000e+00 - val_loss: 0.3184 - val_auc_24: 0.1088 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3247 - auc_24: 0.1232 - f1_score: 0.0000e+00 - val_loss: 0.3172 - val_auc_24: 0.1093 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_50 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005507415771484375, 0.40755615234375, 2.847686767578125, 42.07452392578125, 0.4775039672851563]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 9ms/step - loss: 0.3336 - auc_25: 0.1067 - f1_score: 6.4041e-04 - val_loss: 0.3219 - val_auc_25: 0.1125 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3267 - auc_25: 0.1179 - f1_score: 0.0000e+00 - val_loss: 0.3205 - val_auc_25: 0.1123 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3272 - auc_25: 0.1219 - f1_score: 3.2191e-04 - val_loss: 0.3176 - val_auc_25: 0.1129 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3260 - auc_25: 0.1342 - f1_score: 0.0016 - val_loss: 0.3199 - val_auc_25: 0.1118 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3211 - auc_25: 0.1488 - f1_score: 0.0067 - val_loss: 0.3180 - val_auc_25: 0.1176 - val_f1_score: 0.0016\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3191 - auc_25: 0.1588 - f1_score: 0.0114 - val_loss: 0.3215 - val_auc_25: 0.1163 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3148 - auc_25: 0.1741 - f1_score: 0.0179 - val_loss: 0.3237 - val_auc_25: 0.1126 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3124 - auc_25: 0.1825 - f1_score: 0.0268 - val_loss: 0.3236 - val_auc_25: 0.1142 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_52 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.06591796875, 10.968170166015625, 0.008190277099609376, 0.637451171875, 2.98748779296875, 103.99884033203125, 0.23942108154296876]\n",
      "Epoch 1/11\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.5102 - auc_26: 0.1056 - f1_score: 0.0205 - val_loss: 0.3283 - val_auc_26: 0.1141 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3287 - auc_26: 0.1117 - f1_score: 0.0000e+00 - val_loss: 0.3221 - val_auc_26: 0.1139 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 27.3855 - auc_26: 0.1046 - f1_score: 0.0949 - val_loss: 1.1921 - val_auc_26: 0.0962 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.6033 - auc_26: 0.1084 - f1_score: 0.0753 - val_loss: 0.4229 - val_auc_26: 0.1103 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.4217 - auc_26: 0.1144 - f1_score: 0.0481 - val_loss: 0.8035 - val_auc_26: 0.0969 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3591 - auc_26: 0.1199 - f1_score: 0.0190 - val_loss: 0.3501 - val_auc_26: 0.1091 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3423 - auc_26: 0.1270 - f1_score: 0.0131 - val_loss: 0.3941 - val_auc_26: 0.1135 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_54 (Conv1D)          (None, 7779, 16)          64        \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPooli  (None, 2593, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 2591, 8)           392       \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPooli  (None, 1295, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 10360)             0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 10360)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 10361     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10817 (42.25 KB)\n",
      "Trainable params: 10817 (42.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005507415771484375, 0.43255615234375, 3.007171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 10ms/step - loss: 0.3334 - auc_27: 0.1057 - f1_score: 0.0022 - val_loss: 0.3165 - val_auc_27: 0.1113 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3299 - auc_27: 0.1103 - f1_score: 0.0000e+00 - val_loss: 0.3179 - val_auc_27: 0.1106 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3285 - auc_27: 0.1105 - f1_score: 0.0000e+00 - val_loss: 0.3164 - val_auc_27: 0.1137 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3282 - auc_27: 0.1136 - f1_score: 0.0000e+00 - val_loss: 0.3165 - val_auc_27: 0.1086 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3278 - auc_27: 0.1155 - f1_score: 0.0000e+00 - val_loss: 0.3171 - val_auc_27: 0.1115 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3263 - auc_27: 0.1185 - f1_score: 0.0000e+00 - val_loss: 0.3181 - val_auc_27: 0.1099 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3269 - auc_27: 0.1193 - f1_score: 0.0000e+00 - val_loss: 0.3169 - val_auc_27: 0.1122 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3249 - auc_27: 0.1254 - f1_score: 0.0000e+00 - val_loss: 0.3176 - val_auc_27: 0.1107 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_56 (Conv1D)          (None, 7777, 32)          192       \n",
      "                                                                 \n",
      " max_pooling1d_56 (MaxPooli  (None, 2592, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 2588, 16)          2576      \n",
      "                                                                 \n",
      " max_pooling1d_57 (MaxPooli  (None, 1294, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 20704)             0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 20704)             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 20705     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23473 (91.69 KB)\n",
      "Trainable params: 23473 (91.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[86.15380859375, 94.09210205078125, 0.002765090942382813, 0.66265869140625, 5.097686767578125, 42.07452392578125, 0.4786788940429688]\n",
      "Epoch 1/94\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "970/970 [==============================] - 11s 8ms/step - loss: 0.3320 - auc_28: 0.1048 - f1_score: 6.4133e-04 - val_loss: 0.3166 - val_auc_28: 0.1064 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3280 - auc_28: 0.1123 - f1_score: 0.0000e+00 - val_loss: 0.3265 - val_auc_28: 0.1096 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3256 - auc_28: 0.1252 - f1_score: 3.2196e-04 - val_loss: 0.3194 - val_auc_28: 0.1107 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3222 - auc_28: 0.1371 - f1_score: 6.4267e-04 - val_loss: 0.3230 - val_auc_28: 0.1133 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3188 - auc_28: 0.1556 - f1_score: 0.0045 - val_loss: 0.3205 - val_auc_28: 0.1095 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/94\n",
      "970/970 [==============================] - 6s 7ms/step - loss: 0.3134 - auc_28: 0.1819 - f1_score: 0.0168 - val_loss: 0.3237 - val_auc_28: 0.1099 - val_f1_score: 0.0000e+00\n",
      "208/208 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_58 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_58 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 96.69174194335938, 0.005578689575195313, 0.64439697265625, 7.45635986328125, 103.06036376953125, 0.19485931396484377]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.4272 - auc_29: 0.1070 - f1_score: 0.0201 - val_loss: 0.3167 - val_auc_29: 0.1155 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3286 - auc_29: 0.1092 - f1_score: 0.0000e+00 - val_loss: 0.3202 - val_auc_29: 0.1068 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3237 - auc_29: 0.1249 - f1_score: 3.2191e-04 - val_loss: 0.3383 - val_auc_29: 0.1110 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3212 - auc_29: 0.1456 - f1_score: 0.0035 - val_loss: 0.3223 - val_auc_29: 0.1114 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 1.0039 - auc_29: 0.1589 - f1_score: 0.0388 - val_loss: 488.0288 - val_auc_29: 0.0964 - val_f1_score: 0.1758\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 13.6408 - auc_29: 0.1505 - f1_score: 0.1752 - val_loss: 0.4101 - val_auc_29: 0.1093 - val_f1_score: 0.0361\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_60 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_60 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_61 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.002588897705078125, 0.635888671875, 3.01092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 12ms/step - loss: 0.3324 - auc_30: 0.1064 - f1_score: 0.0013 - val_loss: 0.3209 - val_auc_30: 0.1175 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3292 - auc_30: 0.1163 - f1_score: 0.0000e+00 - val_loss: 0.3212 - val_auc_30: 0.1071 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3188 - auc_30: 0.1490 - f1_score: 0.0016 - val_loss: 0.3256 - val_auc_30: 0.1081 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3030 - auc_30: 0.2148 - f1_score: 0.0434 - val_loss: 0.3366 - val_auc_30: 0.1099 - val_f1_score: 0.0016\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.2805 - auc_30: 0.3082 - f1_score: 0.1528 - val_loss: 0.3808 - val_auc_30: 0.1112 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2559 - auc_30: 0.4104 - f1_score: 0.2850 - val_loss: 0.3708 - val_auc_30: 0.1091 - val_f1_score: 0.0145\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "generation2\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_62 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_62 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_63 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_63 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.002588897705078125, 0.635888671875, 3.00323486328125, 103.06036376953125, 0.19485931396484377]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3337 - auc_31: 0.1062 - f1_score: 0.0022 - val_loss: 0.3208 - val_auc_31: 0.1140 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3267 - auc_31: 0.1185 - f1_score: 0.0000e+00 - val_loss: 0.3170 - val_auc_31: 0.1089 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3180 - auc_31: 0.1564 - f1_score: 0.0048 - val_loss: 0.3261 - val_auc_31: 0.1101 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2990 - auc_31: 0.2359 - f1_score: 0.0639 - val_loss: 0.3343 - val_auc_31: 0.1050 - val_f1_score: 0.0107\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.2773 - auc_31: 0.3275 - f1_score: 0.1824 - val_loss: 0.3523 - val_auc_31: 0.1051 - val_f1_score: 0.0146\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2542 - auc_31: 0.4210 - f1_score: 0.3043 - val_loss: 0.3959 - val_auc_31: 0.1058 - val_f1_score: 0.0203\n",
      "Epoch 7/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2338 - auc_31: 0.4959 - f1_score: 0.3892 - val_loss: 0.4021 - val_auc_31: 0.1043 - val_f1_score: 0.0356\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_64 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_64 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_65 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_65 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 96.69174194335938, 0.005578689575195313, 0.64439697265625, 7.46405029296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 12ms/step - loss: 0.3894 - auc_32: 0.1085 - f1_score: 0.0150 - val_loss: 0.3170 - val_auc_32: 0.1154 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3297 - auc_32: 0.1117 - f1_score: 0.0000e+00 - val_loss: 0.3219 - val_auc_32: 0.1104 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3243 - auc_32: 0.1291 - f1_score: 9.6401e-04 - val_loss: 0.3387 - val_auc_32: 0.1134 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 20.3513 - auc_32: 0.1269 - f1_score: 0.0812 - val_loss: 0.5505 - val_auc_32: 0.1031 - val_f1_score: 0.0185\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3800 - auc_32: 0.1733 - f1_score: 0.1360 - val_loss: 0.3593 - val_auc_32: 0.1058 - val_f1_score: 0.0200\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3132 - auc_32: 0.2232 - f1_score: 0.1195 - val_loss: 0.3471 - val_auc_32: 0.1106 - val_f1_score: 0.0060\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_66 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_66 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_67 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_67 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.0025890350341796877, 0.635888671875, 3.01092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3337 - auc_33: 0.1052 - f1_score: 0.0029 - val_loss: 0.3194 - val_auc_33: 0.1139 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3255 - auc_33: 0.1189 - f1_score: 0.0000e+00 - val_loss: 0.3193 - val_auc_33: 0.1131 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.8095 - auc_33: 0.1338 - f1_score: 0.0449 - val_loss: 0.3228 - val_auc_33: 0.1110 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3008 - auc_33: 0.2229 - f1_score: 0.0146 - val_loss: 0.3253 - val_auc_33: 0.1181 - val_f1_score: 0.0015\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.2924 - auc_33: 0.2624 - f1_score: 0.0342 - val_loss: 0.3269 - val_auc_33: 0.1155 - val_f1_score: 0.0015\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2849 - auc_33: 0.2970 - f1_score: 0.0590 - val_loss: 0.3375 - val_auc_33: 0.1120 - val_f1_score: 0.0133\n",
      "Epoch 7/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.2755 - auc_33: 0.3322 - f1_score: 0.0972 - val_loss: 0.3397 - val_auc_33: 0.1131 - val_f1_score: 0.0119\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_68 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_68 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_69 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.004838897705078126, 0.635888671875, 3.01092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3494 - auc_34: 0.1082 - f1_score: 0.0154 - val_loss: 0.3209 - val_auc_34: 0.1128 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 1.4062 - auc_34: 0.1087 - f1_score: 0.0427 - val_loss: 0.3240 - val_auc_34: 0.1145 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3240 - auc_34: 0.1229 - f1_score: 0.0000e+00 - val_loss: 0.3184 - val_auc_34: 0.1110 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3209 - auc_34: 0.1336 - f1_score: 0.0000e+00 - val_loss: 0.3194 - val_auc_34: 0.1158 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3174 - auc_34: 0.1468 - f1_score: 9.6510e-04 - val_loss: 0.3287 - val_auc_34: 0.1140 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3118 - auc_34: 0.1727 - f1_score: 0.0013 - val_loss: 0.3204 - val_auc_34: 0.1150 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 3.3758 - auc_34: 0.1413 - f1_score: 0.0597 - val_loss: 0.3808 - val_auc_34: 0.1092 - val_f1_score: 0.0119\n",
      "Epoch 8/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3172 - auc_34: 0.1759 - f1_score: 0.0243 - val_loss: 0.3572 - val_auc_34: 0.1132 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_70 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_70 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_71 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005507141113281251, 0.235888671875, 3.01092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3587 - auc_35: 0.1081 - f1_score: 0.0140 - val_loss: 0.3190 - val_auc_35: 0.1109 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3269 - auc_35: 0.1157 - f1_score: 0.0000e+00 - val_loss: 0.3216 - val_auc_35: 0.1054 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3263 - auc_35: 0.1305 - f1_score: 9.6293e-04 - val_loss: 0.3645 - val_auc_35: 0.1079 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 9.4424 - auc_35: 0.1153 - f1_score: 0.1108 - val_loss: 0.4447 - val_auc_35: 0.1049 - val_f1_score: 0.1125\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3373 - auc_35: 0.1782 - f1_score: 0.0956 - val_loss: 0.3349 - val_auc_35: 0.1141 - val_f1_score: 0.0077\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3073 - auc_35: 0.2198 - f1_score: 0.0798 - val_loss: 0.3373 - val_auc_35: 0.1149 - val_f1_score: 0.0105\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_72 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_72 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_73 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_73 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.52734375, 20.63201904296875, 0.0025890350341796877, 0.66265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3313 - auc_36: 0.1075 - f1_score: 0.0022 - val_loss: 0.3259 - val_auc_36: 0.1134 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3266 - auc_36: 0.1124 - f1_score: 0.0000e+00 - val_loss: 0.3244 - val_auc_36: 0.1134 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3261 - auc_36: 0.1133 - f1_score: 0.0000e+00 - val_loss: 0.3162 - val_auc_36: 0.1112 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3250 - auc_36: 0.1207 - f1_score: 0.0000e+00 - val_loss: 0.3175 - val_auc_36: 0.1151 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3247 - auc_36: 0.1194 - f1_score: 0.0000e+00 - val_loss: 0.3164 - val_auc_36: 0.1138 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3232 - auc_36: 0.1264 - f1_score: 0.0000e+00 - val_loss: 0.3190 - val_auc_36: 0.1137 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3220 - auc_36: 0.1334 - f1_score: 6.4392e-04 - val_loss: 0.3181 - val_auc_36: 0.1155 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/21\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3219 - auc_36: 0.1370 - f1_score: 9.6479e-04 - val_loss: 0.3177 - val_auc_36: 0.1169 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_74 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_74 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_75 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_75 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.15234375, 20.63201904296875, 0.002588897705078125, 0.635888671875, 2.95635986328125, 103.06036376953125, 0.19485931396484377]\n",
      "Epoch 1/21\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3347 - auc_37: 0.1075 - f1_score: 0.0016 - val_loss: 0.3160 - val_auc_37: 0.1120 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3269 - auc_37: 0.1172 - f1_score: 0.0000e+00 - val_loss: 0.3170 - val_auc_37: 0.1140 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3191 - auc_37: 0.1487 - f1_score: 0.0019 - val_loss: 0.3342 - val_auc_37: 0.1116 - val_f1_score: 0.0031\n",
      "Epoch 4/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3027 - auc_37: 0.2162 - f1_score: 0.0414 - val_loss: 0.3479 - val_auc_37: 0.1086 - val_f1_score: 0.0188\n",
      "Epoch 5/21\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.2838 - auc_37: 0.2976 - f1_score: 0.1515 - val_loss: 0.3499 - val_auc_37: 0.1046 - val_f1_score: 0.0132\n",
      "Epoch 6/21\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.2564 - auc_37: 0.4081 - f1_score: 0.2770 - val_loss: 0.3762 - val_auc_37: 0.1067 - val_f1_score: 0.0172\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_76 (Conv1D)          (None, 7775, 128)         1024      \n",
      "                                                                 \n",
      " max_pooling1d_76 (MaxPooli  (None, 2591, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_77 (Conv1D)          (None, 2585, 64)          57408     \n",
      "                                                                 \n",
      " max_pooling1d_77 (MaxPooli  (None, 1292, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 82688)             0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 82689     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141121 (551.25 KB)\n",
      "Trainable params: 141121 (551.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 96.69174194335938, 0.005578689575195313, 0.64439697265625, 7.51092529296875, 104.02911376953125, 0.19485931396484377]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.4979 - auc_38: 0.1084 - f1_score: 0.0284 - val_loss: 0.3166 - val_auc_38: 0.1170 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3263 - auc_38: 0.1143 - f1_score: 0.0000e+00 - val_loss: 0.3198 - val_auc_38: 0.1134 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3240 - auc_38: 0.1228 - f1_score: 0.0000e+00 - val_loss: 0.3173 - val_auc_38: 0.1092 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3224 - auc_38: 0.1349 - f1_score: 6.4298e-04 - val_loss: 0.3218 - val_auc_38: 0.1145 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3187 - auc_38: 0.1581 - f1_score: 0.0080 - val_loss: 0.3228 - val_auc_38: 0.1091 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3119 - auc_38: 0.1885 - f1_score: 0.0313 - val_loss: 0.3499 - val_auc_38: 0.1046 - val_f1_score: 0.0201\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_78 (Conv1D)          (None, 7777, 16)          96        \n",
      "                                                                 \n",
      " max_pooling1d_78 (MaxPooli  (None, 2592, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_79 (Conv1D)          (None, 2588, 8)           648       \n",
      "                                                                 \n",
      " max_pooling1d_79 (MaxPooli  (None, 1294, 8)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 10352)             0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 10353     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11097 (43.35 KB)\n",
      "Trainable params: 11097 (43.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[98.16259765625, 97.04330444335938, 0.005507278442382813, 0.66265869140625, 5.257171630859375, 16.9305419921875, 0.688232421875]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 7s 9ms/step - loss: 0.3327 - auc_39: 0.1080 - f1_score: 0.0048 - val_loss: 0.3166 - val_auc_39: 0.1089 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3288 - auc_39: 0.1079 - f1_score: 0.0000e+00 - val_loss: 0.3163 - val_auc_39: 0.1137 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3294 - auc_39: 0.1105 - f1_score: 0.0000e+00 - val_loss: 0.3230 - val_auc_39: 0.1073 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 3s 7ms/step - loss: 0.3290 - auc_39: 0.1118 - f1_score: 0.0000e+00 - val_loss: 0.3163 - val_auc_39: 0.1120 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3292 - auc_39: 0.1136 - f1_score: 0.0000e+00 - val_loss: 0.3163 - val_auc_39: 0.1132 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3285 - auc_39: 0.1173 - f1_score: 3.2191e-04 - val_loss: 0.3302 - val_auc_39: 0.1145 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3274 - auc_39: 0.1211 - f1_score: 3.2201e-04 - val_loss: 0.3175 - val_auc_39: 0.1135 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3273 - auc_39: 0.1233 - f1_score: 6.4309e-04 - val_loss: 0.3337 - val_auc_39: 0.1135 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3246 - auc_39: 0.1276 - f1_score: 9.6541e-04 - val_loss: 0.3191 - val_auc_39: 0.1107 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3228 - auc_39: 0.1310 - f1_score: 3.2180e-04 - val_loss: 0.3193 - val_auc_39: 0.1094 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_80 (Conv1D)          (None, 7779, 128)         512       \n",
      "                                                                 \n",
      " max_pooling1d_80 (MaxPooli  (None, 2593, 128)         0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_81 (Conv1D)          (None, 2591, 64)          24640     \n",
      "                                                                 \n",
      " max_pooling1d_81 (MaxPooli  (None, 1295, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 82880)             0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 1)                 82881     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108033 (422.00 KB)\n",
      "Trainable params: 108033 (422.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.12841796875, 10.968170166015625, 0.005940277099609375, 0.637451171875, 2.98748779296875, 103.99884033203125, 0.23942108154296876]\n",
      "Epoch 1/11\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 9s 11ms/step - loss: 0.3462 - auc_40: 0.1060 - f1_score: 0.0068 - val_loss: 0.3196 - val_auc_40: 0.1134 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 4.1581 - auc_40: 0.1082 - f1_score: 0.0548 - val_loss: 0.3198 - val_auc_40: 0.1091 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3321 - auc_40: 0.1202 - f1_score: 3.2149e-04 - val_loss: 0.3197 - val_auc_40: 0.1158 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/11\n",
      "485/485 [==============================] - 5s 10ms/step - loss: 0.3256 - auc_40: 0.1259 - f1_score: 3.2175e-04 - val_loss: 0.3230 - val_auc_40: 0.1153 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3208 - auc_40: 0.1351 - f1_score: 0.0000e+00 - val_loss: 0.3231 - val_auc_40: 0.1131 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/11\n",
      "485/485 [==============================] - 5s 9ms/step - loss: 0.3164 - auc_40: 0.1495 - f1_score: 0.0000e+00 - val_loss: 0.3298 - val_auc_40: 0.1060 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "generation3\n",
      "Runtime:  2046.4968116283417\n",
      "Test model\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_82 (Conv1D)          (None, 7779, 32)          128       \n",
      "                                                                 \n",
      " max_pooling1d_82 (MaxPooli  (None, 2593, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 2591, 16)          1552      \n",
      "                                                                 \n",
      " max_pooling1d_83 (MaxPooli  (None, 1295, 16)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 20720)             0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 20721     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22401 (87.50 KB)\n",
      "Trainable params: 22401 (87.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[124.22509765625, 97.04330444335938, 0.005507415771484375, 0.43255615234375, 2.847686767578125, 42.07452392578125, 0.4786788940429688]\n",
      "Epoch 1/97\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 6 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "485/485 [==============================] - 8s 10ms/step - loss: 0.3336 - auc_41: 0.1079 - f1_score: 0.0050 - val_loss: 0.3288 - val_auc_41: 0.1204 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3289 - auc_41: 0.1128 - f1_score: 0.0000e+00 - val_loss: 0.3305 - val_auc_41: 0.1179 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3248 - auc_41: 0.1243 - f1_score: 3.2191e-04 - val_loss: 0.3571 - val_auc_41: 0.1151 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/97\n",
      "485/485 [==============================] - 4s 7ms/step - loss: 0.3241 - auc_41: 0.1317 - f1_score: 9.6494e-04 - val_loss: 0.3369 - val_auc_41: 0.1144 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3216 - auc_41: 0.1446 - f1_score: 0.0035 - val_loss: 0.3391 - val_auc_41: 0.1120 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/97\n",
      "485/485 [==============================] - 4s 8ms/step - loss: 0.3179 - auc_41: 0.1619 - f1_score: 0.0108 - val_loss: 0.3383 - val_auc_41: 0.1103 - val_f1_score: 0.0000e+00\n",
      "104/104 [==============================] - 1s 3ms/step\n",
      "Completed\n",
      "FINISHED, Runtime: 36.91 minutes\n",
      "hyperparam_optim=[124.22509765625, 97.04330444335938, 0.005507415771484375, 0.43255615234375, 2.847686767578125, 42.07452392578125, 0.4786788940429688]\n"
     ]
    }
   ],
   "source": [
    "model = CNN_model3\n",
    "# batch_size, epochs, learning_rate, momentum, kernelsize, maxpooling, (nfilters)\n",
    "# bounds = [[16, 256], [10, 50]] #0\n",
    "# bounds = [[16, 64], [100, 200], [0.0001, 0.01], [0.1, 0.9], [2, 8], [2, 3]] #1\n",
    "# bounds = [[32, 128], [30, 80], [0.001, 0.01], [0.1, 0.9], [2, 8], [2, 3], [4, 64]] #2\n",
    "bounds = [[32, 128], [10, 100], [0.001, 0.01], [0.1, 0.9], [2, 8], [4, 128], [0.1, 0.8]] #3\n",
    "#bounds = [[32, 128], [30, 80], [0.001, 0.01], [0.1, 0.9], [2, 8], [4, 64], [1e-6, 1e-1]] #4\n",
    "\n",
    "print(\"Starting\")\n",
    "res_opt_method, CM_opt, hyperparam_optim, optim_results = train_CNN_js(model, bounds, x_train, y_train, x_valid, y_valid, x_test, y_test, strategy)\n",
    "print(\"Completed\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# # SAVE RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "# use a dictionary with keys using the right names.\n",
    "results = {'results': res_opt_method, 'confusion matrix': CM_opt, 'hyperparameters': hyperparam_optim,\n",
    "           'y_test': list(y_test)}\n",
    "a_file = open(results_path + \"results3.pkl\", \"wb\")\n",
    "pickle.dump(results, a_file)\n",
    "a_file.close()\n",
    "\n",
    "# export optimization results\n",
    "a_file = open(results_path + \"GA_results3.pkl\", \"wb\")\n",
    "pickle.dump(optim_results, a_file)\n",
    "a_file.close()\n",
    "\n",
    "## OUT\n",
    "end_global = time.time()\n",
    "print(f\"FINISHED, Runtime: {(end_global - start_global) / 60:.2f} minutes\")\n",
    "print(f\"{hyperparam_optim=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5edb4c-6fcb-4f01-8898-f31c4a798f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utility_functions import FDRthreshold_js, ROC_PR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# # =============================================================================\n",
    "# # ROC & PR curves\n",
    "# # =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "y_test = np.array(results['y_test'])\n",
    "y_pred_prob = np.array(results['results']['Y_pred_prob'])\n",
    "\n",
    "ls_roc_auc, ls_fpr, ls_tpr, ls_pr_auc, ls_precision, ls_recall, pr_no_skill, ls_roc_auc_noskill, ls_fpr_noskill, ls_tpr_noskill = ROC_PR(y_pred_prob, y_test)\n",
    "\n",
    "#ROC\n",
    "plt.figure()\n",
    "#plt.plot(ls_fpr, ls_tpr, lw=1, color=color_ls[met], label=met+\" (AUC={})\".format(np.round(ls_roc_auc[met],3)))\n",
    "plt.plot(ls_fpr, ls_tpr, lw=1, label=f\"ROC-AUC={ls_roc_auc:.3f})\")\n",
    "plt.plot(ls_fpr_noskill, ls_tpr_noskill, linestyle='--', lw=1, color='gray')  #'No Skill'\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title('ROC-Curve')\n",
    "plt.legend()\n",
    "# plt.savefig(visualisation_path + 'ROC_' + planet + '_alpha' + str(alpha) + '_bal' + str(bal) + '_combined_CV_' + str(plotname) + '_version' + str(version) + 'frame' + str(frame) + '_fold' + str(j) + '_js.pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#PR\n",
    "plt.figure()\n",
    "#plt.plot(ls_recall, ls_precision[met], lw=1, color=color_ls[met], label=met + \" (AUC={})\".format(np.round(ls_pr_auc[met],3)))\n",
    "plt.plot(ls_recall, ls_precision, lw=1, label=f\"PR-AUC={ls_pr_auc:.3f})\")\n",
    "plt.plot([0, 1], [pr_no_skill, pr_no_skill], linestyle='--', lw=1, color='gray')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('PR-Curve')\n",
    "plt.legend()\n",
    "#plt.savefig(visualisation_path + 'PR_' + planet + '_alpha' + str(alpha) + '_bal' + str(bal) + '_combined_CV_' + str(plotname) + '_version' + str(version) + 'frame' + str(frame) + '_fold' + str(j) + '_js.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc7751ff-c72b-4932-9e91-f7cd8f7839e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54.5,\n",
       " 33.125,\n",
       " 0.006203125,\n",
       " 0.45625000000000004,\n",
       " 4.90625,\n",
       " 63.765625,\n",
       " 0.4144531250000001]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611220ae-10b1-46e0-97f0-527350b70856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808e31a-88eb-4278-81ec-036c5dee5704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.15.0",
   "language": "python",
   "name": "tensorflow-2.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
